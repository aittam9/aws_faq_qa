	Amazon CodeGuru	Amazon Comprehend	Amazon Fraud Detector	Amazon Kendra	Amazon Lex	Amazon Personalize	Amazon Recognition	Amazon Textract	Amazon Transcribe	Amazon Translate	Amazon SageMaker	Amazon SageMaker Ground Truth	Amazon Augmented AI	Container di deep learning AWS
Cos'è amazon codeguru?	Amazon CodeGuru contiene due componenti: Amazon CodeGuru Security e il profilatore Amazon CodeGuru. CodeGuru Security è uno strumento basato sul machine learning (ML) e sull'analisi dei programmi che rileva le vulnerabilità di sicurezza nel codice Java, Python e JavaScript. CodeGuru Security analizza anche le credenziali codificate. Il profilatore CodeGuru ottimizza le prestazioni delle applicazioni eseguite in produzione e identifica le righe di codice più costose, riducendo significativamente i costi operativi.													
Come inizio a utilizzare codeguru?	CodeGuru è ora disponibile al pubblico. Puoi iniziare a utilizzarlo subito nella console di Amazon CodeGuru.													
In quali regioni aws è disponibile codeguru?	Per le regioni supportate, consulta la tabella delle Regioni AWS per l'infrastruttura globale AWS. Per ulteriori informazioni, consulta la pagina Regions and Endpoints nel documento AWS General Reference.													
Cos'è amazon codeguru security?	CodeGuru Security è uno strumento di scansione del codice basato sul machine learning e sull'analisi dei programmi che rileva le vulnerabilità di sicurezza nel codice Java, Python e JavaScript.													
Quali linguaggi di programmazione sono supportati?	Il profilatore CodeGuru attualmente supporta i linguaggi Java, Python (in anteprima) e JVM come Scala e Kotlin.													
Come inizio a utilizzare codeguru security?	Visita la console di CodeGuru per integrare CodeGuru Security nel tuo ciclo di vita da sviluppatore. Puoi integrarlo in strumenti di integrazione e distribuzione continua (CI/CD), nella scansione dei repository e negli ambienti di sviluppo integrati (IDE).													
Codeguru security accede al mio codice?	CodeGuru Security richiede l'accesso in sola lettura al tuo codice allo scopo di generare i suggerimenti. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati, tra cui la crittografia durante i trasferimenti, per impedire l'accesso o la divulgazione non autorizzati dei tuoi contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Supportiamo anche le chiavi KMS del gestore clienti (CMCMK) per la crittografia. Per ulteriori informazioni, consulta le Domande frequenti sulla privacy dei dati.													
Codeguru security conserva una copia del mio codice?	No, CodeGuru Security non archivia il tuo codice sorgente.													
In che modo codeguru security viene addestrato per fornire suggerimenti intelligenti?	CodeGuru Security viene addestrato utilizzando rule mining e modelli di machine learning supervisionati che utilizzano una combinazione di regressione logistica e reti neurali. Ad esempio, durante la fase di addestramento per la perdita di dati sensibili, il servizio esegue un'analisi completa del codice in cerca dei percorsi che utilizzano la risorsa o i dati sensibili, crea funzioni che li rappresentano e le utilizza come input per i modelli di regressione logistica e per le reti neurali convoluzionali.													
Quali integrazioni supporta codeguru security?	CodeGuru Security è integrato con la scansione del codice Amazon Inspector per Lambda. Presto saranno disponibili ulteriori integrazioni con repository e strumenti CI/CD.													
Cos'è il profilatore amazon codeguru?	Il profilatore CodeGuru aiuta gli sviluppatori e gli operatori IT a comprendere in modo semplice il comportamento in runtime delle proprie applicazioni, a migliorare le prestazioni e a diminuire i costi di elaborazione. Il profilatore Amazon CodeGuru analizza il profilo di runtime dell'applicazione e fornisce suggerimenti intelligenti e visualizzazioni che guidano gli sviluppatori al miglioramento delle prestazioni delle parti più pertinenti del codice.													
Cos'è un gruppo di profiling?	Un gruppo di profiling è un raggruppamento logico creato da te. Rappresenta i limiti di un'applicazione. Ad esempio, in un'architettura di microservizi, un gruppo di profiling aggrega i profili dei microservizi assegnati e ne produce un profilo unico.													
Il codice comprende già un servizio completo di registrazione. occorre comunque effettuare la profilatura?	Registrare il tempo di esecuzione funziona solo in un numero limitato di casi perché la registrazione è solo in grado di monitorare la latenza (non l'utilizzo della CPU) e implementarlo richiede molto tempo perché gli sviluppatori devono registrare ogni funzione in un'applicazione (senza alcun impatto sulle prestazioni dell'applicazione), rimanendo senza gli strumenti necessari per monitorare ed eseguire efficacemente la risoluzione dei problemi di applicazioni in produzione. Ecco dove entra in gioco il profiling: il profilatore CodeGuru è stato progettato per raccogliere i dati su qualsiasi evento che si verifica nel comportamento dell'applicazione, indipendentemente dalla situazione. Il profilatore CodeGuru utilizza una knowledge base di inefficienze di prestazione riscontrate più di frequente al fine di rilevare automaticamente le sequenze di codice nell'applicazione attiva che compromettono le prestazioni. Dunque, gli sviluppatori possono seguire i suggerimenti forniti per risolvere i problemi riscontrati.													
In che modo codeguru profiler differisce dalle apm tradizionali e dai sistemi di profiling standalone?	Le APM tradizionali forniscono dati utili sul monitoraggio, sul tracciamento e sulle prestazioni delle applicazioni. Il profilatore CodeGuru integra queste funzionalità APM offrendo visualizzazioni dei dati di runtime dell'applicazione e suggerimenti eseguibili per i problemi di prestazione riscontrati. Utilizza inoltre il machine learning per rilevare e avvisare riguardo ad anomalie nel profilo dell'applicazione, indicando le righe di codice anomale. Il profilatore CodeGuru consente di individuare facilmente le parti di codice che offrono le migliori opportunità di ottimizzazione delle prestazioni, nonché potenziali risparmi e consente di ricevere indicazioni su come procedere senza dover contare su competenze specializzate in ambito tecnico. Il profilatore Amazon CodeGuru esegue il profiling delle istanze EC2, dei container e delle piattaforme di calcolo serverless inclusa AWS Lambda anche on-premise. Inoltre, alcuni sistemi di profiling standalone sono progettati per essere eseguiti solo in ambienti di test, mentre il profilatore CodeGuru è un servizio progettato per l'esecuzione continua in produzione, con i relativi carichi di traffico e senza interferire con l'applicazione. Si tratta di un aspetto utile durante la fase di risoluzione dei problemi operativi in produzione, anche in caso di esecuzione su host bare metal.													
Quali tipi di applicazione posso profilare?	Il profilatore CodeGuru funziona con le applicazioni ospitate da Amazon EC2, le applicazioni in container eseguite su Amazon ECS e Amazon EKS, nonché le applicazioni serverless in esecuzione su AWS Fargate e AWS Lambda. Inoltre, puoi eseguire il profilatore CodeGuru on-premise.													
In che modo il profilatore codeguru influisce sulle prestazioni delle applicazioni ospitate da aws lambda?	L'agente del profilatore CodeGuru utilizza le risorse (CPU, memoria) allocate alle funzioni di AWS Lambda. È stato messo a punto per avere un impatto minimo sulle prestazioni dell'applicazione mentre viene eseguito in quanto thread in elaborazione. Se l'applicazione consuma la maggior parte delle risorse nella funzione AWS Lambda, considera l'aumento delle risorse per abilitare il funzionamento adeguato dell'agente.													
Come funziona il profilatore codeguru?	Il profilatore CodeGuru è composto da tre parti: un agente, il servizio di profiling e i suggerimenti intelligenti. L'agente si avvia con l'applicazione sulla riga di comando e si esegue in forma di thread in elaborazione come parte dell'applicazione. Raccoglie dati da ognuna delle istanze del servizio in cui l'agente è in esecuzione e li invia ogni cinque minuti al servizio di profiling, dove vengono aggregati. A questo punto, il profilatore CodeGuru pubblica i dati sul profilo in grafici a fiamma interattivi che ti consentono di visualizzare le prestazioni della tua applicazione. Inoltre, il profilatore CodeGuru analizza costantemente i dati soggetti a profiling e li confronta rispetto alle best practice di Amazon e di performance engineering. Inoltre, il servizio invia suggerimenti intelligenti se vengono rilevati problemi relativi alle prestazioni. Inoltre, utilizza il machine learning per analizzare continuamente i dati del runtime dell'applicazione e segnala quando rileva anomalie nel profilo dell'applicazione e indica le righe di codice anomale.													
Quali sono le risorse profilate dal profilatore codeguru e quali sono i linguaggi supportati?	Il profilatore CodeGuru profila CPU (CPU attiva e tempo reale) e memoria (riepilogo dell'heap) per Java e altri linguaggi JVM e CPU (tempo reale) per le applicazioni Python.													
Posso ottenere informazioni su cpu e memoria dalla stessa applicazione?	Sì, una volta abilitata la profilazione della memoria e la avvii, CodeGuru Profiler raccoglierà le informazioni sia sulla memoria sia sulla CPU per l'applicazione. È necessario solo un gruppo di profiling per ottenere dati della CPU e della memoria di un'applicazione specifica.													
Quali informazioni sulla profilazione della memoria fornisce il profilatore codeguru?	Il profilatore CodeGuru offre informazioni sul riepilogo dell'heap. Il riepilogo dell'heap fornisce una vista consolidata dell'utilizzo della memoria per tipo di oggetto (ad esempio, String, int, char[]) e tipi personalizzati, in un determinato arco di tempo (in genere 5 minuti). Il profilatore CodeGuru tiene traccia sia delle dimensioni totali degli oggetti che del loro numero. Questi parametri vengono presentati in un grafico cronologico, in modo da poter individuare facilmente tendenze e picchi dell'utilizzo della memoria per tipo di oggetto.													
Come posso utilizzare le informazioni sul riepilogo dell'heap?	Il riepilogo dell'heap è utile in due scenari. Nel primo, puoi individuare potenziali perdite di memoria. Una curva di utilizzo della memoria in costante crescita per uno o più tipi di oggetti può indicare una perdita, con possibili conseguenti errori di memoria e arresti dell'applicazione. Nel secondo scenario è necessario ottimizzare la capacità della memoria dell'applicazione. In questo caso la suddivisione dell'utilizzo della memoria per tipo di oggetto ti aiuterà a sapere dove focalizzare l'attenzione. Ad esempio, sapendo che un'elevata quantità di memoria imprevista è stata associata a un tipo di oggetto specifico, puoi focalizzare l'analisi e le attività di ottimizzazione sulle parti dell'applicazione responsabili dell'allocazione degli oggetti di quel tipo e cui fanno riferimento.													
Che cos'è l'elaborazione del linguaggio naturale?		L'elaborazione del linguaggio naturale (NLP, Natural Language Processing) è il processo attraverso il quale i computer analizzano, comprendono e derivano significato da informazioni testuali in modo utile e intelligente. Utilizzando l'elaborazione del linguaggio naturale, è possibile estrarre frasi chiave, emozioni, sintassi, entità chiave, data, luogo, persone e così via, insieme alla lingua del testo.												
Che cos'è amazon comprehend?		Amazon Comprehend è un servizio di elaborazione del linguaggio naturale (NLP) che usa l'apprendimento automatico per trovare significato e informazioni nel testo.												
Che cosa è possibile fare con amazon comprehend?		Puoi usare Amazon Comprehend per identificare la lingua del testo, estrarre frasi chiave, luoghi, persone, marchi o eventi, determinare le emozioni verso prodotti o servizi e identificare gli argomenti principali da una raccolta di documenti. L'origine del testo può essere costituita da pagine Web, feed di social media, e-mail o articoli. Puoi anche inserire in Amazon Comprehend un insieme di documenti di testo, perché il servizio identifichi gli argomenti (o gruppi di parole) che rappresentano al meglio le informazioni nella raccolta. L'output di Amazon Comprehend può essere utilizzato per analizzare il feedback dei clienti, offrire un'esperienza di ricerca migliore tramite filtri di ricerca e usare argomenti per classificare i documenti.												
Come si inizia a usare amazon comprehend?		Puoi iniziare a usare Amazon Comprehend dalla console AWS. Il piano gratuito di 12 mesi inizia dal momento in cui invii la prima richiesta. Consulta la documentazione del prodotto per informazioni su come utilizzare le API di Amazon Comprehend nell'applicazione.												
Quali sono i casi d'uso più comuni per amazon comprehend?		Tra i casi d'uso più comuni sono inclusi i seguenti: Analisi della voce dei clienti: puoi determinare se le emozioni dei clienti sono positive, neutre, negative o miste in base al feedback ricevuto tramite chiamate di assistenza, e-mail, social media e altri canali online. Ricerca semantica: puoi usare Amazon Comprehend per offrire una migliore esperienza di ricerca permettendo al motore di ricerca di indicizzare frasi chiave, entità ed emozioni. In questo modo, sarà possibile concentrare la ricerca su intento e contesto degli articoli invece che sulle parole chiave. Gestione e individuazione delle informazioni: puoi analizzare una raccolta di documenti e organizzarli automaticamente in base all’argomento. Potrai quindi usare gli argomenti per personalizzare i contenuti per i clienti.												
È necessario essere esperti in elaborazione del linguaggio naturale per usare amazon comprehend?		No, non devi avere un'esperienza specifica nell'elaborazione del linguaggio naturale per usare Amazon Comprehend. Potrai semplicemente chiamare l'API di Amazon Comprehend e il servizio gestirà l'apprendimento automatico necessario per estrarre i dati pertinenti dal testo.												
Amazon comprehend è un servizio gestito?		Amazon Comprehend è un servizio completamente gestito e continuamente ottimizzato grazie al quale puoi evitare di occuparti del dimensionamento delle risorse o della manutenzione del codice e dei dati di training.												
Amazon comprehend è in grado di apprendere nel tempo?		Sì, Amazon Comprehend usa l'apprendimento automatico e viene continuamente ottimizzato per i casi d'uso.												
In quali regioni aws è disponibile amazon comprehend?		Per un elenco delle regioni AWS supportate da Amazon Comprehend, consulta la tabella delle regioni AWS per l'infrastruttura globale AWS. Per ulteriori informazioni, consulta inoltre la pagina Regioni ed endpoint nel documento AWS General Reference.												
Quali misure di sicurezza vengono applicate in amazon comprehend?		Le richieste alla console e all'API Amazon Comprehend vengono effettuate tramite una connessione sicura (SSL). Puoi utilizzare AWS Identity and Access Management (AWS IAM) per definire gli utenti IAM autorizzati ad accedere a operazioni e risorse Amazon Comprehend specifiche.												
Dove vengono memorizzati i dati?		Puoi usare Amazon Comprehend per leggere i dati da Amazon S3. Puoi anche scrivere i risultati di Amazon Comprehend in un servizio, un database o un data warehouse di storage.												
Come si determina se il servizio è in grado di elaborare i dati?		Per le API di analisi del testo, riceverai un codice di stato HTTP 200 che indica la corretta elaborazione. Se i dati non possono essere elaborati o superano i limiti del servizio, riceverai il codice di errore HTTP corrispondente.												
Come si determina se amazon comprehend restituisce risultati accurati?		Il servizio restituisce un punteggio di affidabilità per ogni risultato. Punteggi di affidabilità inferiori indicano che l'affidabilità del servizio è bassa per quanto riguarda la correttezza dei risultati. Al contrario, se il servizio è altamente affidabile, il punteggio sarà più vicino a 1.												
È possibile importare o utilizzare un modello di elaborazione del linguaggio naturale personalizzato con amazon comprehend?		No. Attualmente Comprehend non supporta modelli personalizzati.												
Quali sono i prezzi di amazon comprehend?		Per informazioni sulle fasce di prezzo e sugli sconti, consulta la pagina dei prezzi di Amazon Comprehend.												
Gli input di testo elaborati da amazon comprehend vengono memorizzati?		In che modo vengono utilizzati da AWS? Amazon Comprehend può memorizzare e utilizzare gli input di testo elaborati dal servizio esclusivamente per erogare e gestire il servizio e per sviluppare e migliorare la qualità di Amazon Comprehend e di altre tecnologie di intelligenza artificiale e di machine learning di Amazon. Questo non si applica ad Amazon Comprehend Medical. L'utilizzo dei contenuti è importante nell'ottica del costante miglioramento dell'esperienza utente di Amazon Comprehend, nonché per lo sviluppo e l'ottimizzazione di tecnologie correlate. Non usiamo alcun dato di identificazione personale eventualmente presente nei tuoi contenuti per proporre prodotti, servizi o attività marketing a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare i contenuti per migliorare e sviluppare la qualità di Amazon Comprehend e di altre tecnologie di machine learning e intelligenza artificiale di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare, consulta Gestione della policy di esclusione dei servizi di AI												
Chi ha accesso ai contenuti elaborati e memorizzati da amazon comprehend?		Solo i dipendenti autorizzati potranno accedere ai contenuti elaborati da Amazon Comprehend. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e avanzati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per maggiori informazioni, consulta le domande frequenti sulla privacy dei dati AWS.												
I contenuti elaborati e memorizzati da amazon comprehend restano di mia proprietà?		Conservi sempre la proprietà dei tuoi contenuti. Li utilizzeremo solo con il tuo consenso.												
I contenuti elaborati da amazon comprehend vengono trasferiti all'esterno della regione aws in cui viene utilizzato il servizio?		I contenuti elaborati da Amazon Comprehend vengono crittografati e memorizzati su disco nella regione AWS in cui utilizzi il servizio. Alcune parti dei contenuti elaborati da Amazon Comprehend potrebbero essere memorizzate in un'altra regione AWS esclusivamente nell'ottica del miglioramento e dello sviluppo costanti dell'esperienza utente di Amazon Comprehend e di altre tecnologie di intelligenza artificiale e apprendimento automatico. Questo non si applica ad Amazon Comprehend Medical. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e avanzati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni, consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.												
È possibile utilizzare amazon comprehend in relazione a siti web, programmi o altre applicazioni rivolti o destinati a minori di 13 anni e soggetti alle norme previste dal children's online privacy protection act (coppa)?		Sì; in conformità ai Termini del servizio Amazon Comprehend, nonché all'obbligo di fornire il necessario preavviso e ottenere l'eventuale consenso dei genitori secondo quanto prescritto dal COPPA, potrai utilizzare il servizio in relazione a siti Web, programmi o altre applicazioni rivolti o destinati, del tutto o in parte, a minori di 13 anni.												
In che modo è possibile determinare se un sito web, un'applicazione o un programma è soggetto ai termini del coppa?		Per ottenere informazioni sui requisiti del COPPA e sulle linee guida su come determinare se un sito Web, programma o applicazione è soggetta al COPPA, consulta direttamente le risorse fornite dalla United States Federal Trade Commission. Il sito offre informazioni su come determinare se un servizio è rivolto o destinato, del tutto o in parte, ai minori di 13 anni.												
Cosa è amazon fraud detector?			Amazon Fraud Detector è un servizio completamente gestito che facilita l'identificazione di potenziali attività fraudolente online come la frode dei pagamenti online e la creazione di account falsi. Amazon Fraud Detector utilizza il machine learning (ML) e 20 anni di competenza nel rilevamento delle frodi di Amazon Web Services (AWS) ed Amazon.com per identificare automaticamente attività potenzialmente fraudolente nell'arco di millisecondi. Con Amazon Fraud Detector, non sono previsti pagamenti anticipati o impegni di lungo termine né infrastrutture da gestire. Si paga solo per l'utilizzo effettivo.											
Come funziona amazon fraud detector?			"In primo luogo, dovrai specificare l'evento che vuoi analizzare a fronte di un sospetto di frode. Fatto ciò, dovrai caricare il tuo set di dati di cronologia su Amazon Simple Storage Service (Amazon S3) e selezionare il modello di rilevamento frodi, che specifica una combinazione di caratteristiche e algoritmi ottimizzati per rilevare una precisa tipologia di frode. Il servizio quindi addestrerà, testerà ed implementerà automaticamente un modello di rilevamento frodi personalizzato basato sulle tue informazioni specifiche. Durante questo processo, puoi incrementare la performance del tuo modello con una serie di modelli preaddestrati con schemi basati sull'esperienza di AWS e Amazon relativa alle frodi. Il risultato del modello è una previsione in punteggio da 0 a 1.000 che prevede la probabilità di rischio di frode. Durante la fase finale del processo, è necessario impostare una logica decisionale (per es. regole) per interpretare il punteggio del modello e assegnare i risultati come ""superato"" oppure ""invia transazione a un investigatore umano per una revisione"". Una volta creato questa framework, sarà possibile integrare l'API Amazon Fraud Detector nelle funzioni transazionali del proprio sito web, come la registrazione di account oppure i pagamenti di un ordine. Amazon Fraud Detector processerà queste attività in tempo reale e fornirà previsioni di frodi nell'arco di qualche millisecondo per consentirti di calibrare la tua esperienza di utente finale."											
Quali casi d'uso specifici sono supportati da amazon fraud detector?			Amazon Fraud Detector è progettato per i casi d'uso di frodi online che richiedono modellazione ML in tempo reale e valutazione basata su regole. Ad esempio:											
Posso personalizzare la configurazione di amazon fraud detector per il mio caso d'uso?			"Sì. Sì, è possibile personalizzare Amazon Fraud Detector per ciascun caso d'uso tramite modelli di Amazon Fraud Detector ML, modelli Amazon SageMaker e regole. Prima di tutto, raccogli tutti i dati di rischio rilevanti da usare come input di valutazione di frode. Questi comprendono indirizzi email, numeri di telefono ed indirizzi IP. Questi dati vengono immagazzinati in un modello ML, il quale produce un punteggio. Infine, puoi utilizzare regole di rilevamento per interpretare il punteggio e altri dati di rischio per prendere decisioni, come approvare o inviare l'ordine ad analisti di frode per un'investigazione ulteriore. Un esempio di una regola semplice e un risultato corrispondente potrebbero essere: “IF model_score < 50 & credit_card_country = US THEN approve_order” (""Se punteggio_modello < 50 & carta_dicredito_paese = USA ALLORA approva_ordine”)."											
Come posso attingere ai dati e all'esperienza di amazon nell'ambito di rilevamento frodi tramite amazon fraud detector?			Con 20 anni di esperienze nell'ambito frodi, Amazon ha avuto modo di vedere direttamente il comportamento di utenti malintenzionati e le diverse modalità utilizzate per commettere frodi online. Amazon Fraud Detector consente di accedere a queste conoscenze. Durante il processo automatizzato di formazione del modello, Amazon Fraud Detector usa una serie di modelli addestrati su motivi dall'esperienza di AWS e Amazon nell'ambito frode per aumentare le prestazioni del modello.											
In che modo amazon fraud detector utilizza il ml per migliorare il mio rilevamento frodi?			Amazon Fraud Detector forma, testa e distribuisce modelli di machine learning per il rilevamento frodi personalizzato sulla base della cronologia dei tuoi dati di frode, e non è necessario avere esperienza con ML. Per sviluppatori con più esperienza nel machine learning, è possibile aggiungere i propri modelli ad Amazon Fraud Detector tramite Amazon SageMaker.											
Come configuro le regole di rilevamento frodi con amazon fraud detector?			"Con Amazon Fraud Detector è possibile eseguire previsioni di frode basate su regole con e senza l'utilizzo di machine learning. Amazon Fraud Detector permette di creare regole di rilevamento (per es. ""IF model_score < 50 & credit_card_country = US THEN approve_order” (""SE punteggio_modello < 50 & carta_dicredito_paese = USA ALLORA approva_ordine”) tramite un linguaggio basato sulla scrittura semplice di regole. È inoltre possibile specificare l'ordine di attivazione delle regole durante una valutazione tramite un'interfaccia intuitiva."											
Il mio team può vedere le valutazioni di frodi tramite amazon fraud detector?			Sì, è possibile rivedere le valutazioni di frodi passate per effettuare auditing sulla logica di decisione tramite la console di Amazon Fraud Detector. Nella console di Amazon Fraud Detector, è possibile cercare gli eventi passati sulla base delle caratteristiche dell'evento e/o della logica di rilevamento applicata, come il risultato, i modelli o le regole usate, o persino i metadati. Poi si procederà ad eseguire il drill-down per scoprire come una logica di rilevamento ha valutato un evento.											
Amazon fraud detector condivide i miei dati di rischio e le mie decisioni di rischio con altre imprese?			No. La sicurezza e la privacy sono le nostre principali preoccupazioni. È un principio fondamentale per l'acquisizione della fiducia del cliente: AWS non condividerà mai i dati del cliente.											
Cos'è amazon kendra?				"Amazon Kendra è un servizio aziendale di ricerca estremamente accurato e facile da utilizzare, basato sul machine learning (ML). Kendra permette agli sviluppatori di aggiungere funzionalità di ricerca alle loro applicazioni, in modo che i loro utenti finali possano scoprire le informazioni archiviate all'interno della grande quantità di contenuti sparsi nella loro azienda. Tali dati provengono da manuali, report di ricerca, domande frequenti, documentazione delle risorse umane (HR) e guide al servizio clienti, che si possono trovare in diversi sistemi come Amazon Simple Storage Service (S3), Microsoft SharePoint, Salesforce, ServiceNow, database di RDS o Microsoft OneDrive. Quando si digita una domanda, il servizio utilizza algoritmi di ML per comprendere il contesto e restituire i risultati più pertinenti, che si tratti di una risposta precisa o di un intero documento. Ad esempio, puoi porre una domanda del tipo ""Quanto è la ricompensa in contanti sulla carta di credito aziendale?"" e Amazon Kendra mapperà i documenti pertinenti e restituirà una risposta specifica (come ""2%""). Kendra fornisce un codice di esempio in modo da poter iniziare rapidamente e integrare facilmente una ricerca estremamente accurata nelle applicazioni nuove o esistenti."										
In che modo amazon kendra si integra con altri servizi aws?				Amazon Kendra offre funzionalità di ricerca basate su ML per tutti i dati non strutturati che archivi in AWS. Amazon Kendra offre connettori nativi facili da utilizzare ai più diffusi tipi di repository AWS popolari come database Amazon S3 e Amazon RDS. Altri servizi di intelligenza artificiale come Amazon Comprehend, Amazon Transcribe e Amazon Comprehend Medical possono essere utilizzati per pre-elaborare documenti, generare testo ricercabile, estrarre entità e arricchire metadati per esperienze di ricerca più specializzate.										
Quali tipi di domande posso porre ad amazon kendra?														
Cosa succede se i miei dati non contengono la risposta precisa che amazon kendra sta cercando?				Quando i tuoi dati non contengono una risposta precisa a una domanda, Amazon Kendra restituisce un elenco dei documenti più rilevanti classificati in base ai suoi modelli di deep learning.										
A quali tipi di domande amazon kendra non sarà in grado di rispondere?				Amazon Kendra non supporta ancora domande per le quali le risposte richiedono aggregazioni o calcoli tra passaggi di vari documenti.										
Come posso iniziare a lavorare con amazon kendra?				"La console di Amazon Kendra offre il modo più semplice per iniziare. Puoi indicare ad Amazon Kendra documenti non strutturati e semi-strutturati, come le domande frequenti archiviate in Amazon S3. Dopo l'inserimento, puoi iniziare a testare Kendra digitando le query direttamente nella sezione ""cerca"" della console. In seguito puoi implementare la ricerca di Amazon Kendra in due semplici modalità: (1) tramite l'editor grafico dell'IU nell'Experience Builder (non occorre alcun codice) oppure (2) implementando l'API di Amazon Kendra tramite qualche riga di codice per avere un controllo più accurato. Nella console sono presenti anche codici di esempio per velocizzare l'implementazione della API."										
Come posso personalizzare amazon kendra per adattarlo meglio al settore della mia azienda o all'attività aziendale?				Amazon Kendra offre competenze specifiche per settori quali: IT, farmaceutico, assicurativo, energetico, industriale, servizi finanziari, giuridico, media e intrattenimento, turistico e alberghiero, sanitario, risorse umane, notizie, telecomunicazioni e automobilistico. Puoi perfezionare ulteriormente ed estendere la comprensione specifica del dominio di Kendra fornendo i tuoi elenchi di sinonimi. Devi solo caricare un file con la tua terminologia specifica e Amazon Kendra utilizzerà questi sinonimi per arricchire le ricerche degli utenti.										
Quali tipi di file supporta amazon kendra?				Amazon Kendra supporta dati non strutturati e semi-strutturati in formato .html, MS Office (.doc, .ppt), PDF e testo. Con la soluzione MediaSearch, puoi anche usare Amazon Kendra per cercare file audio e video.										
In che modo amazon kendra gestisce gli aggiornamenti incrementali dei dati?				Amazon Kendra fornisce due metodi per mantenere aggiornato il tuo indice. Innanzitutto, i connettori forniscono la pianificazione per sincronizzare le origini dati automaticamente e in modo regolare. In secondo luogo, l'API di Amazon Kendra ti permette di creare il tuo connettore per inviare i dati direttamente ad Amazon Kendra dall'origine dati tramite i tuoi lavori ETL o applicazioni esistenti.										
Quali lingue supporta amazon kendra?				Per informazioni sul supporto linguistico, consulta la pagina della documentazione.										
Quali modifiche al codice sono necessarie per utilizzare amazon kendra?				L'inserimento di contenuti non richiede la codifica quando si utilizzano i connettori nativi. Puoi anche scrivere i tuoi connettori personalizzati per integrarli con altre origini dati, usando il kit SDK di Amazon Kendra. In seguito puoi implementare la ricerca di Amazon Kendra in due semplici modalità: (1) tramite l'editor grafico dell'IU nell'Experience Builder (nessun codice richiesto) oppure (2) implementando l'API di Kendra tramite qualche riga di codice per avere maggiore flessibilità. Nella console sono presenti anche codici di esempio per velocizzare l'implementazione della API. Il kit SDK offre pieno controllo e flessibilità dell'esperienza dell'utente finale.										
In quali regioni è disponibile amazon kendra?				Consulta la pagina sui Servizi AWS per regione per maggiori dettagli.										
Posso aggiungere connettori personalizzati?				Puoi scrivere i tuoi connettori tramite l'API Amazon Kendra Custom Data Source. Inoltre Amazon Kendra ha un ecosistema di partner esperti nella ricerca che può aiutare a costruire connettori attualmente non disponibili in AWS. Per maggiori dettagli sulla nostra rete di partner, contattaci.										
In che modo amazon kendra gestisce la sicurezza?				Amazon Kendra crittografa i tuoi dati in transito e inattivi. Sono disponibili tre opzioni per le chiavi di crittografia per i dati a riposo: chiave master KMS di proprietà AWS, KMS gestito da AWS nel proprio account oppure una chiave KMS gestita dal cliente. Per i dati in transito, Amazon Kendra utilizza il protocollo HTTPS per comunicare con l'applicazione client. Le chiamate API per accedere ad Amazon Kendra attraverso la rete utilizzano il protocollo Transport Layer Security (TLS) che deve essere supportato dal client.										
Amazon kendra può trovare risposte dal contenuto delle registrazioni audio e video?				Sì, la soluzione MediaSearch  combina Amazon Kendra con Amazon Transcribe e abilita gli utenti a cercare risposte pertinenti incorporate nei contenuti audio e video.										
Cos'è amazon lex?					Amazon Lex è un servizio per la creazione di interfacce di comunicazione tramite voce e testo. Amazon Lex è basato sullo stesso motore di comunicazione di Alexa e dispone di funzionalità di riconoscimento vocale e comprensione del linguaggio di alto livello, consentendo così l'aggiunta di chatbot dotati di linguaggio naturale in applicazioni sia nuove sia esistenti. Riducendo le complessità correlate allo sviluppo multipiattaforma, Amazon Lex consente di pubblicare più facilmente chatbot vocali o di testo su dispositivi mobili e servizi di chat, tra cui Facebook Messenger, Slack, Kik e Twilio SMS. Lo sviluppo di bot è rapido e semplice, grazie all'interoperabilità nativa con AWS Lambda e Amazon CloudWatch e alla facilità di integrazione con molti altri servizi sulla piattaforma AWS, tra cui Amazon Cognito e Amazon DynamoDB.									
Che cosa occorre per iniziare a utilizzare amazon lex?					"Per iniziare a usare Amazon Lex, accedi alla Console di gestione AWS e cerca ""Lex"" nella categoria ""Artificial Intelligence"" (Intelligenza Artificiale). Per procedere, è necessario disporre di un account Amazon Lex. Se non ne hai già uno, ti verrà richiesto di creare un account durante la procedura di registrazione. Per ulteriori informazioni, consulta la Guida alle operazioni di base di Amazon Lex V2."									
Quali sono i casi d'uso più comuni per amazon lex?					I casi d'uso più comuni sono:									
Come funziona amazon lex con altri servizi aws?					Amazon Lex sfrutta AWS Lambda per l'adempimento degli intenti, Amazon Cognito per l'autenticazione degli utenti e Amazon Polly per le funzioni di sintesi vocale.									
Per usare amazon lex devo essere un esperto di machine learning?					Per usare Amazon Lex non è necessaria alcuna esperienza nel campo del machine learning. Gli sviluppatori dovranno solo definire il flusso della conversazione a livello di dichiarazione, mentre il riconoscimento vocale e la comprensione del linguaggio naturale saranno a carico di Amazon Lex. Gli sviluppatori potranno fornire alcune enunciazioni campione nella lingua desiderata e i messaggi di richiesta agli utenti per ottenere i diversi parametri (slot) necessari. Il modello linguistico viene creato automaticamente.									
In quali regioni aws è disponibile amazon lex?					Per un elenco completo delle Regioni AWS in cui è supportato Amazon Lex, consulta la tabella delle Regioni AWS  per l'intera infrastruttura globale AWS. Per ulteriori informazioni, consulta inoltre la pagina Regioni ed Endpoint nei riferimenti generali di AWS.									
Qual è la larghezza di banda massima supportata da amazon lex?					Amazon Lex si adatta alle esigenze degli utenti e non impone vincoli di larghezza di banda.									
Amazon lex è un servizio gestito?					Amazon Lex è un servizio completamente gestito e non richiede quindi la gestione del ridimensionamento delle risorse o la manutenzione di codice. Il backup dello schema di interazione e dei modelli delle lingue viene eseguito automaticamente. Sono inoltre disponibili funzioni complete di controllo delle versioni, per semplificare un eventuale rollback. L'architettura di Amazon Lex non richiede l'esecuzione di operazioni di archiviazione o backup dei dati degli utenti finali. In quali casi si usa Amazon Polly anziché Amazon Lex? Amazon Polly esegue la sintesi vocale di input di testo. Amazon Lex è un servizio per la creazione di interfacce di comunicazione tramite voce e testo.									
Amazon lex diventa più intelligente nel tempo?					Sì. Amazon Lex migliora nel tempo, grazie alla tecnologia di apprendimento profondo.									
Come si crea un bot in amazon lex?					"Per creare un bot è innanzitutto necessario definire le operazioni che deve eseguire. Tali operazioni sono definite ""intenti"" che devono essere realizzati dal bot. Per ciascun intento è necessario definire slot ed enunciazioni di esempio. Le enunciazioni sono frasi che richiamano l'intento. Gli slot sono dati di input necessari per adempiere l'intento. È infine necessario fornire la logica di business necessaria per l'esecuzione dell'azione. È possibile creare un bot di Amazon Lex sia tramite console che tramite API REST."									
Posso implementare la logica di business nel client?					Sì. Amazon Lex consente di restituire intento e slot analizzati al client per l'implementazione della logica di business.									
Come si esegue la convalida dell'input dell'utente?					Grazie alla totale integrazione con AWS Lambda, Amazon Lex consente di convalidare l'input dell'utente tramite codeHook di inizializzazione e convalida. Questo codice viene eseguito a ogni passaggio della conversazione. È possibile usare codeHook per impostare i parametri della sessione, convalidare l'input dell'utente e personalizzare le risposte.									
Cos'è un intento?					"Per creare un bot di Amazon Lex, è necessario identificare un set di operazioni, definite ""intenti"", che il bot dovrà realizzare. Un bot può comprendere più intenti. Ad esempio, il bot ""PrenotazioneBiglietti"" può avere l'intento di effettuare, annullare e rivedere le prenotazioni."									
Cos'è un'enunciazione?					"Un'enunciazione è una frase pronunciata o scritta che richiama un intento. Ad esempio, per richiamare un intento volto ad effettuare prenotazioni, è possibile definire un'enunciazione di esempio come ""Posso effettuare una prenotazione?""."									
Che cosa sono gli slot?					"Per adempiere un intento, un bot di Amazon Lex ha bisogno di informazioni fornite dall'utente. Queste informazioni vengono acquisite in ""slot"". Ad esempio, il titolo e l'ora di uno spettacolo potrebbero essere definiti come slot per l'intento di effettuare prenotazioni."									
Che cosa sono i messaggi di richiesta?					"Amazon Lex ricava i valori degli slot utilizzando i messaggi di richiesta corrispondenti. Ad esempio, per ricavare il valore dello slot ""ora"" è necessario definire un messaggio di richiesta quale ""Quale orario desidera prenotare?"". Amazon Lex è in grado di ricavare i valori di più slot tramite una conversazione in più passaggi."									
Come si adempie un'azione?					Per l'adempimento di azioni o della logica di business Amazon Lex si integra con AWS Lambda. In alternativa, per l'adempimento di azioni è possibile configurare Amazon Lex in modo che restituisca al client intento e valori degli slot analizzati.									
Come si esegue il monitoraggio e il tracciamento di un bot?					"È possibile tenere traccia dei parametri per il bot nel pannello di controllo ""Monitoraggio"" nella console di Amazon Lex. Al momento è possibile tenere traccia del numero di enunciazioni perse, della latenza delle richieste e del traffico per canale. È possibile consultare un elenco di enunciazioni non riconosciute dal bot, dette anche ""enunciazioni perse"". Grazie alle funzionalità di monitoraggio, è possibile assistere in che modo gli utenti interagiscono con il bot per migliorarlo."									
Come si usa la progettazione automatizzata di chatbot?					La progettazione automatizzata di chatbot ti aiuta a creare un modello di bot in pochi clic. Per prima cosa fornisci un collegamento alla posizione S3 che contiene le trascrizioni delle conversazioni tramite la console Lex (o SDK). Tramite la progettazione automatizzata di chatbot queste trascrizioni verranno poi elaborate per creare un modello di chatbot che includa gli intenti dell'utente, frasi di esempio associate a tali intenti e un elenco di tutte le informazioni necessarie per soddisfarli. Puoi quindi rivedere i risultati forniti dalla progettazione automatizzata di chatbot e aggiungere gli intenti e i tipi di slot più adatti al tuo bot.									
Quali formati di trascrizione sono supportati dalla progettazione automatizzata di chatbot?					Le trascrizioni devono contenere conversazioni tra un chiamante e un agente in formato JSON standard. Una trascrizione di esempio in questo formato è disponibile nella documentazione di Amazon Lex. I clienti di Amazon Connect che utilizzano Contact Lens possono utilizzare direttamente le trascrizioni delle conversazioni nel loro formato originale. Le trascrizioni delle conversazioni da altri servizi di trascrizione possono richiedere una semplice conversione. Dettagli sul processo di conversione sono disponibili qui.									
Quali lingue sono supportate dalla progettazione automatizzata di chatbot?					La progettazione automatizzata di chatbot supporta tutte le versioni della lingua inglese (inglese americano, britannico, australiano, indiano e sudafricano) supportate da Amazon Lex. In anteprima, la progettazione automatizzata di chatbot supporta l'inglese americano.									
Cosa succede quando si crea un bot?					La creazione di un bot attiva l'apprendimento automatico e crea i modelli per il bot stesso, nonché una nuova versione degli intenti e dei tipi di slot. Una volta creata, una versione è immutabile.									
Come si esegue il test di un bot di amazon lex?					È possibile testare un bot di Amazon Lex tramite l'apposita finestra nella console. In questa console è possibile eseguire anche il test della logica di business implementata in AWS Lambda. Il testing dei testi per il bot di Amazon Lex è consentito su tutti i browser supportati; i messaggi vocali possono essere testati esclusivamente in Chrome.									
Come si creano i bot di amazon lex per dispositivi mobili?					Amazon Lex mette a disposizione kit SDK per iOS e Android. Questi kit consentono di sviluppare bot per i casi d'uso dei dispositivi mobili. L'autenticazione dell'utente può essere abilitata tramite Amazon Cognito.									
Come si rendono disponibili i bot di amazon lex all'interno di servizi di messaggistica?					È possibile pubblicare i bot di Amazon Lex all'interno di piattaforme di messaggistica, ad esempio Facebook Messenger, Slack, Kik e Twilio SMS. Per pubblicare il bot puoi fornire i token di autenticazione all'interno della console; AWS li archivierà in modo sicuro e fornirà un URL di callback, che a tua volta potrai fornire al servizio di chat.									
È necessario sottoporre un bot a certificazione prima di distribuirlo?					Non è necessario ottenere la certificazione Amazon di un bot prima di distribuirlo.									
È possibile distribuire una versione di un bot di amazon lex agli utenti finali pur continuando a sviluppare una versione diversa?					Sì. È possibile creare una build e distribuire una versione del bot in produzione mentre è in corso lo sviluppo di una versione differente. Ogni versione dei bot di Amazon Lex è dotata di un codice ARN. Ogni versione può essere associata a un alias diverso. È possibile utilizzare questi strumenti per configurare ambienti di sviluppo, gestione temporanea e produzione.									
È possibile scegliere di distribuire versioni diverse a servizi di messaggistica diversi?					Sì. È possibile distribuire una versione specifica a ciascun servizio di messaggistica. Ogni versione di Amazon Lex è dotata di un codice ARN. Ogni versione può essere associata a un alias diverso. Per la distribuzione a servizi di messaggistica diversi puoi utilizzare alias diversi. È anche possibile distribuire più bot nello stesso servizio di messaggistica.									
Qual è la durata massima dell'input vocale?					I bot di Amazon Lex sono progettati per un'interazione di richiesta e risposta o una conversazione in streaming continuo. Con l'interazione di richiesta e risposta, Amazon Lex supporta fino a 15 secondi di input vocale. In una conversazione in streaming, tutti gli input dell'utente attraverso più passaggi vengono elaborati in una chiamata API in streaming che supporta fino a 15 secondi di input vocale, incluso il silenzio.									
È possibile eseguire una configurazione per input vocale e output di testo?					Sì, è possibile scegliere l'interfaccia API PostContent per fornire input vocale e scegliere l'output di testo.									
Quante lingue supporta amazon lex?					Attualmente, Amazon Lex supporta le seguenti lingue: inglese americano, spagnolo, francese, tedesco, italiano, giapponese, inglese australiano, inglese britannico, francese canadese, spagnolo latinoamericano e spagnolo americano.									
Quali formati audio supporta amazon lex?					Amazon Lex supporta i formati di input audio LPCM e Opus e i formati di output audio MPEG, OGG e PCM.									
È possibile utilizzare amazon lex in vpc?					È possibile accedere ad Amazon Lex da VPC tramite endpoint pubblici per creare ed eseguire un bot. Al momento, Amazon Lex non è dotato di un endpoint VPC.									
È possibile accedere ai bot di amazon lex in locale, ovvero senza una connessione internet?					No, non è possibile. Gli utenti finali devono accedere all'endpoint di runtime di Amazon Lex via Internet.									
Quali sono i miglioramenti in termini di usabilità offerti nella console migliorata v2 e nelle api?					La console e le API di Lex V2 utilizzano un'architettura dell'informazione (IA, information architecture) aggiornata per fornire un controllo delle versioni semplificato, supporto di più lingue in un bot e capacità di streaming. Ulteriori miglioramenti includono il salvataggio di configurazioni bot parzialmente completate, la ridenominazione delle risorse, la navigazione semplificata, il caricamento in blocco delle enunciazioni e il debug granulare.									
Come posso utilizzare la capacità di streaming?					"Puoi utilizzare l'API di streaming per condurre una conversazione in streaming continuo con un bot Lex. Con la conversazione in streaming, il bot ascolta in modo continuo e può essere progettato per rispondere in modo proattivo alle interruzioni e alle pause dell'utente. Ad esempio, puoi configurare il bot per continuare una conversazione quando un utente ha bisogno di più tempo per rispondere inviando messaggi periodici come ""Fai con calma. Fammi sapere quando sei pronto""."									
Quali sono i dettagli sui prezzi per le api v2?					I bot di Amazon Lex sono progettati per un'interazione di richiesta e risposta o una conversazione in streaming continuo. Con l'interazione di richiesta e risposta, ogni input dell'utente (voce o testo) viene elaborato come una chiamata API separata. In una conversazione in streaming, tutti gli input dell'utente attraverso più turni vengono elaborati in una chiamata API in streaming. Per ulteriori informazioni, consulta la pagina dei prezzi di Amazon Lex.  D: È possibile integrare i bot creati utilizzando le API V2 con i flussi di contatti di Amazon Connect? Sì, i flussi di contatti di Amazon Connect funzionano sia con Lex V2 che con le API V1. È possibile utilizzare la console Lex V2 per creare e integrare bot con Amazon Connect.									
Posso sfruttare le funzionalità api v2 per i miei bot esistenti?					No, se vuoi sfruttare i vantaggi delle funzionalità V2, dovrai ricreare il tuo bot all'interno delle API V2. Le API di Lex V1 non sono compatibili perché le API V2 utilizzano un'architettura dell'informazione aggiornata per consentire un controllo delle versioni delle risorse semplificato e il supporto di più lingue all'interno di un bot. La conversione alle API V2 è semplice, quindi inizia a usarle grazie a questa guida alla migrazione dettagliata.									
Quali regioni e lingue supportano le api v2?					Le API V2 di Amazon Lex e l'esperienza d'uso della console migliorata sono disponibili in tutte le 8 Regioni e lingue esistenti, tra cui inglese americano, spagnolo, francese, tedesco, italiano, giapponese, inglese australiano, inglese britannico, francese canadese, spagnolo latinoamericano e spagnolo americano. Per un elenco completo delle Regioni AWS supportate da Amazon Lex, consulta la tabella delle Regioni AWS.									
Il supporto delle nuove funzionalità come il controllo delle versioni semplificato e le lingue multiple in un bot sarà disponibile nelle api esistenti?					No, queste funzionalità sono disponibili solo nelle API V2. Se vuoi sfruttare i vantaggi di queste caratteristiche, puoi effettuare la migrazione alle API V2 seguendo questa guida alla migrazione.									
Potrò accedere alla console v1?					Sì, puoi accedere alla console V1 dalla Console di gestione AWS. Una volta nella console Lex, puoi navigare tra la console V1 e V2. I bot creati nella console V1 saranno visibili solo all'interno della console V1. Non potrai accedere ai tuoi bot V1 nella console V2 finché non li ricreerai nella console V2. Effettuare la migrazione dei tuoi bot a V2 è semplice, ecco una guida alla migrazione dettagliata.									
Come accedo alla console v2?					Puoi fare clic sul link nella barra di navigazione sinistra per scegliere la tua console tra V1 o V2.									
Posso ancora usare le api di lex v1?					Sì. Le API di Lex V1 esistenti sono ancora supportate. Puoi continuare a usarle per creare e condurre le tue conversazioni con il bot.									
Quali sono le differenze rispetto ad alexa skills kit?					Alexa Skills Kit (ASK) consente di creare competenze da utilizzare nell'ecosistema e nei dispositivi Alexa. Gli sviluppatori possono sfruttare tutte le funzionalità di Alexa, ad esempio l'interfaccia API Smart Home e Flash Briefing, audio in streaming e interfacce grafiche utente ricche di funzionalità. I bot di Amazon Lex consentono di utilizzare sia voce che testo e possono essere distribuiti sia su piattaforme per dispositivi mobili che di messaggistica.									
Per richiamare un intento di amazon lex mi serve una parola di attivazione?					"Amazon Lex non supporta la funzionalità di attivazione tramite parola. L'attivazione del microfono, ad esempio con una funzione ""premi per parlare"", dipenderà dell'app che si integra con Amazon Lex."									
Un bot di amazon lex può rispondere con la voce di alexa?					Al momento, la voce di Alexa non è supportata per le risposte di Amazon Lex. Sono tuttavia disponibili altre 7 voci tra cui scegliere.									
È possibile creare una competenza alexa da un bot di amazon lex?					"Amazon Lex offre la possibilità di esportare uno schema di bot Amazon Lex in un file JSON compatibile con Amazon Alexa. Una volta disponibile il file JSON, è necessario eseguire l'accesso al portale per sviluppatori di Alexa, selezionare la scheda ""Interaction Model"" (Modello di interazione), avviare Alexa Skill Builder e copiare lo schema di bot nell'editor di codice.&nbsp; Per ulteriori dettagli, consulta la documentazione di Amazon Lex."									
Quando uno schema di bot di amazon lex viene esportato per utilizzarlo come competenza alexa, vengono esportate e incluse anche le funzioni aws lambda collegate?					No. Viene scaricata solo la definizione di bot.									
Ho creato una competenza alexa da un bot di amazon lex utilizzando la caratterista di esportazione. quali piattaforme di alexa supportano lo schema di bot di amazon lex?					Possono essere utilizzate tutte le piattaforme Alexa che supportano le competenze: The Amazon Echo, Amazon Dot, Amazon Look, Amazon Tap, Amazon Echo Show e qualsiasi dispositivo di terze parti compatibile con Alexa.									
Gli input vocali e di testo elaborati da amazon lex vengono archiviati?					In che modo li utilizza AWS? Amazon Lex può archiviare e utilizzare gli input vocali e di testo elaborati dal servizio esclusivamente per fornire e mantenere il servizio, oltre che per migliorare e sviluppare la qualità di Amazon Lex e di altre tecnologie di machine learning/intelligenza artificiale di Amazon. L'utilizzo dei contenuti è necessario nell'ottica di costante miglioramento dell'esperienza utente del servizio Amazon Lex, nonché per lo sviluppo e la formazione di tecnologie correlate. Non usiamo alcun dato di identificazione personale eventualmente presente nei tuoi contenuti per proporre prodotti, servizi o attività marketing a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare i contenuti per migliorare e sviluppare la qualità di Amazon Lex e di altre tecnologie di machine learning e intelligenza artificiale di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare esplicitamente, consulta Gestione della politica di esclusione dei servizi di IA.									
È possibile eliminare gli input vocali e di testo archiviati da amazon lex?					Sì. Puoi richiedere l'eliminazione degli input vocali e di testo associati al tuo account contattando il servizio di esclusione. L'eliminazione degli input vocali e di testo potrebbe comportare il peggioramento dell'esperienza Amazon Lex. Per ulteriori informazioni su come rifiutare esplicitamente, consulta Gestione della politica di esclusione dei servizi di IA.									
Chi avrà accesso ai contenuti elaborati e memorizzati da amazon lex?					Solo i dipendenti autorizzati potranno accedere ai contenuti elaborati da Amazon Lex. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.									
I contenuti elaborati e memorizzati da amazon lex rimangono di mia proprietà?					Conservi sempre la proprietà dei tuoi contenuti. Li utilizzeremo solo con il tuo consenso.									
I contenuti elaborati da amazon lex vengono trasferiti all'esterno della regione aws in cui è in uso il servizio?					I contenuti elaborati da Amazon Lex vengono crittografati e memorizzati su disco nella regione AWS in cui è in uso il servizio. I contenuti elaborati da Amazon Lex possono essere parzialmente archiviati in un'altra regione AWS esclusivamente per finalità di costante miglioramento e sviluppo della tua esperienza di cliente Amazon Lex e di altre tecnologie di apprendimento automatico/intelligenza artificiale di Amazon. Puoi richiedere l'eliminazione degli input vocali e di testo associati al tuo account contattando AWS Support. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.									
È possibile utilizzare amazon lex in connessione con siti web, programmi o altre applicazioni rivolte o destinate a minori di 13 anni e soggette alle norme previste dal children's online privacy protection act (coppa)?					Sì; in conformità con i Termini del servizio Amazon Lex, nonché adempiuto l'obbligo di fornire il necessario preavviso e ottenuto l'eventuale consenso dei genitori secondo quanto prescritto dal COPPA, sarà possibile utilizzare Amazon Lex in connessione con siti Web, programmi o altre applicazioni rivolte o destinate, del tutto o in parte, ai minori di 13 anni. Amazon Lex non memorizza né conserva informazioni relative a enunciazioni vocali o di testo da siti Web, programmi o applicazioni identificate dal cliente in conformità con i Termini del servizio Amazon Lex rivolte o destinate, del tutto o in parte, ai minori di 13 anni.									
In che modo è possibile determinare se un sito web, un programma o un'applicazione sono soggetti al coppa?					Per ottenere informazioni sui requisiti del COPPA e linee guida su come determinare se un sito Web, programma o applicazione è soggetta al COPPA, consulta direttamente le risorse fornite dalla United States Federal Trade Commission. Il sito offre informazioni su come determinare se un servizio è rivolto o destinato, del tutto o in parte, ai minori di 13 anni.		Per ottenere informazioni sui requisiti del COPPA e linee guida su come determinare se un sito Web, programma o applicazione è soggetta al COPPA, consulta direttamente le risorse fornite dalla United States Federal Trade Commission. Il sito offre informazioni su come determinare se un servizio è rivolto o destinato, del tutto o in parte, ai minori di 13 anni.		Per ottenere informazioni sui requisiti del COPPA e indicazioni per determinare se un sito Web, un programma o un'applicazione sono soggetti al COPPA, consulta direttamente le risorse fornite dalla Federal Trade Commission degli Stati Uniti. Il sito offre informazioni su come determinare se un servizio è rivolto o destinato, del tutto o in parte, ai minori di 13 anni.	Per ottenere informazioni sui requisiti del COPPA e linee guida su come determinare se un sito Web, programma o applicazione è soggetta al COPPA, consulta direttamente le risorse fornite dalla United States Federal Trade Commission. Il sito offre informazioni su come determinare se un servizio è rivolto o destinato, del tutto o in parte, ai minori di 13 anni.				
Quali kit sdk sono supportati da amazon lex?					Amazon Lex supporta al momento i kit SDK per servizi di runtime. I kit SDK per iOS e Android supportano input sia di testo sia vocali; lo stesso vale per Java, JS, Python, CLI, .Net, Ruby, PHP, Go e CPP.									
È possibile usare kit sdk per la creazione di bot?					Per creare un bot è possibile impiegare diversi kit SDK: Java, JavaScript, Python, CLI, .NET, Ruby on Rails, PHP, Go e CPP.									
Che tipo di supporto è disponibile per amazon lex?					A seconda del contratto AWS Support scelto, per Amazon Lex sono disponibili i piani di supporto Developer, Business ed Enterprise. &nbsp;Puoi anche pubblicare le tue domande sui forum Amazon Lex.									
In che modo amazon lex conta il numero di richieste?					Ogni input in un bot di Amazon Lex viene contato come richiesta. Ad esempio, se un utente finale effettua cinque input nel bot nell'ambito di una conversazione, vengono fatturate cinque richieste. L'utilizzo viene calcolato e fatturato per richiesta.									
Quanto costa amazon lex?					Inizia con il piano gratuito di AWS. Per informazioni aggiornate sui prezzi, consulta la pagina dei prezzi di Amazon Lex.									
Amazon lex fa parte del piano gratuito di aws?					Sì. Prova Amazon Lex gratis. Dalla data di registrazione all'utilizzo del servizio Amazon Lex, potrai elaborare fino a 10.000 richieste di testo e 5.000 richieste vocali al mese gratuitamente per un anno.									
Cos'è amazon personalize?						Amazon Personalize è un servizio di machine learning (ML) completamente gestito che utilizza i tuoi dati per generare suggerimenti su prodotti e contenuti per i tuoi utenti. Fornisci dati sui tuoi utenti finali (ad esempio età, posizione, tipo di dispositivo), sugli articoli del tuo catalogo (ad esempio genere, prezzo) e sulle interazioni tra utenti e articoli (ad esempio clic, acquisti). Personalize utilizza questi dati per addestrare modelli privati personalizzati che generano raccomandazioni che possono essere visualizzate tramite un'API. Il servizio utilizza algoritmi per analizzare il comportamento dei clienti e consigliare prodotti, contenuti e servizi che potrebbero interessarli. Questo approccio migliorato all'esperienza del cliente può aumentare il coinvolgimento, la fidelizzazione e le vendite dei clienti, il che può portare a un aumento dei ricavi e della redditività. Personalize è basato sulla stessa tecnologia ML utilizzata da Amazon.com e consente a qualsiasi sviluppatore di aggiungere facilmente personalizzazioni ad applicazioni, siti Web, notifiche push, comunicazioni di marketing e altro ancora esistenti, il tutto senza richiedere alcuna esperienza di machine learning. Personalize utilizza informazioni sui dati in tempo reale per fornire suggerimenti personalizzati istantaneamente in base al comportamento dell'utente. Puoi iniziare rapidamente con raccomandazioni ottimizzate per i casi d'uso per il tuo dominio aziendale oppure puoi creare risorse personalizzate configurabili.								
Quali sono i vantaggi dell'uso di amazon personalize?						Ecco alcuni motivi per cui le aziende scelgono Amazon Personalize per la personalizzazione:								
In che modo le aziende utilizzano amazon personalize?						Amazon Personalize può essere utilizzato per personalizzare l'esperienza dell'utente finale su qualsiasi canale digitale. Gli esempi includono consigli sui prodotti per l'e-commerce, articoli di notizie, pubblicazioni, media e social network, consigli sugli hotel per i siti Web di viaggi, raccomandazioni per le carte di credito per le banche e suggerimenti per gli abbinamenti sui siti di incontri. Amazon Personalize può essere utilizzato anche per personalizzare l'esperienza dell'utente quando la sua interazione avviene su un canale fisico, ad esempio un'azienda di consegna pasti potrebbe personalizzare il pasto settimanale degli utenti in un piano di abbonamento. Di seguito sono riportati altri esempi di casi d'uso. Consulta le referenze dei nostri clienti per scoprire storie di successo reali.								
Come posso provare rapidamente amazon personalize?						Dai un'occhiata a Magic Movie Machine, un breve gioco interattivo in cui cerchi consigli sui film che soddisfino i tuoi interessi personali. Scopri in prima persona come Amazon Personalize impara ciò che ti piace e quindi ottimizza i suggerimenti per te in tempo reale. Avvia la demo ora.								
Come funziona amazon personalize?						Amazon Personalize prevede un semplice processo in tre fasi, che richiede solo pochi clic nella Console di gestione AWS o una serie di semplici chiamate API. Innanzitutto, indica ad Amazon Personalize i tuoi dati di interazione utente (log storico di visualizzazioni, clic, acquisti, ecc.) in Amazon S3, carica i dati utilizzando una semplice chiamata API o usa SageMaker Data Wrangler per preparare e importare i tuoi dati. Se lo desideri, puoi fornire un set di dati sugli articoli o sugli utenti che contenga informazioni aggiuntive sul tuo catalogo e sulla tua base di clienti. In secondo luogo, con pochi clic nella console o con una chiamata API, puoi addestrare un modello di raccomandazione privato personalizzato per i tuoi dati. infine, recupera suggerimenti personalizzati. Guarda questa serie di video di approfondimento di Amazon Personalize per saperne di più.								
Come posso iniziare a usare amazon personalize?						Inizia creando un account e accedendo alla console per gli sviluppatori Amazon Personalize, che li guida attraverso una procedura di installazione intuitiva. Potrai scegliere se usare un'API JavaScript e un SDK lato server per inviare dati del flusso di attività in tempo reale ad Amazon Personalize o se eseguire il processo di bootstrap utilizzando un registro cronologico degli eventi utenti. Puoi anche importare i tuoi dati tramite Amazon Simple Storage Service (S3) o utilizzando SageMaker Data Wrangler. Quindi, con poche chiamate API, puoi addestrare un modello di personalizzazione, consentendo al servizio di scegliere l'algoritmo appropriato per il tuo set di dati con AutoML, oppure possono scegliere manualmente una delle numerose opzioni dell'algoritmo disponibili. Una volta addestrati, i modelli possono essere distribuiti con un'unica chiamata API e possono quindi essere utilizzati dalle applicazioni di produzione. Una volta che sono stati distribuiti, gli sviluppatori chiamano l'assistenza dai loro servizi di produzione per ricevere suggerimenti in tempo reale e Amazon Personalize si calibrerà automaticamente per soddisfare la domanda.								
Quali sono i dati che devo fornire ad amazon personalize?						Gli utenti devono fornire i seguenti dati ad Amazon Personalize: Amazon Personalize addestrerà e distribuirà un modello basato su questi dati. Puoi quindi utilizzare una semplice API di inferenza per ottenere suggerimenti personalizzati al runtime e generare un'esperienza personalizzata per gli utenti finali in base al tipo di modello di personalizzazione (ad esempio, personalizzazione utente, articoli correlati o riclassificazione personalizzata). I seguenti dati possono contribuire a migliorare la pertinenza delle tue raccomandazioni e ti consigliamo vivamente di includere: Per ulteriori informazioni sui tipi di dati che Amazon Personalize può utilizzare, consulta Tipi di dati che puoi importare in Amazon Personalize.								
Come posso importare i miei dati utilizzando sagemaker datawrangler?						"Amazon Personalize semplifica l'importazione e la preparazione dei dati tramite Amazon SageMaker Data Wrangler prima di utilizzarli in Amazon Personalize. Con SageMaker Data Wrangler, è possibile importare dati da oltre 40 origini dati supportate ed eseguire la preparazione completa dei dati (inclusa la selezione, la pulizia, l'esplorazione, la visualizzazione e l'elaborazione dei dati su larga scala) in un'unica interfaccia utente utilizzando poco o nessun codice. Ciò consente di preparare rapidamente set di dati relativi a utenti, articoli o interazioni utilizzando Amazon SageMaker Data Wrangler, sfruttando trasformazioni specifiche di Amazon Personalize e oltre 300 trasformazioni di dati generali integrate, recuperando informazioni sui dati e iterando rapidamente risolvendo i problemi relativi ai dati. Basta visitare la console Amazon Personalize, aprire un set di dati all'interno dei gruppi di set di dati, selezionare ""Importa e prepara i tuoi dati"", quindi scegli ""Prepara i dati con Data Wrangler"". Tieni presente che i clienti che utilizzano Amazon SageMaker Data Wrangler dovranno sostenere costi aggiuntivi in base all'utilizzo. Consulta la pagina dei prezzi."								
Posso mettere in risalto gli articoli senza interazioni nei miei suggerimenti?						"Sì. Amazon Personalize ti consente di aiutare i tuoi utenti a scoprire nuovi prodotti e articoli consentendoti di specificare un ""peso di esplorazione del nuovo articolo"". Questo input viene quindi utilizzato da Amazon Personalize per trovare automaticamente il giusto equilibrio tra l'esposizione di nuovi contenuti agli utenti e l'offerta dei suggerimenti più pertinenti. Amazon Personalize considera anche i dati relativi agli articoli a cui gli utenti sono stati esposti, ma con cui hanno scelto di non interagire."								
Come posso ottimizzare i miei dati per amazon personalize?						Amazon Personalize fornisce l’analisi dei tuoi dati per semplificare l'avvio. Può analizzare i dati forniti e offre suggerimenti per migliorare la preparazione dei dati. Le prestazioni dei sistemi di personalizzazione dipendono dalla fornitura ai modelli di dati di alta qualità sugli utenti e sulle loro interazioni con gli articoli del catalogo. Identificando potenziali carenze nei dati e fornendo suggerimenti per aiutare i clienti a porvi rimedio, Amazon Personalize semplifica la formazione di modelli performanti e riduce la necessità di risoluzione dei problemi.								
Come posso applicare/esportare le raccomandazioni di amazon personalize ai miei flussi di lavoro o alle mie applicazioni aziendali?						Amazon Personalize offre ai clienti due API di inferenza: getRecommendations e getPersonalizedRanking. Queste API restituiscono un elenco di itemID consigliati per un utente, un elenco di articoli analoghi per un articolo o un elenco riclassificato di articoli per un utente. L'itemID può essere un identificatore di prodotto, un ID video e così via. Ci si aspetta che utilizzi questi itemID per generare l'esperienza dell'utente finale attraverso passaggi come il recupero dell'immagine e della descrizione e quindi il rendering di una visualizzazione. In alcuni casi, i clienti potrebbero effettuare l'integrazione con i servizi di consegna di e-mail, i servizi di notifica di AWS o di terze parti per generare l'esperienza dell'utente finale.								
Come devo integrare amazon personalize con le mie applicazioni esistenti?						Dai un'occhiata alla soluzione delle API Personalization che spiega il framework API a bassa latenza in tempo reale che si trova tra le tue applicazioni e i sistemi di raccomandazione come Amazon Personalize. La soluzione fornisce anche implementazioni basate su best practice di caching delle risposte, configurazioni di gateway API, test A/B con Amazon CloudWatch Evidently, metadati degli elementi nel tempo di inferenza, suggerimenti contestuali automatici e altro ancora.								
Come faccio a sapere se amazon personalize fornisce buoni suggerimenti?						Ci sono alcune funzionalità integrate in Amazon Personalize che fungono da punti di controllo per aiutarti a garantire l'ottimizzazione per suggerimenti di alta qualità.								
Amazon personalize può aiutarmi a misurare l'impatto dei suggerimenti?						"Puoi misurare i risultati commerciali di qualsiasi suggerimento di Amazon Personalize con qualsiasi evento inviato al sistema. Puoi quindi visualizzare e valutare l'impatto di uno o più suggerimenti per sviluppare una strategia di personalizzazione più basata sui dati. Dalla console o dall'API di Amazon Personalize, definisci una ""attribuzione metrica"", ovvero un elenco di interazioni (tipi di eventi) che desideri valutare e su cui creare report. Ad esempio, potresti voler tenere traccia di due parametri: la percentuale di clic (CTR) per i suggerimenti e il numero totale di acquisti. Per ogni tipo di evento, dovrai semplicemente definire il parametro e la funzione che desideri valutare (somma o numero) e Amazon Personalize eseguirà il calcolo e invierà i report al tuo account CloudWatch o S3."								
I miei dati saranno privati e sicuri?						Tutti i modelli Amazon Personalize sono unici per il set di dati dei clienti e non vengono condivisi con altri account AWS o con Amazon Retail, Amazon Prime o altre unità aziendali. Nessun dato viene utilizzato per addestrare o propagare modelli per altri clienti: gli input e gli output del modello del cliente sono interamente di proprietà dell'account. Ciascuna interazione che il cliente ha con Amazon Personalize è protetta da crittografia. Qualsiasi dato relativo a utenti, articoli o interazioni trattato da Amazon Personalize può essere criptato ulteriormente con chiavi del cliente attraverso il servizio di gestione delle chiavi AWS e criptato come dato inattivo nella Regione AWS che il cliente sta utilizzando per il servizio. Gli amministratori possono anche controllare gli accessi ad Amazon Personalize tramite una policy di autorizzazione di AWS Identity and Access Management(IAM), garantendo la sicurezza e la riservatezza delle informazioni sensibili.								
Quali sono i casi d'uso più comuni supportati da amazon personalize?														
Quali sono le caratteristiche e le funzionalità principali di amazon personalize?						Amazon Personalize viene costantemente migliorato in base al feedback dei clienti e agli obiettivi della roadmap a lungo termine, mentre ci impegniamo a ottimizzare per semplificare l'onboarding e l'utilizzo. Qui sono elencate diverse funzionalità di Amazon Personalize di grande impatto che vanno oltre le pratiche di machine learning di base. Per un elenco completo delle funzionalità, consulta la pagina Funzionalità.								
Quanto costa amazon personalize?						Consulta la pagina dei prezzi di Amazon Personalize per informazioni aggiornate sui prezzi.								
Come posso ottimizzare i costi di amazon personalize?						Con Amazon Personalize, paghi solo in base all'uso effettivo e senza tariffe minime né impegni anticipati. Ecco alcuni suggerimenti su come gestire i costi.								
Cos'è amazon rekognition?							Amazon Rekognition è un servizio che facilita l'aggiunta di efficaci analisi visive alle applicazioni. Rekognition Image consente di creare facilmente potenti applicazioni per cercare, verificare e organizzare milioni di immagini. Rekognition Video consente di estrarre il contesto dai video salvati o dai flussi in diretta in base al movimento, aiutandoti ad analizzarli. Rekognition Image è un servizio di riconoscimento delle immagini che rileva oggetti, scene, attività, punti di riferimento, volti, colori dominanti e qualità dell'immagine. Rekognition Image estrae anche il testo, riconosce le celebrità e identifica i contenuti inappropriati nelle immagini. Consente anche di ricercare e confrontare i volti. Rekognition Video è un servizio di riconoscimento video che rileva le attività, interpreta i movimenti delle persone in un filmato e riconosce oggetti, personaggi famosi e contenuti inappropriati nei video archiviati in Amazon S3 e nei flussi in diretta. Rekognition Video rileva le persone e le segue nel video anche quando i loro volti non sono visibili e quando la persona esce o entra nell'inquadratura. Ad esempio, può essere utile in un'applicazione che invia notifiche in tempo reale quando qualcuno consegna un pacco alla porta. Rekognition Video consente anche di indicizzare i metadati, come oggetti, attività, scene, punti di riferimento, personaggi famosi e volti, agevolando la ricerca nel video.							
Cos'è il deep learning?							Il deep learning è un sottocampo del machine learning e una significativa branca dell'intelligenza artificiale. Ha lo scopo di dedurre astrazioni ad alti livelli da dati non elaborati utilizzando un grafico profondo con più livelli di elaborazione composto di più trasformazioni lineari e non lineari. L'apprendimento profondo si basa vagamente sui modelli di elaborazione e comunicazione delle informazioni del cervello. L'apprendimento profondo sostituisce caratteristiche ottenute manualmente con quelle apprese da grandi quantità di dati annotati. L'apprendimento si verifica attraverso la valutazione iterativa di centinaia di migliaia di parametri nel grafico profondo con algoritmi efficienti. Diverse architetture di apprendimento profondo come le reti neurali profonde convoluzionali (CNN, Convolutional Neural Network) e le reti neurali ricorsive sono state applicate a visione artificiale, riconoscimento vocale, elaborazione del linguaggio naturale e riconoscimento audio per ottenere risultati innovativi su varie attività. Amazon Rekognition fa parte della famiglia di servizi Amazon AI. I servizi Amazon AI utilizzano l'apprendimento profondo per comprendere immagini, trasformare testi in linguaggio parlato e creare interfacce vocali e di testo conversazionale intuitive.							
Devo avere esperienza nell'apprendimento profondo per utilizzare amazon rekognition?							No. Con Amazon Rekognition non occorre creare, gestire o aggiornare pipeline di apprendimento profondo. Per ottenere risultati accurati su complesse attività di visione artificiale come il rilevamento di oggetti e scene, l'analisi dei volti e il riconoscimento facciale, i sistemi di apprendimento profondo devono essere accuratamente calibrati e programmati con enormi quantità di dati acquisiti sul campo. L'approvvigionamento, la pulizia e l'etichettatura accurate dei dati sono attività costose e molto lunghe. Inoltre, formare una rete neurale profonda è un'operazione costosa dal punto di vista computazionale e spesso richiede hardware personalizzato realizzato utilizzando unità di elaborazione grafica (GPU). Amazon Rekognition è interamente gestito e viene fornito già programmato per attività di riconoscimento delle immagini, affinché non sia necessario investire tempo e risorse nella creazione di una pipeline di apprendimento profondo. Amazon Rekognition continua a migliorare l'accuratezza dei propri modelli basando la propria attività su nuovi dati di apprendimento relativi a ricerca e approvvigionamento. Questo ti permette di concentrarti su progettazione e sviluppo di applicazioni di alto valore.							
Quali sono gli utilizzi più comuni di amazon rekognition?							Tra gli utilizzi più comuni di Rekognition Image ti segnaliamo: Tra gli utilizzi più comuni per Rekognition Video:							
Come si inizia a usare amazon rekognition?							"Se non sei già registrato ad Amazon Rekognition, puoi fare clic sul pulsante ""Prova Amazon Rekognition"" nella pagina Amazon Rekognition e completare la procedura di registrazione. Devi disporre di un account Amazon Web Services; qualora non lo avessi già, ti sarà richiesto di crearlo durante il processo di registrazione. Dopo che ti sarai registrato, prova Amazon Rekognition con le tue immagini e i tuoi video utilizzando la Console di gestione Amazon Rekognition o scarica gli SDK Amazon Rekognition per iniziare a creare le tue applicazioni. Per ulteriori informazioni, consulta la nostra Getting Started Guide dettagliata."							
Quali formati di immagini e video supporta amazon rekognition?							Attualmente Amazon Rekognition Image supporta i formati JPEG e PNG. Puoi inviare immagini anche come oggetto di S3 o come una matrice di byte. Amazon Rekognition Video consente di analizzare i video memorizzati nei bucket Amazon S3. Il video deve essere codificato con il codec H.264. I formati supportati sono MPEG-4 e MOV. Un codec è software o un hardware che comprime i dati per velocizzare il trasferimento, quindi decomprime i dati ricevuti riportandoli al formato originale. Il codec H.264 è diffusamente usato per la registrazione, la compressione e la distribuzione dei contenuti video. Un formato di file video può contenere uno o più codec. Se il tuo file video MOV o MPEG-4 non funziona con Rekognition Video, controlla che sia stato codificato con il codec H.264.							
Quali sono la dimensioni dei file immagine utilizzabili con amazon rekognition?							Amazon Rekognition Image supporta file immagine fino a 15 MB se vengono inviati come oggetti di S3 e fino a 5 MB se sono inviati come array di byte. Amazon Rekognition Video supporta file fino a 10 GB e fino a 6 ore di video se si tratta di file di S3.							
In che modo la risoluzione delle immagini influisce sulla qualità dei risultati delle api di rekognition image?							Amazon Rekognition può essere utilizzato su un'ampia gamma di risoluzioni immagine. Per risultati migliori, ti consigliamo di utilizzare VGA (640 x 480) o una risoluzione superiore. Una risoluzione inferiore a QVGA (320 x 240) può aumentare le possibilità che volti, oggetti o contenuti inappropriati non vengano rilevati, anche se le dimensioni minime delle immagini controllate da Amazon Rekognition sono 80 x 80 pixel.							
Qual è la grandezza minima di un oggetto perché possa essere rilevato e analizzato da amazon rekognition image?							Come regola generale, assicurati che l'oggetto o il volto più piccolo presente nell'immagine sia almeno il 5% delle dimensioni (in pixel) della dimensione più piccola dell'immagine. Se ad esempio lavori con un'immagine di 1600 x 900, ogni dimensione del volto o dell'oggetto più piccolo deve essere di almeno 45 pixel.							
Come posso implementare la revisione umana delle previsioni di amazon rekognition?							Amazon Rekognition è integrato direttamente con Amazon Augmented AI (Amazon A2I), perciò è possibile instradare agevolmente le previsioni con bassa affidabilità da Amazon Rekognition Image ai revisori umani. Utilizzando l'API Amazon Rekognition per la moderazione dei contenuti o la console di Amazon A2I, è possibile indicare le condizioni in presenza delle quali Amazon A2I instrada le previsioni ai revisori, specificando una soglia di affidabilità o una percentuale di campionamento casuale. Se specifichi una soglia di affidabilità, Amazon A2I instrada solamente le predizioni che rientrano nella soglia relativa alla revisione umana. Puoi adeguare tali soglie in qualsiasi momento per raggiungere l'equilibrio giusto tra accuratezza ed efficienza dei costi. In alternativa, se specifichi una percentuale a campione, Amazon A2I instrada un campione casuale delle predizioni per la revisione umana. Questo può aiutarti a implementare audit che consentano di monitorare l'accuratezza delle previsioni su base regolare. Amazon A2I fornisce inoltre ai revisori un'interfaccia Web con tutte le istruzioni e gli strumenti necessari a portare a termine le attività. Per ulteriori informazioni su come implementare la revisione umana con Amazon Rekognition, consulta la pagina Web di Amazon A2I.							
In che modo la risoluzione del video influisce sulla qualità dei risultati delle api di rekognition video?							Il sistema è programmato per riconoscere volti più grandi di 32 pixel (per la dimensione minore), che corrispondono a una dimensione minima del volto da riconoscere compresa tra circa 1/7 dello schermo più piccolo con risoluzione QVGA fino a 1/30 con risoluzione HD a 1080p. Ad esempio, con risoluzione VGA, si possono prevedere prestazioni inferiori per i volti più piccoli di 1/10 della dimensione minore dello schermo.							
Quali altri fattori possono influire sulla qualità delle api di rekognition video?							Oltre alla risoluzione del video, anche le immagini sfocate, le persone in rapido movimento, le condizioni di luminosità e la posa possono influire sulla qualità delle API.							
Quali sono i contenuti video più adatti alle api di rekognition video?							Questa API funziona nel modo migliore con video realizzati da privati e professionisti con campo visivo frontale in normali condizioni di luminosità e colore. Questa API non è testata per i video in bianco e nero, per i video a IR o per le condizioni di luminosità estreme. Con applicazioni sensibili ai falsi allarmi è consigliabile ignorare i dati in uscita con punteggio di affidabilità inferiore a un valore selezionato (specifico per le singole applicazioni).							
In quali regioni aws è disponibile amazon rekognition?							Per l'elenco delle regioni in cui Amazon Rekognition è disponibile consulta la tabella delle regioni AWS.							
Che cos'è un'etichetta?							"Un'etichetta è un oggetto, una scena o un concetto rilevato in un'immagine in base ai relativi contenuti. Ad esempio, la foto di alcune persone su una spiaggia tropicale può contenere etichette come ""Persona"", ""Acqua"", ""Sabbia"", ""Palma"" e ""Costume"" (oggetti), ""Spiaggia"" (scena) e ""Esterno"" (concetto)."							
Cos'è un punteggio di affidabilità e come si usa?							"Il punteggio di affidabilità è un numero compreso tra 0 e 100 che indica la probabilità che una data previsione sia corretta. Ad esempio, se nella spiaggia tropicale il processo di rilevamento di oggetti e scene restituisce un punteggio di affidabilità di 99 per l'etichetta ""Acqua"" e di 35 per l'etichetta ""Palma"", è più probabile che l'immagine contenga acqua piuttosto che una palma. Le applicazioni molto sensibili al rilevamento di errori (falsi positivi) devono ignorare risultati associati a punteggi di affidabilità inferiori a una determinata soglia. La soglia ottimale dipende dall'applicazione. In molti casi otterrai la migliore esperienza utente impostando valori di affidabilità minimi più alti rispetto al valore predefinito."							
Cosa si intende per rilevamento di oggetti e scene?							Per rilevamento di oggetti e scene si intende il processo di analisi di un'immagine o di un video per l'assegnazione di etichette in base al contenuto visivo. Amazon Rekognition Image esegue questo processo attraverso l'API DetectLabels. Questa API ti consente di identificare automaticamente migliaia di oggetti, scene e concetti e restituisce un punteggio di affidabilità per ogni etichetta. DetectLabels utilizza una soglia di sicurezza predefinita di 50. Il rilevamento di oggetti e scene è ideale per i clienti che desiderano cercare e organizzare grandi raccolte di immagini, incluse applicazioni per i consumatori e lo stile di vita che dipendono da contenuto generato dall'utente e da aziende di tecnologia pubblicitaria che desiderano migliorare i propri algoritmi di targeting.							
Amazon rekognition è in grado di individuare le posizioni degli oggetti e restituire cornici?							"Sì, Amazon Rekognition può rilevare la posizione di molti oggetti comuni quali ""Persona"", ""Automobile"" o ""Cane"" sia in immagini che in video. È possibile ricevere le coordinate del riquadro per ogni istanza dell'oggetto trovato, così come un punteggio di affidabilità. Per maggiori informazioni sulla struttura della risposta API per le cornici di oggetti, consulta la documentazione."							
Amazon rekognition fornisce informazioni sulla relazione tra le etichette individuate?							"Sì, per ogni etichetta trovata, Amazon Rekognition restituisce il suo genitore, l'alias e la categoria, se esistono. I genitori sono riportati nel campo ""genitori"" in ordine gerarchico. La prima etichetta del genitore è il genitore immediato, mentre le etichette successive sono i genitori dei genitori. Ad esempio, quando viene identificata un'""Automobile"", Amazon Rekognition restituisce due etichette genitore: ""Veicolo"" (padre) e ""Trasporto"" (padre del padre). Gli alias sono etichette che hanno lo stesso significato delle etichette primarie e vengono restituite nel campo ""alias"". Ad esempio, poiché ""Telefono cellulare"" è un alias di ""Telefono cellulare"", Amazon Rekognition restituisce ""Telefono cellulare"" nel campo ""alias"" di un'etichetta ""Telefono cellulare"". Le categorie raggruppano le etichette in base a temi comuni e vengono riportate nel campo ""categorie"". Ad esempio, poiché ""Cane"" è un'etichetta della categoria ""Animali e animali domestici"", Amazon Rekognition restituisce ""Animali e animali domestici"" nel campo ""categorie"" dell'etichetta ""Cane"". Per maggiori dettagli sull'elenco completo delle etichette supportate e sulla loro tassonomia, visita la documentazione il rilevamento delle etichette di Amazon Rekognition."							
Quali tipi di etichette supporta amazon rekognition?							Rekognition supporta migliaia di etichette appartenenti a categorie comuni incluse, senza alcuna limitazione:							
In che modo il rilevamento di oggetti e scene differisce nel caso dell'analisi dei video?							"Rekognition Video consente di individuare automaticamente migliaia di oggetti (come veicoli o animali domestici) e di attività (come i festeggiamenti o le danze). Fornisce anche le indicazioni di data/ora e un punteggio di affidabilità per ciascuna etichetta. Inoltre si basa sul movimento e sul contesto temporale del video per individuare con precisione attività complesse, come ""soffiare su un candela"" o ""spegnere un incendio""."							
Non trovo l'etichetta di cui ho bisogno. come posso richiedere una nuova etichetta?							"Inviaci le tue richieste di etichette attraverso la Console Amazon Rekognition digitando il nome dell'etichetta nel campo di inserimento della sezione ""Cerca tutte le etichette"" e clicca su ""Richiedi a Rekognition di rilevare"" l'etichetta richiesta. Il catalogo di etichette di Amazon Rekognition è in continua espansione grazie ai suggerimenti dei clienti."							
Che cos'è image properties?							Image Properties è una funzione di Amazon Rekognition Image per rilevare i colori dominanti e la qualità dell'immagine. Image Properties rileva i colori dominanti dell'intera immagine, del primo piano dell'immagine, dello sfondo dell'immagine e degli oggetti con riquadri di delimitazione localizzati. Image Properties misura anche la qualità dell'immagine attraverso i punteggi di luminosità, nitidezza e contrasto. Image Properties può essere richiamata attraverso l'API DetectLabels (rileva etichette) utilizzando IMAGE_PROPERTIES come parametro di ingresso, con o senza il parametro di ingresso GENERAL_LABEL per il rilevamento delle etichette. Visita la documentazione per il rilevamento delle etichette di Amazon Rekognition per saperne di più.							
Come si determinano i colori dominanti?							Image Properties restituisce i colori dominanti in quattro formati: RGB, hexcode, colori CSS e colori semplificati. Amazon Rekognition identifica innanzitutto i colori dominanti in base alla percentuale di pixel, quindi mappa questi colori nella tavolozza di 140 colori CSS, RGB, codice esadecimale e 12 colori semplificati (ad esempio, 'verde', 'rosa', 'nero', 'rosso', 'giallo', 'ciano', 'marrone', 'arancione', 'bianco', 'viola', 'blu', 'grigio'). Per impostazione predefinita, Image Properties restituisce dieci (10) colori dominanti, a meno che i clienti non specifichino il numero di colori da restituire. Il numero massimo di colori dominanti che l'API può restituire è di 12.							
Come si interpretano i punteggi di luminosità, nitidezza e contrasto?							Image Properties fornisce un valore da 0 a 100 per ogni punteggio di luminosità, nitidezza e contrasto. Ad esempio, un'immagine sottoesposta restituirà un punteggio di luminosità basso, mentre un'immagine molto illuminata restituirà un punteggio di luminosità alto.							
Come è possibile controllare se amazon rekognition dispone di modelli aggiornati?							Amazon Rekognition restituisce un parametro EtichettaModelloVersione che ti consente di sapere se il modello è stato aggiornato. I modelli di rilevamento di oggetti e scene sono frequentemente aggiornati sulla base dei feedback dei clienti.							
Posso utilizzare custom labels per analizzare volti o rilevare testo personalizzato?							No. Custom Labels serve per individuare oggetti e scene nelle immagini. Non permette di analizzare volti o rilevare testo personalizzato. Per questo tipo di attività è necessario utilizzare altre API di Rekognition. Per l'analisi dei volti e la rilevazione di testi, consulta la documentazione.							
Posso utilizzare custom labels per individuare immagini dal contenuto non sicuro?							Sì. Custom Labels serve per individuare oggetti e scene nelle immagini. Se addestrato, Custom Labels può rilevare immagini dal contenuto non sicuro specifiche del tuo caso d'uso. Per l'utilizzo dell'API Moderation per rilevare immagini dal contenuto non sicuro generiche, consulta anche la documentazione.							
Quante immagini servono per addestrare un modello personalizzato?							Il numero di immagini necessarie per addestrare un modello personalizzato dipende dalla variabilità delle etichette personalizzate che dovrà prevedere e dalla qualità dei dati di addestramento. Un logo nitido sovrapposto a un'immagine, ad esempio, può essere rilevato con 1-2 immagini di addestramento, mentre per riconoscere un logo meno definito in più variazioni (scala, punto di vista, deformazioni) possono essere necessarie decine o centinaia di esempi con annotazioni di alta qualità. Se è già disponibile un numero elevato di immagini dotate di etichette, è consigliabile addestrare il modello con tutte le immagini disponibili. Per i limiti massimi delle dimensioni del dataset di addestramento, consulta la documentazione. Per addestrare un modello personalizzato con grande accuratezza possono essere necessarie centinaia di immagini, tuttavia con Custom Labels è possibile addestrare prima un modello con decine di immagini per ogni etichetta, verificare i risultati di test per individuare i risultati non soddisfacenti e aggiungere successivamente nuove immagini ripetendo l'addestramento in modo iterativo per migliorare il modello.							
Quante risorse di elaborazione inferenziale devo prevedere per il mio modello personalizzato?							Il numero delle risorse di elaborazione inferenziale parallele dipende da quante immagini devi elaborare in un determinato momento. Il throughput di un'unica risorsa dipende da fattori quali le dimensioni delle immagini, la loro complessità (cioè quanti oggetti rilevati sono visibili) e la complessità del modello personalizzato. Per ottimizzare il provisioning del modello personalizzato è consigliabile monitorare la frequenza con la quale è necessario eseguire il provisioning e il numero di immagini da elaborare in un determinato momento. Se pensi di elaborare periodicamente le immagini (ad esempio, una volta al giorno o alla settimana oppure in orari del giorno predefiniti), inizia impostando il provisioning del modello personalizzato a orari predefiniti, elaborando tutte le immagini e quindi interrompendo il provisioning. Se non interrompi il provisioning, ti verrà addebitato il costo anche se non viene elaborata alcuna immagine.							
Il mio addestramento non è riuscito. mi verranno addebitati dei costi?							No. Se l'addestramento non riesce, non dovrai pagare per le risorse di elaborazione.							
Cos'è la moderazione dei contenuti?							L'API di moderazione dei contenuti di Amazon Rekognition utilizza il deep learning per rilevare contenuti per adulti espliciti o allusivi, contenuti violenti o relativi alle armi, contenuti visivamente disturbanti e contenuti relativi a droghe, alcol, tabacco, simboli d'odio, gioco d'azzardo e gesti osceni in immagini e video. Oltre a contrassegnare le immagini o i video in base alla presenza di contenuti inappropriati e offensivi, Amazon Rekognition restituisce un elenco di etichette suddiviso in gerarchie con un punteggio di affidabilità. Queste etichette indicano sottocategorie specifiche dei contenuti rilevati, fornendo pertanto ulteriore controllo agli sviluppatori sul filtraggio e il controllo di grandi volumi di contenuti generati dagli utenti. Questa API può essere impiegata in flussi di lavoro di moderazione per applicazioni quali social network, app di incontri, piattaforme di condivisione di immagini, blog, forum, applicazioni per bambini, siti di e-commerce, servizi di intrattenimento e piattaforme di inserzioni online.							
Che tipo di contenuti inappropriati, offensivi e inaccettabili rileva amazon rekognition?							"Puoi trovare una lista completa di categorie di contenuti rilevate da Amazon Rekognition qui. Amazon Rekognition restituisce una gerarchia di etichette e un punteggio di affidabilità per ciascuna etichetta. Ad esempio, data una specifica immagine inappropriata, Rekognition restituirà un messaggio di ""nudità esplicita"" con un punteggio di affidabilità di livello più alto. Gli sviluppatori possono utilizzare questi metadati per contrassegnare i contenuti di alto livello, ad esempio quando tutti i tipi di contenuti espliciti per adulti devono essere contrassegnati. Nella stessa sessione, Rekognition può anche restituire un secondo livello di granularità fornendo ulteriore contesto, ad esempio indicando che la presenza di contenuti sessuali espliciti maschili con relativo punteggio di affidabilità. Queste informazioni possono essere utili agli sviluppatori per creare una logica di filtraggio più complessa in base a diverse aree geografiche e segmenti demografici. L'API di moderazione dei contenuti, tuttavia, non costituisce un'autorità affidabile né si pone come filtro esauriente in relazione a contenuti inappropriati e offensivi. Inoltre non è in grado di rilevare la presenza nelle immagini di eventuali contenuti illegali (ad esempio pedopornografia) o contenuti per adulti non naturali. In caso di necessità, ad esempio se occorre il rilevamento di altri tipi di contenuti inappropriati, contattaci utilizzando la procedura illustrata più avanti."							
In che modo è possibile sapere quale versione del modello è attualmente in uso?							"Apportiamo regolarmente migliorie ai modelli di Amazon Rekognition. Per visualizzare la versione del modello, utilizza il campo ""ModerationModelVersion"" nella risposta API."							
In che modo è possibile assicurarsi che amazon rekognition soddisfi gli obiettivi di precisione per il mio caso d'uso di moderazione di immagini o video?							"I modelli di moderazione dei contenuti di Amazon Rekognition sono stati ampiamente ottimizzati e testati, ma il nostro consiglio è comunque di sperimentare l'accuratezza del servizio con i propri set di dati. È possibile utilizzare il parametro ""MinConfidence"" nelle richieste all'API per equilibrare il rilevamento dei contenuti (recupero) con l'affidabilità del rilevamento (precisione). Riducendo il valore del parametro ""MinConfidence"", sarà più facile rilevare la maggior parte dei contenuti inappropriati, ma sarà anche più probabile che vengano contrassegnati anche contenuti che non sono osceni né espliciti. Aumentando il valore del parametro ""MinConfidence"" si riducono i falsi positivi ma alcune immagini con contenuti espliciti e osceni potrebbero essere ignorate."							
In che modo è possibile fornire feedback su rekognition per migliorarne le api di moderazione dei contenuti?							Invia le tue richieste tramite il servizio clienti di AWS. Grazie ai feedback dei clienti, Amazon Rekognition espande costantemente i tipi di contenuti inappropriati rilevati. I contenuti illegali (ad esempio la pedopornografia) non saranno accettati ai fini della procedura.							
Cos'è l'analisi facciale?							L'analisi facciale consiste nel rilevamento di un volto all'interno di un'immagine e nell'estrazione dei relativi attributi. Amazon Rekognition Image restituisce la cornice per ogni volto rilevato in un'immagine, insieme ad attributi come sesso, presenza di occhiali da sole e punti di riferimento del volto. Rekognition Video restituirà i volti rilevati in un video con le indicazioni di data/ora e per ciascun volto rilevato indicherà la posizione e la cornice insieme ai punti di riferimento del volto.							
Quali attributi facciali posso ottenere da amazon rekognition?							Oltre a una cornice e a un punteggio di affidabilità per ogni attributo, Amazon Rekognition restituisce i seguenti attributi facciali per ogni volto rilevato:							
Che cos'è la posa del volto?							Per posa del volto si intende la rotazione di un volto rilevato sugli assi di beccheggio, rollio e imbardata. Ognuno di questi parametri viene restituito come un angolo compreso tra -180° e 180°. La posa del volto può essere utilizzata per trovare l'orientamento del poligono che circonda il viso (in opposizione alla cornice rettangolare), per misurare la deformazione, per tenere traccia dei visi in modo accurato e altro ancora.							
Cosa si intende per qualità del volto?							La qualità del volto descrive la qualità dell'immagine del volto rilevato utilizzando due parametri: nitidezza e luminosità. Entrambi i parametri vengono restituiti come valori compresi tra 0 e 1. A questi parametri può essere applicata una soglia per filtrare volti nitidi e bene illuminati. È utile per le applicazioni che funzionano meglio con immagini di volti di alta qualità, come nel caso del confronto facciale e del riconoscimento facciale.							
Cosa sono i punti di riferimento del volto?							I punti di riferimento del volto sono un insieme di punti salienti, generalmente posizionati agli angoli, alle estremità e al centro dei principali componenti facciali come gli occhi, il naso e la bocca. L'API DetectFaces di Amazon Rekognition restituisce un insieme di punti di riferimento facciali che è possibile utilizzare per ritagliare volti, eseguire il morphing per trasformare un viso in un altro, sovrapporre maschere personalizzate per creare filtri specifici e altro ancora.							
Quanti volti è possibile rilevare in un'immagine?							Amazon Rekognition permette di rilevare fino a 100 volti in un'immagine.							
In che modo l'analisi facciale differisce nel caso dell'analisi dei video?							Rekognition Video consente di individuare i volti in un video e analizzarne le caratteristiche, ad esempio se stanno sorridendo, se gli occhi sono aperti o se mostrano emozioni. Rekognition Video restituirà i volti rilevati con le indicazioni di data/ora e per ciascun volto rilevato indicherà la posizione e fornirà la cornice, insieme a punti di riferimento come occhio sinistro, occhio destro, naso, angolo sinistro della bocca e angolo destro della bocca. Queste informazioni sulla posizione e sulla data/ora si possono utilizzare per seguire facilmente le sensazioni degli utenti nel tempo e aggiungere ulteriori funzionalità come riquadri automatici, evidenziazioni o ritaglio. La ricerca utente non è supportata per l'analisi dei video.							
Oltre alla risoluzione del video, quali altri fattori possono influire sulla qualità delle api di rekognition video?							Le celebrità che si muovono molto velocemente e i video sfocati possono influire sulla qualità delle API di Rekognition Video. Inoltre, anche eventuale trucco pesante o camuffamento, comuni per gli attori e le attrici, possono influire sulla qualità.							
Che cos'è il confronto facciale?							Il confronto facciale è il processo che consente di confrontare un volto con uno o più altri volti per valutarne la somiglianza. Utilizzando l'API CompareFaces, Amazon Rekognition Image consente di misurare la probabilità che i volti presenti in due immagini diverse appartengano alla stessa persona. L'API confronta un volto individuato nell'immagine originale con ogni volto rilevato nell'immagine di destinazione e restituisce un punteggio di somiglianza per ogni confronto. Per ogni faccia rilevata si avranno anche una cornice e un punteggio di affidabilità. Il confronto facciale può essere utilizzato anche per verificare l'identità di una persona confrontandola con foto presenti in archivio quasi in tempo reale.							
Posso utilizzare un'immagine di origine contenente più di un volto?							Sì. Se l'immagine di origine contiene più visi, CompareFaces rileva il viso più grande e lo utilizza per confrontarlo con ogni viso rilevato nell'immagine di destinazione.							
Quanti volti posso confrontare?							Puoi confrontare un volto nell'immagine originale con un massimo di 15 volti rilevati nell'immagine di destinazione.							
Cos'è face search?							Face Search è il processo di utilizzo di un volto di input per cercare corrispondenze simili in una raccolta di volti memorizzati. Attraverso il riconoscimento facciale, puoi creare facilmente applicazioni come l'autenticazione a più fattori per i pagamenti bancari, l'ingresso automatizzato agli edifici per i dipendenti e altro ancora.							
Cos'è una raccolta di volti e come posso crearne una?							Una raccolta di volti è l'indice ricercabile dei vettori di volti, che sono una rappresentazione matematica dei volti. Rekognition non memorizza immagini di volti nella tua collezione. Mediante l'utilizzo dell'API CreateCollection puoi facilmente creare una raccolta in una regione AWS supportata e tornare a un Amazon Resource Name (ARN). Ogni raccolta di volti dispone di un CollectionId univoco associato.							
Come faccio ad aggiungere volti a una raccolta per la ricerca?							Per aggiungere un volto a una raccolta esistente, utilizza l'API IndexFaces. Questa API accetta un'immagine sotto forma di oggetto di S3 o matrice di byte immagine e aggiunge una rappresentazione dei vettori dei volti rilevati alla raccolta. IndexFaces restituisce inoltre un FaceId univoco e una cornice per ogni volto aggiunto. È possibile aggregare più vettori di volti della stessa persona per creare e archiviare vettori utente utilizzando le API CreateUser e AssociateFaces. I vettori utente sono rappresentazioni più robuste dei vettori a faccia singola perché contengono più vettori di volti con diversi gradi di illuminazione, nitidezza, pose, differenze di aspetto, ecc. La ricerca di volti con vettori utente può migliorare significativamente la precisione rispetto alla ricerca di volti con vettori a volto singolo. I vettori utente sono memorizzati nella stessa raccolta dei vettori di volti associati.							
Come si eliminano i volti da una raccolta?							Per eliminare un volto da una raccolta esistente, utilizza l'API DeleteFaces. Questa API agisce sulla raccolta di volti fornita (utilizzando un CollectionId) e rimuove le voci corrispondenti all'elenco di FaceId. Se il FaceID è associato a un vettore utente, dovrai prima utilizzare la chiamata API DisassoicateFaces per rimuoverlo dal vettore utente. Inoltre, puoi eliminare utenti da una raccolta esistente utilizzando l'API DeleteUsers. Per ulteriori informazioni sull'aggiunta e l'eliminazione di volti, consulta il nostro esempio di Gestione delle raccolte.							
Come posso cercare un utente nella raccolta di volti?							Dopo aver creato gli utenti e i FaceID associati, puoi eseguire la ricerca utilizzando un'immagine (SearchUsersByImage), un ID utente (searchUsers) o un FaceID (SearchUsers). Queste API acquisiscono un volto iniziale e restituiscono una serie di utenti corrispondenti ordinati in base al punteggio di somiglianza. Per ulteriori dettagli, consulta il nostro esempio di Ricerca dei volti.							
Come posso cercare un volto nella raccolta?							Una volta che avrai creato una raccolta indicizzata di volti, potrai cercare un viso utilizzando un'immagine (SearchFaceByImage) o un FaceId (SearchFaces). Queste API acquisiscono un volto iniziale e restituiscono una serie di volti corrispondenti ordinati in base al punteggio di somiglianza, con al primo posto il volto che ha ottenuto il punteggio più alto. Per ulteriori dettagli, consulta il nostro esempio di Ricerca dei volti.							
In che modo face search è diverso per l'analisi dei video?							Rekognition Video consente di eseguire ricerche dei volti in tempo reale in raccolte contenenti decine di milioni di volti. Innanzitutto si crea una raccolta di volti nella quale si possono memorizzare volti costituiti da rappresentazioni vettoriali dei tratti somatici. Rekognition esegue quindi la ricerca nella raccolta dei volti per individuare volti visivamente simili in tutto il video. Per ciascun volto presente nel video, Rekognition restituirà un punteggio di affidabilità, consentendo di visualizzare le possibili corrispondenze direttamente nell'applicazione. La ricerca utente non è supportata per l'analisi dei video.							
Oltre alla risoluzione del video, quali altri fattori possono influire sulla qualità delle api video?							Oltre alla risoluzione del video, anche la qualità e i volti significativi, insieme alla parte di raccolta in cui si esegue la ricerca, hanno un impatto notevole. Utilizzando più istanze del volto di una stessa persona con varianti come barba, occhiali, pose diverse (di profilo e frontale) si miglioreranno significativamente i risultati. Generalmente le persone che si muovono molto velocemente possono ridurre la qualità del riconoscimento. Inoltre, i video sfocati potrebbero presentare una qualità inferiore.							
Che cos'è il riconoscimento di volti celebri?							Il riconoscimento di volti celebri di Amazon Rekognition è una nuova funzionalità basata su algoritmi di apprendimento approfondito con cui puoi individuare, mediante un'API molto intuitiva, volti di celebrità e personaggi famosi o noti nel loro campo. L'API RecognizeCelebrities può essere usata su vasta scala e riconosce le celebrità in diverse categorie, tra cui politica, sport, affari, intrattenimento e media. Questa funzionalità risulta particolarmente utile ai clienti a cui occorrono librerie di immagini digitali indicizzabili e ricercabili in base ai personaggi celebri di loro interesse.							
A chi è rivolta l'api di riconoscimento di volti celebri?							Amazon Rekognition è in grado di identificare solo le celebrità per cui il modello di apprendimento approfondito è stato addestrato. L'API RecognizeCelebrities non costituisce un'autorità, né intende esserlo, per la creazione di elenchi di celebrità. Si tratta di una caratteristica creata per includere il maggior numero di celebrità possibili, in base alle esigenze e ai feedback dei clienti. Vengono aggiunti costantemente nuovi nomi, ma il fatto che questa funzionalità non riconosca individui che potrebbero essere considerati noti secondo altri gruppi o clienti non riflette le nostre opinioni su chi debba o non debba essere considerato una celebrità. Se desideri che l'API di riconoscimento di volti celebri sia in grado di identificare nuove celebrità, inviaci un feedback.							
È possibile richiedere di rimuovere una celebrità dall'elenco di personaggi riconosciuti dall'api di amazon rekognition?							Sì. Se una celebrità desidera essere rimossa da questa funzionalità, può farne richiesta tramite e-mail al servizio clienti di AWS.							
Quali riferimenti sono supportati per fornire informazioni aggiuntive su una celebrità?							L'API supporta un elenco opzionale di fonti da includere nella risposta informazioni sulla celebrità. Al momento è possibile indicare un URL dal sito IMDB, se disponibile. In futuro potranno essere aggiunte altre fonti.							
In che modo il riconoscimento di volti celebri differisce nel caso dell'analisi dei video?							Rekognition Video consente di individuare e riconoscere quando e dove appaiono persone famose in un video. I dati di uscita con codifica temporale includono il nome e un identificativo univoco della persona, le coordinate della cornice, un punteggio di affidabilità e gli URL dei contenuti correlati, ad esempio il collegamento alla pagina del personaggio su IMDB. La persona viene rilevata anche se a volte il suo volto non è visibile, nel video. Questa funzione consente di indicizzare e ricercare librerie di video digitali per utilizzi legati a esigenze specifiche di marketing e dei media.							
Che cos'è text detection?							Text Detection è una caratteristica di Amazon Rekognition che permette di rilevare e riconoscere contenuti di testo all'interno di immagini o video, ad esempio nomi di strade, didascalie, nomi di prodotti, grafiche in sovrimpressione, sottotitoli video e targhe di mezzi motorizzati. La funzione Text Detection è stata creata per il rilevamento di testo da immagini e video reali anziché da immagini di documenti. L'API DetectText di Amazon Rekognition si applica alle immagini e restituisce etichette di testo e cornici per ogni stringa di caratteri rilevata, con un punteggio di affidabilità. Nelle applicazioni di condivisione di immagini e di social networking, ad esempio, è possibile abilitare la ricerca visiva basata su un indice di immagini che contiene le stesse etichette di testo. Nelle applicazioni di sicurezza, il servizio permette di identificare i veicoli in base ai numeri di targa dalle immagini scattate tramite body cam. Analogamente, per i video, utilizzando le API StartTextDetection e GetTextDetection è possibile rilevare testo e ottenere punteggi di affidabilità e timestamp per ogni rilevamento. Nelle applicazioni per media e intrattenimento, invece, è possibile creare metadati di testo che supportano la ricerca per i contenuti rilevanti, ad esempio notizie, punteggi sportivi, pubblicità e didascalie. Puoi anche verificare se nel testo rilevato sono presenti violazioni di policy o conformità, per esempio un indirizzo e-mail o un numero di telefono sovrapposti dagli spammer.							
Quali tipi di testo supporta la funzione text detection di amazon rekognition?							La funzione Text Detection è stata creata appositamente per lavorare su immagini e video reali anziché su immagini di documenti. Supporta i numeri e la maggior parte dei caratteri latini strutturati secondo un'ampia varietà di layout, font e stili diversi e sovrapposti agli oggetti sullo sfondo, con diversi livelli di orientamento; ad esempio può rilevare le scritte in striscioni e poster. Text Detection è in grado di riconoscere fino a 50 sequenze di caratteri per immagine, elencandoli come parole e righe. Text Detection è in grado di riconoscere il testo ruotato da -90 a +90 gradi rispetto all'asse orizzontale.							
Posso limitare il rilevamento di testo a regioni specifiche in un'immagine o un frame video?							Sì, puoi utilizzare le opzioni di filtro del rilevamento di testo per specificare un massimo di 10 regioni di interesse (ROI) nella richiesta API. Amazon Rekognition restituirà esclusivamente il testo che rientra in queste regioni.							
Posso filtrare i rilevamenti di testo per affidabilità della parola o dimensione della cornice?							Sì, nella richiesta API puoi utilizzare le opzioni di filtro del rilevamento di testo per specificare le soglie minime di punteggio di affidabilità o di dimensione della cornice.							
Come posso dare un feedback su rekognition per migliorarne le funzionalità di riconoscimento del testo?							Invia le tue richieste tramite il supporto clienti di AWS. Grazie ai feedback dei clienti, Amazon Rekognition espande costantemente i tipi di testi riconosciuti.							
Quale dispositivo di protezione individuale è in grado di rilevare amazon rekognition?							"La funzione ""DetectProtectiveEquipment"" di Amazon Rekognition è in grado di rilevare tipi comuni di protezioni per viso, mani e testa. Per ulteriori informazioni, consulta la documentazione sulla funzione. Puoi anche utilizzare le etichette personalizzate di Amazon Rekognition per rilevare dispositivi di protezione individuale come gilè catarifrangenti, occhiali di sicurezza e altri dispositivi speciali per la tua attività. Per informazioni sull'utilizzo delle etichette personalizzate di Amazon Rekognition per il rilevamento di dispositivi di protezione individuali personalizzati, consulta questo repository di Github."							
Amazon rekognition è in grado di individuare le posizioni del dispositivo di protezione e restituire cornici?							"Sì, l'API ""DetectProtectiveEquipment"" di Amazon Rekognition è in grado di rilevare la posizione del dispositivo di protezione come protezioni per viso, mani e testa su persone in immagini. Si possono ricevere le coordinate della cornice per ogni elemento del dispositivo di protezione individuato, così come un punteggio di affidabilità. Per ulteriori informazioni sulla reattività dell'API, consulta la documentazione."							
Il servizio è in grado di rilevare se la maschera è indossata correttamente?							"Il rilevamento dell'API ""DetectProtectiveEquipment"" di Amazon Rekognition fornisce un valore ""CoversBodyPart"" (vero/falso) e un valore di affidabilità per il valore booleano di ciascun elemento individuato del dispositivo di protezione. In questo modo si ottengono informazioni circa il posizionamento del dispositivo di protezione sulla parte del corpo corrispondente della personale. La previsione sulla presenza del dispositivo di protezione sulla parte del corpo corrispondente aiuta a escludere i casi in cui il dispositivo è presente nell'immagine ma non sulla persona. Tuttavia, non indica né stabilisce se la persona è adeguatamente protetta dal dispositivo di protezione o se le protezioni sono indossate in maniera corretta."							
Il rilevamento del dispositivo di protezione individuale di amazon rekognition è in grado di identificare le persone rilevate?							No, il rilevamento del dispositivo di protezione individuale di Amazon Rekognition non esegue il riconoscimento facciale o il confronto facciale, quindi non è in grado di identificare le persone rilevate.							
Dove è possibile trovare ulteriori informazioni sui limiti e sulla latenza dell'api?							Per aggiornamenti sui dettagli dei limiti e della latenza dell'API, consulta la documentazione sul rilevamento del dispositivo di protezione individuale di Amazon Rekognition.							
Come si inviano le immagini dalle fotocamere del posto di lavoro ad amazon rekognition?							Esistono diverse opzioni per acquisire immagini dalle fotocamere presenti sul posto di lavoro. Per ulteriori informazioni, consulta il blog sul rilevamento del dispositivo di protezione individuale di Amazon Rekognition. Quali sono i prezzi per il rilevamento del dispositivo di protezione individuale? Il rilevamento del dispositivo di protezione individuale di Amazon Rekognition è addebitato in maniera analoga ad altre API per immagini di Amazon Rekognition su base unitaria. Per ulteriori informazioni, visita la pagina dei prezzi di Amazon Rekognition.							
Cosa sono gli amazon rekognition streaming video events?							Amazon Rekognition Streaming Video Events utilizza il machine learning per rilevare oggetti dalla videocamera collegata per fornire avvisi attuabili in tempo reale. Amazon Rekognition Streaming Video Events funziona con i tuoi Kinesis Video Streams nuovi ed esistenti per elaborare flussi video (fino a 120 secondi per evento di movimento) e avvisarti non appena viene rilevato un oggetto di interesse desiderato. Puoi utilizzare queste notifiche per:							
Come funziona amazon rekognition streaming video events?							Puoi utilizzare i Kinesis Video Streams nuovi o esistenti per iniziare a utilizzare Amazon Rekognition Streaming Video Events. Quando configuri le impostazioni del tuo stream processor per Amazon Rekognition, puoi scegliere le etichette desiderate (persona, animale domestico o pacco) che desideri rilevare, la durata del video (fino a 120 secondi per evento di movimento) che Rekognition deve elaborare per ogni evento e/o l'area di interesse del frame che si desidera elaborare tramite Rekognition. Le API di Rekognition Streaming Video Events elaborano il video solo se invii una notifica a Rekognition per avviare l'elaborazione del flusso video. Quando viene rilevato un movimento su una videocamera collegata, invii una notifica a Rekognition per avviare l'elaborazione del flusso video. Rekognition elabora il Kinesis Video Stream corrispondente, post rilevamento, per cercare gli oggetti desiderati da te specificati. Non appena viene rilevato un oggetto desiderato, Amazon Rekognition ti invierà una notifica. Questa notifica include l'oggetto rilevato, il riquadro di delimitazione, l'immagine ingrandita dell'oggetto e l'orario.							
Quali etichette sono supportate da amazon rekognition streaming video events?							Amazon Rekognition Streaming Video Events può supportare persone, animali domestici e pacchi.							
Quali animali domestici e tipi di pacchetto vengono rilevati dalle api di amazon rekognition streaming video event?							Le API di Amazon Rekognition Streaming Video Event supportano il rilevamento di cani e gatti. L'API è in grado di rilevare scatole di cartone di medie e grandi dimensioni con elevata precisione. L'API rileva anche scatole più piccole, buste a bolle e raccoglitori, ma occasionalmente potrebbe mancare alcuni di questi oggetti.							
Le etichette rilevate mi saranno addebitate separatamente?							Posso scegliere quali etichette attivare? No, le etichette rilevate non saranno addebitate separatamente. Ti verrà addebitata la durata del video in streaming elaborato da Rekognition. Puoi attivare etichette specifiche (animale domestico, pacchetto) o scegliere di aderire a tutte e tre le etichette (persone, animale domestico, pacchetto) durante la configurazione delle impostazioni di elaborazione del flusso.							
Devo trasmettere video in streaming continuamente su amazon rekognition?							No, non è necessario eseguire lo streaming di video continuamente su Amazon Rekognition.							
Devo creare nuovi kinesis video streams (kvs) per utilizzare streaming video events?							Amazon Rekognition Streaming Video Events funziona sia con Kinesis Video Streams nuovi che con quelli esistenti. Integra semplicemente i flussi KVS pertinenti con l'API di Amazon Rekognition Streaming Video Events per iniziare con l'analisi video sui flussi KVS.							
Quando mi verrà inviata la notifica da amazon rekognition?							Amazon Rekognition avvia l'elaborazione del flusso video dopo il rilevamento del movimento. Puoi configurare la durata dell'elaborazione di questo flusso video (fino a 120 secondi per evento). Non appena Amazon Rekognition rileva l'oggetto di interesse nel flusso video, Rekognition ti invierà una notifica. Questa notifica include l'oggetto rilevato, il riquadro di delimitazione, l'immagine ingrandita dell'oggetto e l'orario.							
Quali valori di risoluzione e fps sono supportati per il rilevamento delle etichette?							Per mantenere bassi i costi e la latenza, Amazon Rekognition Streaming Video Events supporta flussi video a risoluzione 1080p o inferiore. Rekognition elabora il flusso video a 5 fps.							
Quali codec e formato di file sono supportati per lo streaming di video?							Amazon Rekognition Video supporta file H.264 in formato MPEG-4 (.mp4) o MOV.							
Qual è la durata massima del video elaborato per evento?							Puoi elaborare fino a 120 secondi di video per evento.							
Posso scegliere una particolare area del fotogramma da elaborare per il mio flusso video?							Sì, come parte della configurazione del tuo StreamProcessor puoi scegliere la regione di interesse che vuoi elaborare sul tuo frame. Amazon Rekognition elaborerà solo quella particolare area del frame.							
Quanti flussi video simultanei posso elaborare con amazon rekognition?							Amazon Rekognition Streaming Video Events può supportare 600 sessioni simultanee per cliente AWS. Contatta il tuo account manager se devi aumentare questo limite.							
Quali tipi di entità è in grado di rilevare video amazon rekognition?							Video Amazon Rekognition è in grado di rilevare oggetti, scene, punti di riferimento, volti, celebrità, testi e contenuti inappropriati nei video. Puoi inoltre ricercare i volti che compaiono in un video utilizzare un repository o una raccolta di immagini di volti personalizzati.							
Quali tipi di formati e codici supporta amazon rekognition video?							Amazon Rekognition Video supporta file H.264 in formato MPEG-4 (.mp4) o MOV. Se i tuoi file video utilizzano un codec diverso, puoi transcodificarli in H.264 utilizzando AWS Elemental MediaConvert.							
Come funzionano le api asincrone di amazon rekognition video?							Amazon Rekognition Video può elaborare video archiviati in un bucket Amazon S3. Puoi utilizzare una serie di operazioni asincrone: per avviare l'analisi del video richiamerai un'operazione Start come StartLabelDetection per il rilevamento di oggetti e scene. Lo stato di completamento della richiesta viene pubblicato su un argomento di Amazon Simple Notification Service (SNS). Per conoscere lo stato di completamento dall'argomento Amazon SNS puoi utilizzare una coda Amazon Simple Queue Service (SQS) o una funzione AWS Lambda. Una volta ottenuto lo stato di completamento, richiamerai un'operazione Get come GetLabelDetection per accedere ai risultati della richiesta. Per un elenco di API Amazon Rekognition Video disponibili, consulta questa pagina.							
Come posso trovare la cronologia di ogni rilevamento in un video?							Video Amazon Rekognition restituisce i risultati delle etichette in base a timestamp o segmenti video. Puoi scegliere come organizzare questi risultati utilizzando il parametro di input AggregateBy nell'API GetLabelDetection. Per saperne di più su timestamp e segmenti e per vedere una risposta API di esempio, visita Rilevamento di etichette in un video.							
Quante attività di analisi video posso eseguire contemporaneamente con video amazon rekognition?							Con Amazon Rekognition Video puoi elaborare fino a 20 attività contemporaneamente. Per ulteriori informazioni sui limiti, consulta la nostra pagina corrispondente.							
Quale risoluzione video devo utilizzare?							Amazon Rekognition Video gestisce automaticamente un'ampia gamma di risoluzioni e qualità video. Per risultati ottimali, si consiglia di utilizzare da 720p (1280×720 pixel) a 1080p (1920x1080 pixel) o risoluzioni equivalenti. Video con risoluzioni molto basse (ad esempio, QVGA o 240p) possono avere un impatto negativo sulla qualità dei risultati.							
Che cos'è il rilevamento dei movimenti delle persone?							Con Rekognition Video puoi trovare il percorso di ogni persona nella sequenza temporale del video. Rekognition Video rileva le persone anche quando la telecamera è in movimento e, per ciascuna persona, restituisce la cornice insieme alle caratteristiche del volto e alle indicazioni di data/ora. Nelle attività commerciali consente di ottenere informazioni anonime sui clienti, rilevando ad esempio come si muovono lungo i corridoi di un centro commerciale o per quanto tempo rimangono in fila alle casse.							
Quali tipi di analisi multimediale è in grado di eseguire amazon rekognition video?							Amazon Rekognition Video è in grado di rilevare i seguenti tipi di segmenti o entità per analisi multimediale: Amazon Rekognition Video fornisce inizio, fine, durata e timecode per ogni entità rilevata, nonché timestamp (millisecondi), codice del formato SMPTE e opzioni del numero di fotogrammi per ognuno.							
Come inizio l'analisi multimediale con amazon rekognition video?							Le caratteristiche dell'analisi multimediale sono disponibili tramite l'API di rilevamento dei segmenti di Amazon Rekognition Video. Questa è un'API asincrona costituita da due operazioni: StartSegmentDetection per iniziare l'analisi, e GetSegmentDetection per ottenere i risultati dell'analisi. Per iniziare, consulta la documentazione. Se desideri visualizzare i risultati dell'analisi multimediale o provare altri servizi di intelligenza artificiale di Amazon come Amazon Transcribe con i tuoi video, utilizza l'applicazione Media Insights, un'applicazione demo e framework serverless per generare facilmente informazioni e sviluppare applicazioni per le tue risorse video, audio, di testo e immagini, mediante l'uso di servizi AWS Machine Learning e multimediali. Puoi facilmente avviare la tua applicazione demo utilizzando il modello AWS CloudFormation fornito, per provare i tuoi video e visualizzare i risultati dell'analisi.							
Che cos'è un timecode accurato del fotogramma?							I timecode accurati dei fotogrammi forniscono il numero esatto di fotogrammi per un segmento di video o entità pertinente. Di norma le aziende multimediali elaborano i timecode utilizzando il formato SMPTE (Society of Motion Picture and Television Engineers) ore:minuti:secondi:numero di fotogrammi, ad esempio, 00:24:53:22.							
Il fotogramma del rilevamento dei segmenti di amazon rekognition video è accurato?							Sì, l'API per il rilevamento dei segmenti di Amazon Rekognition Video fornisce timecode SMPTE accurati dei fotogrammi, nonché timestamp in millisecondi per l'inizio e la fine di ogni rilevamento.							
Quali tipi di formati per la frequenza dei fotogrammi può gestire il rilevamento dei segmenti di amazon rekognition video?							Il rilevamento dei segmenti di Amazon Rekognition Video gestisce automaticamente standard di numeri interi, frazioni e drop frame per frequenze comprese tra 15 e 60 fps. Ad esempio, sono supportate frequenze di fotogrammi come 23,976 fps, 25 fps, 29,97 fps e 30 fps. Le informazioni sulla frequenza dei fotogrammi vengono utilizzate in ogni caso per fornire timecode accurati dei fotogrammi.							
Quale opzione di filtro è possibile applicare?							È possibile specificare l'affidabilità minima per ogni tipo di segmento mentre si effettua la richiesta API. Per esempio, è possibile escludere qualsiasi segmento con punteggio di affidabilità inferiore al 70%. Per il rilevamento dei fotogrammi neri, è anche possibile controllare la luminosità massima dei pixel considerati come pixel neri, come ad esempio un valore di 40 per una gamma cromatica da 0 a 255. Inoltre, è anche possibile controllare quale percentuale di pixel in un fotogramma deve soddisfare questo criterio di luminosità dei pixel neri per poter classificare il fotogramma come fotogramma nero, per esempio il 99%. Questi filtri consentono di rendere conto di qualità e formato video variati quando si rilevano fotogrammi neri. Per esempio, video recuperati da archiviazione a nastro possono essere rumorosi e avere un diverso livello di nero rispetto a un video digitale moderno. Per ulteriori dettagli, consulta questa pagina.							
In che modo amazon rekognition conteggia le immagini elaborate?							Per le API che accettano immagini come input, Amazon Rekognition fa coincidere il numero delle immagini analizzate con il numero delle immagini elaborate. DetectLabels, DetectModerationLabels, DetectFaces, IndexFaces, RecognizeCelebrities, SearchFaceByImage e Image Properties appartengono a questa categoria. Per l'API CompareFaces, in cui due immagini vengono inviate come input, solo l'immagine di origine viene conteggiata come unità di immagini elaborate. Per le chiamate API che non richiedono un'immagine come parametro di input, Amazon Rekognition conteggia ogni chiamata API come un'immagine elaborata. SearchFaces appartiene a questa categoria. Le restanti API di Amazon Rekognition - ListFaces, DeleteFaces, CreateCollection, DeleteCollection e ListCollections - non concorrono a calcolare il numero delle immagini elaborate.							
In che modo amazon rekognition conta i minuti dei video elaborati?							Per i video archiviati, Amazon Rekognition conta i minuti di video elaborati correttamente dall'API e li somma per la fatturazione. Per i flussi video in tempo reale ti verranno addebitati i blocchi di cinque secondi di video elaborati correttamente.							
Per quali api amazon rekognition applica tariffe?							Amazon Rekognition Image addebita i costi relativi all'uso delle seguenti API: DetectLabels, DetectModerationLabels, DetectText, DetectFaces, IndexFaces, RecognizeCelebrities, SearchFaceByImage, CompareFaces, SearchFaces e Image Properties. Amazon Rekognition Video addebita i costi in base alle durate (in minuti) dei video elaborati correttamente dalle API StartLabelDetection, StartFaceDetection, StartFaceDetection, StartTextDetection, StartContentModeration, StartPersonTracking, StartCelebrityRecognition, StartFaceSearch e StartStreamProcessor.							
Quanto costa amazon rekognition?							Per informazioni sui prezzi correnti, consulta la pagina dei prezzi di Amazon Rekognition.							
Mi verranno addebitati i vettori caratteristici archiviati nelle mie raccolte di volti?							Sì. Amazon Rekognition addebita 0,01 USD per 1.000 vettori caratteristici dei volti al mese. Per ulteriori dettagli, consulta la pagina dei prezzi.							
Amazon rekognition partecipa al piano gratuito di aws?							Sì. Poiché hai accesso al piano di utilizzo gratuito di AWS, puoi iniziare a utilizzare Amazon Rekognition gratuitamente. Dopo l'iscrizione, i nuovi clienti Amazon Rekognition possono analizzare fino a 5.000 immagini gratuitamente ogni mese per i primi 12 mesi. Eccetto Image Properties, puoi utilizzare tutte le API di Amazon Rekognition con questo piano gratuito e perfino archiviare fino a 1.000 volti senza ulteriori addebiti. Inoltre, i clienti di Amazon Rekognition Video possono analizzare gratuitamente 1.000 minuti di video al mese per il primo anno.							
I prezzi includono le tasse?							Per informazioni dettagliate sulle imposte, consulta la guida alle imposte di Amazon Web Services.	Per informazioni dettagliate sulle tasse, consulta il documento Assistenza di Amazon Web Services sulle imposte.						
Amazon rekognition video funziona con le immagini archiviate in amazon s3?							Sì. Puoi iniziare ad analizzare immagini archiviate in Amazon S3 semplicemente indirizzando l'API di Amazon Rekognition al tuo bucket di S3. Non è necessario che sposti i dati. Per ulteriori dettagli su come utilizzare oggetti di S3 con le chiamate API di Amazon Rekognition, vedi il nostro esercizio sul rilevamento delle etichette.							
È possibile utilizzare amazon rekognition con immagini memorizzate in un bucket di amazon s3 in un'altra regione?							No. Verifica che il bucket di Amazon S3 che desideri utilizzare si trovi nella stessa regione degli endpoint per l'API di Amazon Rekognition.							
Come posso elaborare più file di immagini in un batch utilizzando amazon rekognition?							Puoi elaborare le immagini di Amazon S3 in blocco seguendo le fasi descritte nel nostro esempio di elaborazione di batch in Amazon Rekognition su GitHub.							
Come posso utilizzare aws lambda con amazon rekognition?							Amazon Rekognition consente di accedere facilmente ad AWS Lambda e ti permette di portare analisi di immagini basate sui trigger nei data store di AWS come Amazon S3 e Amazon DynamoDB. Per utilizzare Amazon Rekognition con AWS Lambda, segui la procedura riportata qui e seleziona il progetto di Amazon Rekognition.							
È possibile utilizzare amazon rekognition con aws cloudtrail?							Sì. Amazon Rekognition supporta la registrazione, sotto forma di file di log di evento in CloudTrail, delle seguenti operazioni: CreateCollection, DeleteCollection, CreateStreamProcessor, DeleteStreamProcessor, DescribeStreamProcessor, ListStreamProcessors e ListCollections. Per ulteriori informazioni sulle chiamate API di Amazon Rekognition che si integrano con AWS CloudTrail, consulta il documento Logging Amazon Rekognition API Calls with AWS CloudTrail.							
Le immagini e i video da me inviati ed elaborati da amazon rekognition vengono archiviati?							E come vengono utilizzati da AWS? Amazon Rekognition può archiviare e utilizzare le immagini e i video elaborati dal servizio esclusivamente per fornire e mantenere il servizio e, a meno che tu scelga di non farlo come specificato di seguito, anche per migliorare e sviluppare la qualità di Amazon Rekognition e di altre tecnologie di apprendimento automatico e intelligenza artificiale di Amazon. L'utilizzo dei tuoi contenuti è importante per migliorare continuamente la tua esperienza come cliente di Amazon Rekognition, anche grazie allo sviluppo e al perfezionamento delle tecnologie correlate. Non usiamo alcun dato di identificazione personale eventualmente presente nei tuoi contenuti per proporre prodotti, servizi o attività marketing a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare i contenuti immagini e video per migliorare o sviluppare la qualità di Amazon Rekognition e di altre tecnologie di Machine Learning e Intelligenza Artificiale di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare, consulta Gestione della policy di esclusione dei servizi di AI.							
Posso eliminare gli input di immagini e video che sono stati archiviati da amazon rekognition?							Sì. Puoi richiedere l'eliminazione dei contenuti audio e video associati al tuo account contattando AWS Support. L'eliminazione delle immagini e dei video che hai inviato potrebbe compromettere la tua esperienza con Amazon Rekognition.							
Chi ha accesso ai miei contenuti elaborati e archiviati da amazon rekognition?							Solo i dipendenti autorizzati avranno accesso ai tuoi contenuti elaborati da Amazon Rekognition. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.							
I miei contenuti elaborati e archiviati da amazon rekognition rimangono di mia proprietà?							Conservi sempre la proprietà dei tuoi contenuti. Li utilizzeremo solo con il tuo consenso.							
I contenuti elaborati da amazon rekognition vengono trasferiti fuori dall'area aws in cui utilizzo amazon rekognition?							Tutti i contenuti elaborati da Amazon Rekognition sono crittografati e memorizzati in condizioni statiche nella regione AWS in cui utilizzi Amazon Rekognition. A meno che tu decida di non farlo, come specificato di seguito, i contenuti elaborati da Amazon Rekognition possono essere parzialmente archiviati in un'altra regione AWS esclusivamente per finalità di costante miglioramento e sviluppo della tua esperienza di cliente Amazon Rekognition e di altre tecnologie di apprendimento automatico e intelligenza artificiale di Amazon. Puoi richiedere l'eliminazione dei contenuti audio e video associati al tuo account contattando AWS Support. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. I tuoi contenuti non verranno archiviati in un'altra regione AWS se scegli di non utilizzarli al fine di migliorare e sviluppare la qualità di Amazon Rekognition e di altre tecnologie di Machine Learning e Intelligenza Artificiale di Amazon. Per ulteriori informazioni su come rifiutare, consulta Gestione della policy di esclusione dei servizi di AI.							
Posso usare amazon rekognition collegato a siti web, programmi o altre applicazioni rivolte o destinate a minori di 13 anni e soggette alle norme previste dal children's online privacy protection act (coppa)?							Sì. Ai sensi dei Termini di servizio di Amazon Rekognition, adempiuto l'obbligo di fornire il necessario preavviso e ottenuto il consenso dei genitori secondo quanto prescritto dal COPPA, è possibile utilizzare Amazon Rekognition in connessione con siti Web, programmi o altre applicazioni rivolte o destinate, del tutto o in parte, a minori di 13 anni.							
Amazon rekognition è idoneo ai fini hipaa?							Amazon Rekognition è un servizio idoneo ai fini HIPAA coperto dal BAA (Business Associate Addendum) di AWS. Se disponi di un BAA con AWS, Amazon Rekognition tratterà, divulgherà e conserverà le informazioni sanitarie protette solo se stabilito nei termini del contratto.							
Come posso controllare l'accesso degli utenti ad amazon rekognition?							Amazon Rekognition è stato integrato con AWS Identity and Access Management (IAM). Le policy di AWS IAM possono essere utilizzate per garantire che solo gli utenti autorizzati abbiano accesso alle API di Amazon Rekognition. Per ulteriori dettagli, consulta la pagina del controllo degli accessi e dell'autenticazione di Amazon Rekognition.							
In che modo posso riportare un potenziale uso illecito di amazon rekognition?							Se hai ragione di credere che Amazon Rekognition sia utilizzato in maniera illecita o illegale oppure infrange i tuoi diritti, nonché quelli di altre persone, puoi effettuare una segnalazione e AWS investigherà sulla questione.							
Cos'è amazon textract?								Amazon Textract è un servizio di analisi dei documenti che rileva ed estrae testi stampati, scritti a mano, dati strutturati (come campi di interesse e rispettivi valori) e tabelle ricavate da immagini e scansioni di documenti. I modelli di machine learning di Amazon Textract sono stati addestrati su milioni di documenti in modo che praticamente qualsiasi tipo di documento caricato venga riconosciuto automaticamente ed elaborato per l'estrazione del testo. Quando le informazioni vengono estratte dai documenti, il servizio restituisce un punteggio di affidabilità per ogni elemento che è in grado di identificare, consentendo di prendere decisioni informate su come utilizzare i risultati. Ad esempio, se estrai informazioni da documenti fiscali, puoi impostare regole personalizzate per contrassegnare qualsiasi informazione estratta con un punteggio di affidabilità inferiore al 95%. Inoltre, tutti i dati estratti vengono restituiti con le coordinate dei riquadri di delimitazione, ovvero una cornice rettangolare che racchiude completamente ogni dato individuato, in modo da identificare rapidamente la posizione di una parola o di un numero all'interno di un documento. Puoi accedere a queste funzionalità dall'API di Amazon Textract, nella Console di gestione AWS o utilizzando l'interfaccia a riga di comando AWS (CLI).						
Quali sono i casi d'uso più comuni per amazon textract?								I casi d'uso più comuni per Amazon Textract includono:						
Quali tipi di testo amazon textract è in grado di rilevare ed estrarre?								Amazon Textract può rilevare testi stampati e scritti a mano dall'alfabeto inglese standard e dai simboli ASCII. Amazon Textract è in grado di estrarre testi stampati, moduli e tabelle in inglese, tedesco, francese, spagnolo, italiano e portoghese. Inoltre, Amazon Textract estrae dati etichettati esplicitamente, dati impliciti e voci da un elenco dettagliato di prodotti o servizi da pressoché qualsiasi fattura o ricevuta in inglese, senza alcun modello o configurazione. Amazon Textract può anche estrarre dati specifici o impliciti, come nomi e indirizzi da documenti di identità in inglese, quali passaporti e patenti di guida statunitensi senza la necessità di modelli o configurazione. Infine, Amazon Textract può estrarre qualsiasi dato specifico dai documenti senza doversi preoccupare della struttura o delle variazioni dei dati nel documento utilizzando query in inglese.						
Quali formati di documenti supporta amazon textract?								Amazon Textract attualmente supporta i formati PNG, JPEG, TIFF e PDF. Per le API sincrone, puoi inviare immagini come oggetti S3 o come un array di byte. Per le API asincrone, puoi inviare oggetti S3. Se il documento è già in un formato di file supportato da Amazon Textract (PDF, TIFF, JPG, PNG), non convertirlo né sottocampionarlo prima di caricarlo in Amazon Textract.						
Come si inizia a utilizzare amazon textract?								"Per iniziare a utilizzare Amazon Textract, puoi fare clic sul pulsante ""Avvia Amazon Textract"" nella pagina di Amazon Textract. Devi disporre di un account Amazon Web Services; qualora non lo avessi già, ti sarà richiesto di crearlo durante il processo. Una volta effettuato l'accesso all'account AWS, prova Amazon Textract con le nostre immagini o i documenti PDF utilizzando la Console di gestione Amazon Textract. Puoi anche scaricare gli SDK Amazon Textract per iniziare a creare le applicazioni. Per ulteriori informazioni, consulta la nostra guida alle operazioni di base dettagliata."						
Quali api offre amazon textract?								"Amazon Textract offre API che rilevano ed estraggono testi stampati e scritti a mano da immagini scansionate di documenti, estrapolano dati strutturati come le tabelle, eseguono l'associazione chiave-valore sul testo estratto e separano le API incentrate sull'estrazione dei dati da fatture, ricevute e documenti di identità. Amazon Textract esegue il riconoscimento ottico dei caratteri (OCR) utilizzando l'API Detect Document Text, ma va oltre il processo di analisi del documento ed esegue anche il rilevamento dell'associazione chiave-valore in modo che le estrazioni dei testi rimangano organizzate nella rispettiva struttura prevista. L'API Analyze Document può rilevare testi stampati e scritti a mano, campi, valori e le rispettive relazioni, tabelle e altre entità all'interno di un documento, unitamente ai rispettivi punteggi di affidabilità associati. Con l'API Analyze Document, gli sviluppatori possono acquisire automaticamente dati strutturati da un'ampia varietà di documenti, inclusi i moduli fiscali, report finanziari, cartelle cliniche e richieste di prestiti. L'API Analyze Document fornisce anche agli sviluppatori la flessibilità per specificare i dati da estrarre dai documenti utilizzando query, senza doversi preoccupare della struttura dei dati o delle variazioni al modo in cui questi sono disposti nei diversi formati e versioni del documento. L'API Analyze Expense può rilevare il nome del fornitore in una ricevuta anche se è indicato all'interno di un logo sulla pagina, senza un'etichetta specifica denominata ""vendor"" (fornitore). Può anche individuare ed estrarre elementi, quantità e prezzi non etichettati con intestazioni di colonna per le voci. Con l'API Analyze Expense, gli sviluppatori possono utilizzare nomi di chiavi e intestazioni di colonna normalizzati quando estraggono i dati da fatture e ricevute, in modo che le applicazioni downstream possano confrontare facilmente l'output da molti documenti. L'API Analyze ID comprende il contesto dei documenti di identità, come passaporti e patenti di guida statunitensi senza la necessità di modelli o configurazione. Utilizzando Analyze ID, le aziende che forniscono servizi di verifica dei documenti d'identità e quelle che operano nei settori finanziario, sanitario e assicurativo possono facilmente automatizzare la creazione di account, la pianificazione di appuntamenti, le domande di lavoro e altro, permettendo ai clienti di inviare un'immagine o una scansione del proprio documento d'identità. Per ulteriori dettagli, consulta la Guida di riferimento alle API di Amazon Textract."						
Di quali funzionalità dispone l'api analyze document?								"L'API Analyze Document presenta tre funzionalità: moduli, tabelle e query. Puoi utilizzare queste funzionalità singolarmente o combinate tra loro. Usa i moduli per estrarre dati come coppie chiave-valore (ad esempio, ""Nome"" e valore associato: ""Jane Smith""). Usa le tabelle per estrarre i dati tabulari o di tabelle organizzati in colonne e righe. Usa le query per specificare le informazioni necessarie da un documento sotto forma di domande in linguaggio naturale (ad esempio, ""Come si chiama il cliente?"") e ricevere la risposta (ad esempio, ""Jane Doe"") come parte della stessa."						
In che modo i clienti devono costruire/creare/formulare le query?								Abbiamo pubblicato una guida dettagliata sulle best practice per creare query come parte della nostra documentazione sulle API nella pagina delle risorse di Textract. In generale, per creare una query i clienti devono porre una domanda in linguaggio naturale utilizzando parole ricavate dalla documentazione.						
C'è un limite al numero di query per documento che posso fare?								Le query vengono elaborate in base a ogni pagina e le informazioni possono essere estratte utilizzando le query tramite operazioni sia sincrone che asincrone. Per le operazioni sincrone, sono supportate al massimo 15 query per pagina. Per le operazioni asincrone, sono supportate al massimo 30 query per pagina.						
Come posso ottenere i risultati migliori da amazon textract?								Amazon Textract utilizza il machine learning per leggere praticamente qualsiasi tipo di documento al fine di estrarre testi stampati, scritti a mano e informazioni strutturate. Per ottenere risultati ottimali, tieni a mente i seguenti suggerimenti: Puoi iniziare ad analizzare i documenti con Amazon Textract in pochi clic nella Console di gestione Amazon Textract. Se hai problemi a ottenere risultati precisi con ricevute, identificazione o diagrammi industriali, contattaci all'indirizzo amazon-textract@amazon.com per ricevere assistenza.						
Come posso utilizzare il punteggio di affidabilità fornito da amazon textract?								Il punteggio di affidabilità è un numero compreso tra 0 e 100 che indica la probabilità che una data previsione sia corretta. Con Amazon Textract, tutti i testi stampati, scritti a mano e i dati strutturati estratti vengono restituiti con le coordinate dei riquadri di delimitazione, ovvero una cornice rettangolare che racchiude completamente ogni dato identificato. Ciò ti consente di identificare il punteggio per ogni entità estratta in modo da prendere decisioni informate su come vuoi utilizzare i risultati.						
Come posso implementare la revisione umana delle previsioni di amazon textract?								Amazon Textract è integrato direttamente con Amazon Augmented AI (A2I), perciò è possibile sottoporre facilmente a revisione umana le previsioni con bassa affidabilità da Amazon Textract. Utilizzando l'API di Amazon Textract per l'estrazione dei dati e la console di Amazon A2I, è possibile indicare le condizioni in presenza delle quali Amazon A2I instrada le previsioni ai revisori, specificando una soglia di affidabilità o una percentuale di campionamento casuale. Se specifichi una soglia di affidabilità, Amazon A2I instrada solamente le previsioni che rientrano nella soglia relativa alla revisione umana. Puoi adeguare tali soglie in qualsiasi momento per raggiungere l'equilibrio giusto tra accuratezza ed efficienza dei costi. In alternativa, se specifichi una percentuale a campione, Amazon A2I instrada un campione casuale delle predizioni per la revisione umana. Questo può aiutarti a implementare audit che consentono di monitorare l'accuratezza delle previsioni su base regolare. Amazon A2I fornisce anche ai revisori un'interfaccia Web con tutte le istruzioni e gli strumenti necessari a portare a termine le attività. Per ulteriori informazioni su come implementare la revisione umana con Amazon Textract, consulta il sito Web di Amazon A2I.						
In quali regioni aws è disponibile amazon textract?								Amazon Textract è attualmente disponibile nelle regioni Stati Uniti orientali (Virginia settentrionale), Stati Uniti orientali (Ohio), Stati Uniti occidentali (Oregon), Stati Uniti occidentali (California settentrionale), AWS GovCloud (Stati Uniti-Ovest), AWS GovCloud (Stati Uniti-Est), Canada (Centrale), Europa (Irlanda), Europa (Londra), Europa (Francoforte), Europa (Parigi), Asia Pacifico (Singapore), Asia Pacifico (Sydney), Asia Pacifico (Seoul) e Asia Pacifico (Mumbai).						
È possibile utilizzare amazon textract con aws cloudtrail?								Sì. Amazon Textract supporta la registrazione delle seguenti azioni come eventi CloudTrail: DetectDocumentText, AnalyzeDocument, StartDocumentTextDetection, StartDocumentAnalysis, GetDocumentTextDetection e GetDocumentAnalysis. Per ulteriori dettagli, consulta Logging Amazon Textract API Calls with AWS CloudTrail (Registrazione delle chiamate API di Amazon Textract con AWS CloudTrail).						
In che modo amazon textract conteggia le immagini elaborate?								Un'immagine (PNG, TIFF o JPEG) viene conteggiata come pagina singola. Per i PDF, ogni pagina all'interno del documento viene conteggiata come pagina elaborata.						
Quali api mi vengono addebitate con amazon textract?								Per ulteriori informazioni sui prezzi, consulta la pagina dei prezzi di Amazon Textract.						
Quanto costa amazon textract?								Amazon Textract ti addebita i costi in base al numero di pagine e di immagini elaborate. Per maggiori informazioni, visita la pagina dei prezzi.						
Amazon textract partecipa al piano gratuito aws?								Sì. Come parte del piano gratuito AWS, puoi iniziare a utilizzare Amazon Textract gratuitamente. Il piano gratuito dura tre mesi e i nuovi clienti AWS possono analizzare:  API Detect Document Text: 1.000 pagine al mese API Analyze Document: API Analyze Expense: 100 pagine al mese API Analyze ID: 100 pagine al mese						
I documenti e le immagini da me inviati ed elaborati da amazon textract vengono archiviati?								E come vengono utilizzati da AWS? Amazon Textract può archiviare e utilizzare gli input di documenti e immagini elaborati dal servizio, esclusivamente per erogare e mantenere attivo il servizio, oltre a migliorare e sviluppare la qualità di Amazon Textract e di altre tecnologie di machine learning e Intelligenza Artificiale (IA) di Amazon. L'utilizzo dei contenuti è necessario nell'ottica di costante miglioramento dell'esperienza utente del servizio Amazon Textract, nonché per lo sviluppo e la formazione di tecnologie correlate. Non usiamo alcun dato di identificazione personale eventualmente presente nei tuoi contenuti per proporre prodotti, servizi o attività di marketing a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare gli input di documenti e immagini per migliorare o sviluppare la qualità di Amazon Textract e di altre tecnologie di machine learning e Intelligenza Artificiale (IA) di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare esplicitamente, consulta la Policy di esclusione dei servizi di IA.						
I contenuti elaborati da amazon textract vengono trasferiti all'esterno della regione aws in cui è in uso il servizio?								I contenuti elaborati da Amazon Textract vengono crittografati e archiviati su disco nella regione AWS in cui è in uso il servizio. A meno che tu decida di non farlo, come specificato di seguito, i contenuti elaborati da Amazon Textract possono essere parzialmente archiviati in un'altra regione AWS esclusivamente per finalità di costante miglioramento e sviluppo della tua esperienza di cliente Amazon Textract e di altre tecnologie di apprendimento automatico e Intelligenza Artificiale (IA) di Amazon. Puoi richiedere l'eliminazione degli input di immagini e video associati al tuo account contattando il Supporto AWS. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. I tuoi contenuti non verranno archiviati in un'altra regione AWS se scegli di non utilizzarli al fine di migliorare e sviluppare la qualità di Amazon Textract e di altre tecnologie di machine learning e Intelligenza Artificiale (IA) di Amazon. Per ulteriori informazioni su come rifiutare esplicitamente, consulta la Policy di esclusione dei servizi di IA.						
Posso eliminare le immagini e i documenti archiviati da amazon textract?								Sì. Puoi richiedere l'eliminazione degli input di documenti e immagini associati al tuo account contattando il Supporto AWS. L'eliminazione delle immagini e dei documenti che hai inviato potrebbe compromettere la tua esperienza con Amazon Textract.						
Chi avrà accesso ai contenuti elaborati e archiviati da amazon textract?								Solo i dipendenti autorizzati potranno accedere ai contenuti elaborati da Amazon Textract. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.						
I contenuti elaborati e archiviati da amazon textract rimangono di mia proprietà?								Sì. Manterrai la proprietà sui contenuti. Li useremo solo previo consenso.						
Amazon textract è soggetto alla normativa hipaa?								Sì, AWS ha esteso il proprio programma di conformità agli standard HIPAA in modo da includere Amazon Textract. Se disponi di un contratto di società in affari (BAA) con AWS, puoi utilizzare Amazon Textract per estrarre dalle immagini testi che includono informazioni sanitarie protette. Ulteriori informazioni sulla conformità alla normativa HIPAA »						
Quali programmi di conformità rientrano nell'ambito di amazon textract?								Textract è soggetto allo standard HIPAA ed è conforme a PCI, ISO e SOC. Per ulteriori informazioni, visita AWS Artifact nella Console di gestione AWS o https://aws.amazon.com/compliance/services-in-scope/. Textract supporta anche gli endpoint del Cloud privato virtuale Amazon (Amazon VPC) tramite AWS PrivateLink, che consente ai clienti di avviare in sicurezza le chiamate API ad Amazon Textract dall'interno del loro VPC ed evitare così l'uso dell'Internet pubblica.						
Cos'è amazon transcribe?									Amazon Transcribe è un servizio AWS di Intelligenza Artificiale (IA) che semplifica la conversione di voce in testo. Grazie alla tecnologia di riconoscimento vocale automatizzato, puoi utilizzare Amazon Transcribe per numerose applicazioni aziendali, tra cui trascrizione di chiamate di assistenza vocali con i clienti, generazione in tempo reale di sottotitoli e analisi basate su testo per contenuti audio e video.					
In che modo amazon transcribe interagisce con gli altri prodotti aws?									Amazon Transcribe converte gli input audio in testo, permettendo così l'utilizzo di diverse applicazioni di analisi dei testi. Ad esempio, utilizzando Amazon Comprehend sui dati di testo convertito da Amazon Transcribe, puoi eseguire l'analisi le tendenze o estrarre entità e frasi chiave. In modo analogo, integrando Amazon Translate e Amazon Polly, puoi accettare input vocali in una lingua, tradurli in un'altra e generare un output vocale, consentendo in questo modo una conversazione in lingue diverse. È anche possibile integrare Amazon Transcribe con Amazon Kendra o Amazon OpenSearch per indicizzare ed eseguire ricerche basate su testo in una libreria audio/video. Per ulteriori informazioni, consulta la soluzione Analisi dei dati delle chiamate e assistenza agli agenti in tempo reale, Analisi post chiamate, MediaSearch o Analisi dei contenuti.					
Cos'altro dovrei sapere prima di utilizzare il servizio amazon transcribe?									Amazon Transcribe è progettato per gestire una vasta gamma di caratteristiche vocali e acustiche, comprese le variazioni di volume, tono e velocità del parlato. La qualità e il contenuto del segnale audio (inclusi, a titolo indicativo, fattori quali rumore di fondo, altoparlanti sovrapposti, accento o passaggi tra lingue diverse in un unico file audio) possono influenzare l'accuratezza dell'uscita del servizio. Aggiorniamo costantemente il servizio per migliorare la sua capacità di accogliere variazioni acustiche e tipi di contenuti ulteriori.					
In che modo gli sviluppatori accederanno ad amazon transcribe?									Il modo più semplice per iniziare è avviare un processo di trascrizione di un file audio tramite la console. Il servizio può però essere richiamato anche direttamente dall'interfaccia a riga di comando di AWS, oppure è possibile integrare con la propria applicazione uno dei kit SDK supportati. In ogni caso, è possibile iniziare a usare Amazon Transcribe per generare trascrizioni automatizzate di file audio tramite poche righe di codice.					
Amazon transcribe supporta le trascrizioni in tempo reale?									Sì. Amazon Transcribe consente di aprire un flusso bidirezionale su HTTP2. Puoi inviare un flusso audio al servizio e ricevere nello stesso momento un flusso di testo in tempo reale. Per maggiori dettagli, consulta la documentazione.					
Quale codifica supporta la trascrizione in tempo reale?									I tipi di media supportati fanno differenza tra trascrizioni in batch e trascrizioni in streaming, sebbene i formati senza perdita di dati siano consigliati per entrambi. Per maggiori dettagli, consulta la documentazione.					
Quali lingue supporta amazon transcribe?									Per ulteriori informazioni sulle lingue supportate, consulta la pagina della documentazione.					
Con quali dispositivi è compatibile amazon transcribe?									Amazon Transcribe opera su quasi ogni dispositivo. In generale, è compatibile con tutti i dispositivi in cui sia integrato un microfono, come telefoni, PC, tablet e dispositivi IoT (ad esempio, sistemi audio per automobili). L'API di Amazon Transcribe è in grado di rilevare la qualità del flusso audio di input (8 kHz o 16 kHz) e selezionerà di conseguenza i modelli acustici idonei per la conversione di voce in testo. Inoltre, gli sviluppatori potranno richiamare l'API Amazon Transcribe tramite le loro applicazioni per dispositivi per utilizzare le funzionalità del servizio.					
Sono previste restrizioni alle dimensioni dei contenuti audio elaborati da amazon transcribe?									Le chiamate di servizio di Amazon Transcribe sono limitate a quattro ore (o 2 GB) per chiamata API per il servizio in batch. Il servizio di streaming può ospitare connessioni aperte fino a 4 ore.					
Quali linguaggi di programmazione supporta amazon transcribe?									Il servizio in batch di Amazon Transcribe supporta .NET, Go, Java, Javascript, PHP, Python e Ruby. Il servizio in tempo reale di Amazon Transcribe supporta gli SDK Java, Ruby e C++. È in arrivo un ulteriore supporto per SDK. Per maggiori dettagli, consulta la pagina Risorse e la documentazione.					
Le parole del mio vocabolario personalizzato non vengono riconosciute! cosa posso fare?									Il risultato del riconoscimento vocale dipende da una serie di fattori oltre alle voci del vocabolario personalizzato, quindi non è possibile avere alcuna certezza del fatto che se un termine è incluso nel vocabolario personalizzato viene riconosciuto correttamente. Tuttavia, il motivo più frequente è l'assenza della pronuncia corretta della parola personalizzata. Se non è ancora stata fornita la pronuncia della parola personalizzata, crearne una. Se è già stata fornita, ricontrollarne la correttezza o includere altre varianti della pronuncia, se necessario. Per farlo è sufficiente creare nel file del vocabolario personalizzato più voci con pronunce diverse. Consulta la documentazione relativa al vocabolario personalizzato per maggiori informazioni.					
Perché vedo un numero consistente di parole personalizzate nel mio output?									"I vocabolari personalizzati sono ottimizzati per un breve elenco di parole mirate; vocabolari più consistenti comportano una generazione eccessiva di parole personalizzate, specie quando contengono parole che vengono pronunciate in modo simile. Se l'elenco di cui si dispone è lungo, tentare di ridurlo lasciando soltanto le parole rare e le parole che si prevede siano effettivamente presenti nei propri file audio. Se disponi di un vocabolario consistente che interessa più casi d'uso, dividilo in elenchi distinti in base ai diversi casi d'uso. Le parole che sono brevi e hanno un suono simile a quello di molte altre parole possono comportare una generazione eccessiva (presenza di troppe parole personalizzate nell'output). È preferibile unire queste parole alle parole vicine ed elencarle come frasi separate da un trattino. Ad esempio, la parola personalizzata ""AD"" potrebbe venire inclusa in una frase, ad esempio ""Convertitore AD""."					
Esistono due modi per fornire la pronuncia, i campi ipa o soundslike nella tabella del vocabolario personalizzato. qual è il migliore?									Il metodo IPA consente una pronuncia molto più accurata. È bene fornire la pronuncia IPA se è possibile generare IPA (ad esempio, da un lessico che dispone della pronuncia IPA o da uno strumento di conversione online).					
Vorrei usare il metodo ipa ma non sono un esperto di linguistica. esiste uno strumento online che posso utilizzare?									Numerosi dizionari standard, come l'Oxford English Dictionary o il Cambridge Dictionary (incluse le rispettive versioni online) forniscono la pronuncia secondo l'IPA. Esistono anche convertitori online (ad es. easypronunciation.com o tophonetics.com per l'inglese); tuttavia, nella maggior parte dei casi questi strumenti si basano su altri dizionari e potrebbero non generare l'IPA corretto per alcune parole, come i nomi propri. Amazon Transcribe non approva espressamente alcuno strumento di terze parti.					
Devo utilizzare standard ipa diversi specifici di un accento diverso nell'ambito della stessa lingua (ad esempio, inglese usa o inglese britannico)?									È necessario utilizzare lo standard IPA appropriato per i file audio che verranno elaborati. Ad esempio, se prevedi di elaborare l'audio da persone che parlano inglese britannico, utilizza lo standard di pronuncia inglese britannico. La serie di simboli IPA consentiti può differire per le diverse lingue e i dialetti supportati da Amazon Transcribe; assicurarsi che le pronunce inserite contengano esclusivamente i caratteri consentiti. I dettagli sui set di caratteri IPA sono disponibili nella documentazione: Vocabolari personalizzati					
Come posso fornire la pronuncia servendomi del campo soundslike nella tabella del vocabolario personalizzato?									È possibile spezzare una parola o una frase in più porzioni e fornire la pronuncia per ciascuna porzione utilizzando l'ortografia standard della lingua per imitare il suono della parola. Ad esempio, in inglese si possono fornire i suggerimenti di pronuncia per la frase Los-Angeles in questo modo: loss-ann-gel-es. Il suggerimento per il nome Etienne avrebbe in inglese questo aspetto: eh-tee-en. Le diverse parti del suggerimento sono separate da un trattino (-). È anche possibile utilizzare uno qualsiasi dei caratteri consentiti nella lingua di immissione. Per maggiori informazioni, visita la pagina Vocabolari personalizzati.					
Come funziona quando esistono due modi diversi di fornire gli acronimi (con i punti e senza punti ma con la pronuncia)?									Se si usa un acronimo che contiene i punti, la pronuncia delle varie lettere viene generata internamente. Se non si usano i punti, occorre fornire la pronuncia nell'apposito campo. Per alcuni acronimi, non è ovvio se utilizzare una pronuncia ortografica o una pronuncia simile a una parola. Ad esempio, NATO spesso è pronunciato 'n eɪ t oʊ' (nay-toh) e non 'ɛn eɪ ti oʊ' (N. A. T. O.). Per maggiori informazioni, visita la pagina Vocabolari personalizzati.					
Dove posso trovare esempi di come utilizzare le pronunce personalizzate?									Puoi trovare formati di input di esempio ed esempi nella documentazione qui.					
Cosa succede se utilizzo un'ipa errata?									Se non sono sicuro, è meglio che eviti di inserire l'IPA? Il sistema utilizzerà la pronuncia fornita dall'utente; in tal modo aumentano le possibilità che la parola venga riconosciuta correttamente se la pronuncia è corretta e corrisponde a quanto è stato detto. Se non si è certi di poter generare l'IPA corretta, è consigliabile eseguire un confronto elaborando i propri file audio con un vocabolario che contenga le proprie pronunce IPA e con un vocabolario che contenga soltanto le parole (e, facoltativamente, i tipi di visualizzazione). Se non si fornisce alcuna pronuncia, il servizio utilizzerà un'approssimazione, che potrebbe o meno funzionare meglio di quanto è stato immesso.					
"Quando si usano i moduli displayas, posso visualizzare i set di caratteri che non hanno alcuna relazione con la lingua originale che si sta trascrivendo (ad esempio, output di ""street"" come ""街道"") sì. anche se le frasi possono utilizzare soltanto un set limitato di caratteri per la lingua specificata, i caratteri utf-8 diversi da \t (tab) sono consentiti nella colonna displayas. ?"									"D: quando si usano i moduli DisplayAs, posso visualizzare i set di caratteri che non hanno alcuna relazione con la lingua originale che si sta trascrivendo (ad esempio, output di ""Street"" come ""街道"") Sì. Anche se le frasi possono utilizzare soltanto un set limitato di caratteri per la lingua specificata, i caratteri UTF-8 diversi da \t (TAB) sono consentiti nella colonna DisplayAs."					
La redazione di contenuti automatici o di informazioni di identificazione personale (pii) è disponibile sia con le api in batch che per quelle in streaming per transcribe?									Sì, Amazon Transcribe supporta la redazione di contenuti automatici o la redazione di PII  sia per le API in batch che per quelle in streaming.					
Quali sono le lingue supportate per la redazione di contenuti automatici / l'identificazione e la redazione di pii?									Consulta la documentazione di Amazon Transcribe per informazioni sulla disponibilità delle lingue per la redazione di contenuti automatici e di PII.					
La redazione di contenuti automatici rivede anche le informazioni personali sensibili provenienti da fonti audio?									No, questa funzionalità non rimuove le informazioni personali sensibili da fonti audio. Tuttavia, Amazon Transcribe Call Analytics rimuove le informazioni personali sensibili sia dalle trascrizioni che dall'audio di origine. Visita questo link per maggiori dettagli su come l'analisi delle chiamate può redigere l'audio. Puoi rivedere le informazioni personali anche dall'audio sorgente utilizzando i timestamp di avvio e fine forniti nelle trascrizioni redatte per ogni istanza di un'enunciazione identificata su informazioni che consentono l'identificazione personale degli utenti. Fai riferimento alla soluzione di redazione audio per le API standard di Transcribe. Tuttavia, le API di Amazon Transcribe Call Analytics rimuovono le informazioni personali sensibili sia dalle trascrizioni che dall'audio sorgente. Per maggiori informazioni, consulta la documentazione di redazione audio di Call Analytics.					
Posso utilizzare la redazione di contenuti automatici per rivedere le informazioni personali da trascrizioni testuali esistenti?									No, la redazione di contenuti automatici funziona esclusivamente con audio come contenuti in entrata.					
Cos'altro devo sapere prima di utilizzare la redazione di contenuti automatici?									La redazione di contenuti automatici è progettata per identificare ed eliminare le informazioni di identificazione personale (PII). Tuttavia, a causa della natura prevedibile del machine learning, potrebbe non identificare ed eliminare tutte le istanze di PII presenti in una trascrizione generata dal servizio. Ti consigliamo di rivedere gli output forniti dalla redazione di contenuti automatici per assicurarti che soddisfino le tue esigenze.					
Ci sono differenze tra la redazione di contenuti automatici per le api in streaming e quelle in batch?									Sì, sono due le funzionalità aggiuntive supportate dalla redazione di contenuti automatici per la API in streaming che non sono supportate dall'API in batch. Puoi decidere di identificare soltanto, e non rivedere, le PII quando usi la redazione di contenuti con l'API in streaming. Con l'API in streaming puoi inoltre identificare o rivedere specifici tipi di PII. Per esempio, puoi rivedere solo il numero di sicurezza sociale e le informazioni della carta di credito e mantenere altre PII come nomi e indirizzi e-mail.					
In quali regioni aws sono disponibili la redazione di contenuti automatici o la redazione di pii?									Consulta la documentazione di Amazon Transcribe per informazioni sulla disponibilità della redazione di contenuti automatici e la redazione di PII per le API in batch e quelle in streaming nelle regioni AWS.					
Quali api supportano l'identificazione automatica della lingua?									Al momento l'identificazione automatica della lingua è supportata dalle API in batch e in streaming.					
Quali lingue può identificare automaticamente amazon transcribe?									Amazon Transcribe può identificare una qualsiasi delle lingue supportate dalle API in batch e in streaming. Consulta questa sezione per i dettagli delle lingue supportate e delle funzionalità specifiche della lingua.					
Amazon transcribe identifica più lingue nello stesso file audio?									Amazon Transcribe supporta ID multilingua per il batch. Per maggiori dettagli, consulta questo link.					
Esiste un modo per limitare la lista delle lingue che possono essere scelte dall'identificazione automatica delle lingue?									Sì, puoi specificare un elenco di lingue che potrebbero essere presenti nella tua libreria multimediale. Quando fornisci un elenco delle lingue, la selezione della lingua identificata verrà effettuata da quell'elenco. Se non viene fornito un elenco delle lingue, il sistema elaborerà il file audio con tutte le lingue supportate da Amazon Transcribe e selezionerà la più probabile. L'accuratezza per l'identificazione della lingua migliora quando fornisci un elenco delle lingue, da cui poter scegliere. Per maggiori dettagli, consulta questo link.					
Quanto costa?									Consulta la pagina dei prezzi di Amazon Transcribe per ulteriori informazioni.	Consulta la pagina dei prezzi di Amazon Translate per ulteriori informazioni.				
In quali regioni aws è disponibile amazon transcribe?									Consulta la tabella delle regioni per l'infrastruttura globale di AWS. Consulta questa sezione per maggiori dettagli sugli endpoint e le quote di Amazon Transcribe.					
In che modo aws utilizza gli input vocali elaborati e salvati da amazon transcribe?									Amazon Transcribe può memorizzare e utilizzare gli input vocali elaborati dal servizio, esclusivamente per erogare e mantenere attivo il servizio, oltre a migliorare e sviluppare la qualità di Amazon Transcribe e di altre tecnologie di Machine Learning e Intelligenza Artificiale di Amazon. L'utilizzo dei contenuti è importante nell'ottica di miglioramento costante dell'esperienza utente di Amazon Transcribe, nonché per lo sviluppo e la formazione di tecnologie correlate. Amazon non utilizzerà eventuali informazioni che consentono l'identificazione personale, presenti nei tuoi contenuti, per creare prodotti, servizi o materiale di marketing mirati a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli scrupolosi e sofisticati, sia tecnici sia fisici (inclusa la crittografia su dati in transito e inattivi), progettati per impedire accessi non autorizzati e divulgazione di informazioni riservate e garantire che l'utilizzo dei contenuti da parte nostra sia conforme agli impegni presi nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare i contenuti per migliorare e sviluppare la qualità di Amazon Transcribe e di altre tecnologie di machine learning e intelligenza artificiale di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare esplicitamente, consulta la sezione Policy di esclusione dei servizi di IA.					
Posso eliminare dati e artefatti associati ai lavori di trascrizione archiviati da amazon transcribe?									Sì. È possibile utilizzare la funzione Elimina API disponibile per eliminare dati e altri artefatti associati ai lavori di trascrizione. In caso di problemi durante l'operazione, contatta AWS Support.					
Chi ha accesso ai contenuti elaborati e memorizzati da amazon transcribe?									Solo i dipendenti autorizzati potranno accedere ai contenuti elaborati da Amazon Transcribe. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli scrupolosi e sofisticati, sia tecnici sia fisici (inclusa la crittografia su dati in transito e inattivi), progettati per impedire accessi non autorizzati e divulgazione di informazioni riservate e garantire che l'utilizzo dei contenuti da parte nostra sia conforme agli impegni presi nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.					
I contenuti elaborati e memorizzati da amazon transcribe rimangono di mia proprietà?									Manterrai la proprietà sui contenuti; Amazon li userà solo previo consenso.					
Cosa succede ai miei dati utilizzati per formare modelli di linguaggio personalizzati?									Saranno sempre di mia proprietà? Quando invii dati di testo utilizzati per addestrare un modello dedicato, sei il proprietario sia dei dati di testo originali che di quelli del modello personalizzato generato. I dati di testo non verranno archiviati, né utilizzati per migliorare il nostro motore di riconoscimento vocale generale. I modelli prodotti utilizzando CLM sono autonomi e accessibili solamente dal cliente.					
Visto che il servizio non manterrà i miei dati di formazione, esistono svantaggi o sono possibili riduzioni alla qualità della trascrizione o dell'esperienza generale con il servizio?									La trascrizione non subirà alcuna riduzione in termini di qualità a causa della mancata archiviazione dei dati da parte del servizio. Dopo aver utilizzato i dati di formazione per produrre un modello di linguaggio personalizzato, il modello sarà disponibile per l'utilizzo, a tua discrezione. Il set di formazione originale caricato viene eliminato dai nostri sistemi. L'unico svantaggio è dato dalla necessità di supporto tecnico. Poiché non manteniamo i dati di formazione originali, non abbiamo accesso a tali asset o ai relativi artefatti intermedi, se mai dovessi avere bisogno del team di supporto per indagare problematiche potenziali del servizio. Il supporto sarà comunque disponibile ma probabilmente non efficace fin da subito, poiché è probabile che avremo bisogno di chiederti informazioni aggiuntive.					
Come posso riutilizzare i dati per miglioramenti o aggiornamenti futuri?									Poiché i dati di formazione non vengono archiviati, sarà necessario caricare di nuovo lo stesso set di dati o qualsiasi altro dato aggiuntivo per formare nuovi modelli. In presenza di un aggiornamento al modello di base fornito da Amazon Transcribe, ti arriverà una notifica. Per sfruttare il modello di base più recente, devi inviare i dati per formare un nuovo modello. Avrai quindi il modello personalizzato originale generato in precedenza e la nuova versione da utilizzare.					
Come posso eliminare un modello?									Puoi eliminare qualsiasi modello linguistico del cliente che hai generato, a tua discrezione.					
I contenuti elaborati da amazon transcribe vengono trasferiti all'esterno della regione aws in cui è in uso il servizio?									I contenuti elaborati da Amazon Transcribe vengono crittografati e memorizzati su disco nella regione AWS in cui è in uso Amazon Transcribe. I contenuti elaborati da Amazon Transcribe possono essere parzialmente archiviati in un'altra regione AWS, esclusivamente con la finalità di un miglioramento costante e dello sviluppo della tua esperienza di cliente Amazon Transcribe e di altre tecnologie di Machine Learning e Intelligenza Artificiale di Amazon. Se scegli di non utilizzare i contenuti per migliorare e sviluppare la qualità di Amazon Transcribe e di altre tecnologie di Machine Learning e Intelligenza Artificiale di Amazon, i tuoi contenuti non verranno archiviati in un'altra regione AWS. Puoi richiedere l'eliminazione degli input vocali associati al tuo account, contattando AWS Support. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.					
È possibile utilizzare amazon transcribe in connessione con siti web, programmi o altre applicazioni rivolti o destinati a minori di 13 anni e soggette alle norme previste dal children's online privacy protection act (coppa)?									Sì; in conformità con i Termini del servizio di Amazon Transcribe, nonché adempiuto l'obbligo di fornire il necessario preavviso e ottenuto l'eventuale consenso dei genitori secondo quanto prescritto dal COPPA, sarà possibile utilizzare il servizio in connessione con siti web, programmi o altre applicazioni rivolti o destinati, del tutto o in parte, ai minori di 13 anni.					
Cos’è amazon transcribe call analytics?									Amazon Transcribe Call Analytics è un'API alimentata dall'IA che fornisce ricche trascrizioni di chiamate e informazioni dettagliate di conversazione utilizzabili che è possibile aggiungere alle applicazioni di chiamata per migliorare l'esperienza cliente e la produttività degli agenti. Combina potenti modelli di riconoscimento vocale e di elaborazione del linguaggio naturale (NLP) personalizzati che sono addestrati specificamente per comprendere le chiamate del servizio clienti e di vendita in uscita. Come parte delle soluzioni AWS Contact Center Intelligence (CCI), questa API è agnostica per i contact center e facilita ai clienti e ai produttori di software indipendenti l'aggiunta di funzionalità di analisi delle chiamate alle applicazioni.  D: Che cosa è possibile fare con Amazon Transcribe Call Analytics?  Amazon Transcribe Call Analytics può eseguire analisi in tempo reale e post-chiamata. Con Call Analytics puoi aggiungere rapidamente informazioni preziose come i punteggi del sentimento dei clienti e degli agenti, gli aspetti principali delle chiamate e le categorie delle chiamate direttamente come output API a qualsiasi applicazione per le chiamate in entrata o in uscita. I casi d'uso comuni includono l'assistenza dell'agente, gli avvisi del supervisore e l'analisi delle chiamate. Ecco due soluzioni di esempio open source basate su Transcribe Call Analytics: Analisi delle chiamate in tempo reale con assistenza all'agente e Analisi post chiamate.  D: Come si inizia a usare Amazon Transcribe Call Analitycs?   È possibile utilizzare Transcribe Call Analytics attraverso le API e la Console di gestione AWS. I processi di analisi possono essere creati e monitorati attraverso l'API o la console. Nella console sarà visibile un elenco di processi di analisi e una pagina di dettagli del lavoro con parametri di input e un'anteprima dell'output JSON. Oltre a questo, sarà possibile creare e modificare le categorie attraverso le API o la console per la funzione di categorizzazione automatica dei contatti.  D: Quali lingue supporta Amazon Transcribe Call Analytics?  Consulta la documentazione di Amazon Transcribe per informazioni sulla disponibilità delle lingue per la redazione di contenuti automatici e di PII.  D: In quali regioni AWS è disponibile Amazon Transcribe Call Analytics? Consulta la documentazione dei servizi regionali AWS per informazioni sulla copertura delle regioni AWS per Amazon Transcribe Call Analytics.					
Come funzionano i prezzi per amazon transcribe call analytics?									L'API Amazon Transcribe Call Analytics ha un prezzo separato dalle API standard di Amazon Transcribe. Per ulteriori dettagli, consulta la pagina dei prezzi di Amazon Transcribe.					
Cos'è amazon transcribe medical?									Amazon Transcribe Medical è un servizio di riconoscimento vocale automatico (ASR) che semplifica agli sviluppatori il compito di aggiungere capacità di sintesi vocale di contenuti medici alle proprie applicazioni. Usando Amazon Transcribe Medical, puoi trascrivere in modo rapido e accurato discorsi medici e conversazioni vocali e convertirli in testo per una varietà di scopi, come la registrazione delle note dei dottori o l'elaborazione nell'analisi del testo a valle per estrarre intuizioni significative.					
Che cosa è possibile fare con amazon transcribe medical?									Amazon Transcribe Medical utilizza modelli avanzati di machine learning per trascrivere accuratamente i discorsi medici in testo. Transcribe Medical può generare trascrizioni di testo che possono essere utilizzati per supportare una varietà di casi d'uso, spaziando dal flusso di lavoro della documentazione clinica e dal monitoraggio della sicurezza dei farmaci (farmacovigilanza) al sottotitolaggio per la telemedicina e persino l'analisi dei contact center nei settori sanitario e scientifico.					
Per utilizzare amazon transcribe medical è necessario essere un esperto di riconoscimento vocale automatico (asr)?									No, non è necessaria alcuna competenza ASR o di machine learning per utilizzare Amazon Transcribe Medical. È solo necessario chiamare l'API di Transcribe Medical e il servizio gestirà il machine learning richiesto nel back-end per trascrivere il discorso medico in testo.					
Come si inizia a usare amazon transcribe medical?									Puoi iniziare a utilizzare Amazon Transcribe Medical dalla console di gestione AWS oppure dall’SDK. Fai riferimento a questa pagina della documentazione tecnica per ulteriori informazioni. Amazon Transcribe Medical offre un piano gratuito che ti consente di provare il servizio. Consulta la pagina dei prezzi, per ulteriori informazioni.					
Quali lingue supporta amazon transcribe medical?									Amazon Transcribe Medical attualmente supporta la trascrizione medica in inglese (USA).					
Quali specialità mediche supporta amazon transcribe medical?									Amazon Transcribe Medical supporta la trascrizione di un gamma in continua espansione di aree di medicina generale e specialistica. Consulta la documentazione per un elenco completo delle specialità mediche supportate.					
In quali regioni aws è disponibile amazon transcribe medical?									Consulta la documentazione dei servizi regionali AWS per informazioni sulla copertura delle regioni AWS per Amazon Transcribe Medical.					
Qual è il prezzo di amazon transcribe medical?									Per informazioni sui prezzi, consulta la pagina dei prezzi di Amazon Transcribe Medical.					
Amazon transcribe medical è conforme alla normativa hipaa?									Sì.					
Il contenuto elaborato da amazon transcribe medical viene utilizzato per uno scopo diverso dall’erogazione del servizio?									Amazon Transcribe Medical non utilizza il contenuto elaborato dal servizio per finalità differenti dall’erogazione e la gestione del servizio. I contenuti elaborati dal servizio non vengono utilizzati per sviluppare o migliorare la qualità di Amazon Transcribe Medical o di altre tecnologie di machine learning/intelligenza artificiale di Amazon.					
Amazon transcribe medical apprende con il tempo?									Sì, Amazon Transcribe Medical usa il machine learning e viene continuamente addestrato per essere ottimizzato per i casi d'uso dei clienti. Amazon Transcribe Medical non archivia né usa i dati dei clienti utilizzati con il servizio per formare i modelli.					
Cos’altro devo sapere prima di utilizzare il servizio amazon transcribe medical?									Amazon Transcribe Medical non è un servizio che sostituisce il parere, la diagnosi o i trattamenti dei medici professionisti. Tu e i tuoi utenti finali siete responsabili di esercitare la vostra discrezione, l’esperienza e il giudizio per determinare la correttezza, la completezza, la puntualità e l’adeguatezza delle informazioni fornite da Amazon Transcribe Medical. Tu e i tuoi utenti finali siete gli unici responsabili di eventuali decisioni, consulenze, azioni e/o mancanza di azioni basate sull’utilizzo di Amazon Transcribe Medical. Amazon Transcribe Medical potrebbe non identificare con accuratezza le informazioni sanitarie in ogni circostanza e non soddisfa i requisiti per la de-identificazione delle informazioni sanitarie protette in conformità con HIPAA. Tu sei responsabile di esaminare i contenuti restituiti da Amazon Transcribe Medical per assicurarti che soddisfi le tue esigenze.					
Quale funzionalità forniscono oggi i modelli di linguaggio personalizzati?									Puoi usare i modelli di linguaggio personalizzati per addestrare e sviluppare modelli di linguaggio specifici di un dato dominio. I modelli di linguaggio personalizzati (CLM, custom language models) attualmente supportano l'inglese (Australia), inglese (Gran Bretagna), hindi, inglese (Stati Uniti) e spagnolo (Stati Uniti) per trascrizioni di batch e inglese (Stati Uniti) per trascrizioni streaming. I modelli di linguaggio personalizzati supportano l'utilizzo simultaneo del vocabolario personalizzato per trascrizioni di batch.					
Quanti e quali tipi di dati di formazione sono necessari?									Come ottengo i dati? I dati devono essere in un formato specifico? I dati di testo devono essere rilevanti per l'audio che verrà trascritto utilizzando il modello personalizzato, devono contenere il numero più alto possibile di parole specifiche del settore, frasi e combinazioni di parole. Raccomandiamo di utilizzare almeno 100.000 e massimo 10.000.000 parole di testo in esecuzione. Le risorse di dati di testo possono essere ottenute da qualsiasi origine pubblica o proprietaria (per esempio, il testo proveniente dai siti Web dei clienti). Raccomandiamo che ogni file di testo contenga almeno 200.000 parole, senza superare le dimensioni di 1 GB per file. Il testo deve essere in formato UTF-8 e utilizzare una frase per riga. Ogni frase deve contenere punteggiatura. Gli utenti sono responsabili della correttezza grammaticale, ortografica e la convalida del codice.					
Come posso utilizzare i modelli di linguaggio personalizzati (clm)?									Per addestrare un modello di linguaggio personalizzato i clienti possono semplicemente fornire i dati di testo in un bucket Amazon S3. Gli utenti possono utilizzare la console del servizio Amazon Transcribe per caricare ed elaborare i dati e formare un modello di linguaggio personalizzato. La formazione è totalmente automatizzate e richiede un intervento minimo da parte dell'utente. Quando il modello finale personalizzato è pronto, viene reso disponibile nell'account AWS del cliente per la trascrizione di file audio specifici di settore. Inoltre, i clienti possono formare più modelli personalizzati da utilizzare per una vasta gamma di casi d'uso.					
I miglioramenti sono garantiti?									Vale la pena spendere energie per la raccolta dei dati di testo? I miglioramenti non sono garantiti: l'aumento delle prestazioni dipende dal grado di corrispondenza tra audio e dati di testo e sulla quantità di dati di forniti. Una maggiore quantità di dati normalmente fa la differenza ma, soprattutto, i dati devono contenere parole e sequenze di parole che saranno contenute anche dall'audio che si intende trascrivere. I miglioramenti alla precisione delle trascrizioni dipenderà dalla qualità dei dati di formazione e dal caso d'uso. In alcuni scenari, il valore di riferimento generale indica un aumento della precisione relativa dal 10 al 15%.					
Quanto dura la formazione di un modello?									Sarò in grado di utilizzarlo? Per formare un modello ci vogliono normalmente tra le 6 e le 10 ore. La durata della formazione dipende dalla grandezza del set di dati. Il modello personalizzato sarà disponibile subito dopo il completamento della formazione.					
In che modo potrò utilizzare il modello?									Come posso capire se funziona meglio del modello generico fornito da Amazon Transcribe? Il modello sarà disponibile nell'account con un ID modello da te assegnato prima del processo di addestramento. Per utilizzare il modello, la richiesta di trascrizione deve essere contrassegnata con il relativo ID. Dovresti testare il modello sui tuoi file audio e confrontare l'output con quello ottenuto dal motore generico.					
Quanti modelli di linguaggio personalizzati posso addestrare?									Posso avere più modelli abilitati simultaneamente nello stesso account? Al momento, puoi formare fino a 5 modelli diversi per ogni account AWS. Per ogni account puoi archiviare fino a 10 modelli per impostazione predefinita. Il limite può essere aumentato qui se necessario.					
Sono supportati i modelli acustici personalizzati?									No. I modelli acustici personalizzati non sono supportati. I modelli di linguaggio personalizzati vengono creati a partire da dati di testo inerenti al caso d'uso o dominio.					
Cos'è amazon translate?										Amazon Translate è un servizio di traduzione automatica neurale per la traduzione di testo tra lingue supportate. Grazie ai metodi di deep learning, il servizio offre traduzioni di alta qualità, personalizzabili e a costi ridotti e permette agli sviluppatori di tradurre materiale aziendale o generato dagli utenti o di creare applicazioni che richiedono il supporto di più lingue. Il servizio può essere utilizzato tramite API per ottenere traduzione in tempo reale o in batch di un testo dalla lingua di origine alla lingua di destinazione.				
Quali sono le lingue supportate?										Amazon Translate supporta la traduzione tra le seguenti 75 lingue: afrikaans, albanese, amarico, arabo, armeno, azero, bengalese, bosniaco, bulgaro, catalano, ceco, cinese semplificato, cinese tradizionale, coreano, creolo haitiano, croato, danese, dari, ebraico, estone, farsi (persiano), finlandese, francese, francese (Canada), gallese, georgiano, giapponese, greco, gujarati, hausa, hindi, inglese, indonesiano, irlandese, islandese, italiano, kannada, kazako, lettone, lituano, macedone, malese, malayalam, maltese, mongolo, marathi norvegese, olandese, pashtu, polacco, portoghese, portoghese (Portogallo), punjabi, romeno, russo, serbo, singalese, slovacco, sloveno, somalo, spagnolo, spagnolo (Messico), svedese, swahili, tagalog, thailandese, tamil, tedesco, telugu, turco, ucraino, ungherese, urdu, uzbeko e vietnamita. Per ulteriori dettagli, consulta questa pagina della documentazione.				
Qual è il vantaggio di utilizzare amazon translate?										Amazon Translate permette di raggiungere un numero sempre maggiore di clienti, comunicando con loro in modo efficiente e riducendo di conseguenza il costo totale di proprietà. Molte aziende dispongono di enormi volumi di contenuti, creati internamente o dagli utenti dei loro servizi, e l'unico modo per renderli disponibili a diverse lingue in modo rapido è avvalersi della traduzione automatica. Poiché i costi di Amazon Translate non sono paragonabili a quelli di un professionista (lo 0,05% circa: 15 USD per milione di parole con Amazon Translate contro 30.000 USD per la traduzione con professionisti, in media), le aziende potranno permettersi di tradurre molti più contenuti rispetto al passato. Per i fornitori di servizi linguistici e rivenditori a valore aggiunto, Amazon Translate è un facilitatore per la crescita aziendale. Amazon Translate, infatti, permetterà di migliorare la produttività dei primi anche del 50%, consentendo ai traduttori freelance di concentrarsi sulla creazione di contenuti creativi di alta qualità. Amazon Translate consente inoltre di personalizzare l'esito della traduzione utilizzando la traduzione personalizzata attiva (ACT); i fornitori di servizi linguistici possono proteggere il proprio IP quando impiegano l'ACT per traduzioni personalizzate. I rivenditori di traduzioni potranno ampliare la propria dotazione di servizi senza assumere nuovo personale o rinnovare l'infrastruttura.				
Quali sono i casi d'uso più comuni per amazon translate?										Amazon Translate è un'ottima soluzione nei casi in cui il volume di contenuti sia elevato, la velocità un fattore importante e una certa tolleranza agli errori (seppure nella maggior parte dei casi minimi) accettabile. Ad esempio, l'output grezzo di Amazon Translate è molto utile quando è necessario estrarre informazioni da un testo particolarmente lungo in diverse lingue, permettere ai clienti di effettuare ricerche all'interno dell'applicazione nella propria lingua, rendere disponibili in diverse lingue contenuti creati dagli utenti (ad esempio in forum e per assistenza), capire il senso di questionari o sondaggi o pubblicare bozze di un testo. Con l'aggiunta di un servizio di post-editing leggero, Amazon Translate potrà essere utilizzato per facilitare l'assistenza o pubblicare ad esempio specifiche di prodotti, confronti con la concorrenza, domande frequenti e contenuti di supporto. Con un post-editing più marcato, è anche possibile utilizzare Amazon Translate per tradurre contenuti ad elevata visibilità o aziendali, ad esempio materiale pubblicitario o di marketing, contratti e così via.				
In che modo è possibile utilizzare il servizio?										Il mezzo più semplice per iniziare a utilizzare Amazon Translate è la console. Il servizio può però essere richiamato anche direttamente dall'interfaccia a riga di comando di AWS, oppure è possibile integrare con la propria applicazione uno dei kit SDK, in base al linguaggio utilizzato. In entrambi i casi, sono sufficienti poche righe di codice per iniziare a usare Amazon Translate. È possibile inoltrare il testo da tradurre all'API indicando la lingua sorgente e la lingua di destinazione. Amazon Translate restituirà il testo tradotto. L'API può essere utilizzata in tre modi: in primo luogo, può essere integrata nell'applicazione per tradurre componenti dinamici come le chat. In alternativa, è possibile connetterla ad altri servizi per fornire elaborazione multilingue. Ad esempio, un servizio di database come Amazon Relational Database Service (RDS) può essere richiamato tramite un piano AWS Lambda per consentire la localizzazione di contenuti parzialmente dinamici, quali recensioni e post di un forum. Infine, è possibile tradurre batch di documenti. Ad esempio, le aziende di servizi finanziari possono tradurre e monitorare gli articoli in qualsiasi lingua; i reparti legali possono individuare materiale relativo a una causa indipendentemente dalla lingua (eDiscovery), i consulenti per brevetti potranno eseguire ricerche su materiali coperti da proprietà intellettuale in tutto il mondo.				
Il servizio fornisce il rilevamento automatico della lingua sorgente?										Amazon Translate accetta testo non strutturato e flag di lingua che indicano l'idioma sorgente e quello di destinazione. Se la lingua sorgente non è nota, Amazon Translate impiegherà automaticamente Amazon Comprehend per riconoscere la lingua e riportarla per ottenere una traduzione nella lingua di destinazione.				
Quali input supporta il servizio?										Amazon Translate supporta input di testo non strutturato in formato UTF-8.				
Quali limitazioni prevede l'api?										Le chiamate del servizio Amazon Translate sono limitate a 5.000 byte per chiamata API. AWS fornisce istruzioni su come suddividere documenti di grandi dimensioni in sezioni e paragrafi per poter tradurre testi di qualsiasi lunghezza. Consulta tali istruzioni qui. Il servizio di traduzione in batch asincrono di Amazon Translate accetta batch di dimensioni fino a 5 GB per chiamata API con documenti non più grandi di 20 MB, ogni documento contenente non più di 1.000.000 di caratteri e massimo 1.000.000 milione di documenti per batch nella cartella del bucket S3. Il servizio Amazon Translate è altamente scalabile. I limiti predefiniti possono essere consultati qui.				
È necessario dichiarare che la traduzione è stata eseguita da amazon?										Oppure tramite traduzione automatica? Non è necessario indicare l'autore delle traduzioni, ma si consiglia comunque di informare i clienti che il testo proviene da un motore di traduzione automatica.				
Come si richiede assistenza tecnica?										"In che modo è possibile inviare un feedback? Per ottenere assistenza, contatta il servizio clienti di AWS. Eventuali commenti possono essere inoltrati tramite il servizio clienti oppure tramite l'opzione ""Feedback"" nella console di Amazon Translate."				
In quali regioni aws è disponibile amazon translate?										Consulta la tabella delle regioni per l'infrastruttura globale di AWS. La traduzione in batch di Amazon Translate è disponibile negli Stati Uniti orientali 1 (Virginia settentrionale), Stati Uniti orientali 2 (Ohio), Stati Uniti occidentali 2 (Oregon), UE occidentale 1 (Irlanda), UE occidentale 2 (Londra), UE Centrale 2 (Francoforte) e Asia Pacifico nord orientale 1 (Seul).				
Le richieste in cui non viene eseguita alcuna traduzione vengono addebitate?										"Richieste in cui la lingua di origine è uguale alla lingua di destinazione (se l'utente è stato designato o identificato automaticamente) e quando si verifica un errore e non viene restituita alcuna traduzione, non vengono addebitate. Richieste in cui il contenuto non è traducibile (ad es. ""& * ^% ((** & (^"") vengono addebitate."				
Gli input di testo elaborati da amazon translate vengono salvati?										In che modo li utilizza AWS? Amazon Translate potrà memorizzare e utilizzare gli input di testi elaborati dal servizio esclusivamente per erogare ed eseguire la manutenzione del servizio e per migliorare e sviluppare Amazon Translate e altre tecnologie di apprendimento automatico o intelligenza artificiale di Amazon. L'utilizzo dei contenuti è importante nell'ottica di costante miglioramento dell'esperienza utente del servizio Amazon Translate, nonché per lo sviluppo e la formazione di tecnologie correlate. Non usiamo alcun dato di identificazione personale eventualmente presente nei tuoi contenuti per proporre prodotti, servizi o attività marketing a te o ai tuoi utenti finali. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli scrupolosi e sofisticati, sia tecnici sia fisici (inclusa la crittografia su dati in transito e inattivi), progettati per impedire accessi non autorizzati e divulgazione di informazioni riservate e garantire che l'utilizzo dei contenuti da parte nostra sia conforme agli impegni presi nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/. Puoi scegliere di non utilizzare i contenuti per migliorare e sviluppare la qualità di Amazon Translate e di altre tecnologie di machine learning e intelligenza artificiale di Amazon, utilizzando una policy di esclusione di AWS Organizations. Per ulteriori informazioni su come rifiutare, consulta Gestione della policy di esclusione dei servizi di AI.				
Chi avrà accesso ai contenuti elaborati e memorizzati da amazon translate?										Solo i dipendenti autorizzati potranno accedere ai contenuti elaborati da Amazon Translate. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli adeguati e sofisticati, a livello tecnico e fisico, tra cui la crittografia sia in condizioni statiche che durante i trasferimenti, per impedire gli accessi non autorizzati e la divulgazione dei contenuti e per garantire che l'utilizzo da parte nostra sia conforme ai nostri impegni nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.				
I contenuti elaborati e memorizzati da amazon translate rimangono di mia proprietà?										I contenuti rimarranno di tua proprietà; Amazon li userà solo previo consenso.				
I contenuti elaborati da amazon translate vengono trasferiti all'esterno della regione aws in cui è in uso il servizio?										I contenuti elaborati da Amazon Translate vengono crittografati e memorizzati su disco nella regione AWS in cui è in uso il servizio. I contenuti elaborati da Amazon Translate possono essere parzialmente archiviati in un'altra regione AWS esclusivamente per finalità di costante miglioramento e sviluppo della tua esperienza di cliente Amazon Translate e di altre tecnologie di apprendimento automatico e intelligenza artificiale di Amazon. La tua fiducia, la tua privacy e la sicurezza dei tuoi contenuti rappresentano la nostra massima priorità. Implementiamo controlli scrupolosi e sofisticati, sia tecnici sia fisici (inclusa la crittografia su dati in transito e inattivi), progettati per impedire accessi non autorizzati e divulgazione di informazioni riservate e garantire che l'utilizzo dei contenuti da parte nostra sia conforme agli impegni presi nei tuoi confronti. Per ulteriori informazioni consulta la pagina https://aws.amazon.com/compliance/data-privacy-faq/.				
È possibile utilizzare amazon translate in connessione con siti web, programmi o altre applicazioni rivolti o destinati a minori di 13 anni e soggette alle norme previste dal children's online privacy protection act (coppa)?										Sì; in conformità con i Termini dei servizi AWS, nonché adempiuto l'obbligo di fornire il necessario preavviso e ottenuto l'eventuale consenso dei genitori secondo quanto prescritto dal COPPA, sarà possibile utilizzare Amazon Translate in connessione con siti web, programmi o altre applicazioni rivolti o destinati, del tutto o in parte, ai minori di 13 anni.				
Cos'è amazon sagemaker?											Amazon SageMaker è un servizio completamente gestito per preparare i dati e costruire, addestrare e implementare modelli di machine learning (ML) per qualsiasi caso d'uso impiegando infrastrutture, strumenti e flussi di lavoro completamente gestiti.			
In quali regioni è disponibile amazon sagemaker?											Per un elenco delle regioni AWS supportate da Amazon SageMaker, consulta la pagina dei servizi per regione AWS. Per ulteriori informazioni, consulta inoltre la pagina Endpoint regionali nella guida di riferimento generale.			
Qual è la disponibilità del servizio amazon sagemaker?											Amazon SageMaker è progettato per offrire disponibilità elevata. Non sono previsti finestre di manutenzione o tempi di inattività pianificati. Le API SageMaker vengono eseguite nei data center sicuri e ad elevata disponibilità di Amazon, con replica dello stack di servizi configurata fra tre strutture in ogni regione AWS per offrire tolleranza ai guasti in caso di inattività di un server o di interruzione del servizio nella zona di disponibilità.			
In che modo amazon sagemaker protegge il codice?											Amazon SageMaker memorizza il codice in volumi di storage per l'apprendimento automatico, protetti da gruppi di sicurezza crittografabili su disco.			
Quali misure di sicurezza implementa amazon sagemaker?											Amazon SageMaker crittografa gli artefatti di modello di ML e di altri elementi del sistema, sia inattivi sia in transito. Le richieste all'API e alla console di SageMaker vengono inoltrate tramite una connessione sicura (SSL). Puoi avvalerti dei ruoli AWS Identity and Access Management in SageMaker per fornire le autorizzazioni per accedere alle risorse per l'addestramento e l'implementazione per tuo conto. È possibile utilizzare bucket Amazon Simple Storage Service (Amazon S3) crittografati per dati e artefatti di modello, nonché applicare una chiave del Servizio di gestione delle chiavi AWS (AWS KMS) a notebook di SageMaker, processi di addestramento ed endpoint per crittografare il volume di archiviazione dedicato al ML collegato. Amazon SageMaker supporta inoltre il cloud privato virtuale (VPC) di Amazon e AWS PrivateLink.			
Amazon sagemaker utilizza o condivide modelli, dati di addestramento o algoritmi?											Amazon SageMaker non utilizza o condivide modelli, dati di addestramento o algoritmi dei clienti. Sappiamo quanto i clienti si preoccupino per la privacy e la sicurezza dei dati. È per questo che, in AWS, hanno sempre il controllo e la proprietà sui loro contenuti; grazie a strumenti semplici ma efficaci possono determinare dove i dati saranno memorizzati, proteggere le informazioni dei loro clienti sia in transito sia inattive e gestire l'accesso ai servizi e alle risorse di AWS per i loro utenti. AWS implementa anche controlli scrupolosi e sofisticati, sia tecnici sia fisici, progettati per impedire accessi non autorizzati e divulgazione di dati riservati. La proprietà dei dati rimane al cliente, che potrà scegliere a quali servizi AWS consentirne elaborazione, memorizzazione e hosting. AWS non accede né utilizza i contenuti dei clienti per alcun motivo senza il loro consenso.			
Come viene fatturato l'utilizzo di amazon sagemaker?											Verranno addebitati i costi delle risorse di storage e di elaborazione dati e apprendimento automatico utilizzate per hosting del notebook, addestramento di modelli, elaborazione di previsioni e registrazione dei risultati. Amazon SageMaker permette di selezionare il numero e il tipo di istanze da utilizzare per il notebook in hosting, l'addestramento e l'hosting del modello. I prezzi sono calcolati solo in base all'uso effettivo, senza tariffe minime né impegni anticipati. Consulta la pagina dei prezzi di Amazon SageMaker per i dettagli e il Calcolatore Prezzi di Amazon SageMaker per i dettagli.			
Come posso ottimizzare i costi di amazon sagemaker, ad esempio individuando e arrestando risorse inattive per evitare addebiti superflui?											Esistono varie best practice da adottare per ottimizzare l'utilizzo delle risorse di Amazon SageMaker. Alcuni approcci prevedono la messa a punto della configurazione, altre soluzioni programmatiche. Una guida completa sull'argomento, completa di tutorial visivi ed esempi di codice, è disponibile in questo post di blog.			
Se invece è già presente un notebook o un ambiente di formazione o hosting?											Amazon SageMaker offre un flusso di lavoro completo, ma è sempre possibile continuare a utilizzare gli strumenti esistenti insieme al servizio. Trasferire i risultati di ciascuna fase da o verso SageMaker in base ai requisiti aziendali è molto semplice.			
R è supportato da amazon sagemaker?											Sì, R è supportato da Amazon SageMaker. Puoi utilizzare R all'interno delle istanze SageMaker Notebook, che includono un kernel R preinstallato e la libreria reticolare. La libreria reticolare offre un'interfaccia R per il kit SDK di Amazon SageMaker Python, consentendo ai professionisti del ML di costruire, addestrare, ottimizzare e implementare modelli R.			
Come faccio a verificare eventuali squilibri nel mio modello?											Amazon SageMaker Clarify aiuta a migliorare la trasparenza del modello rilevando distorsioni statistiche nell’intero flusso di lavoro di ML. SageMaker Clarify verifica la presenza di squilibri durante la preparazione dei dati, dopo l’addestramento e nel corso del tempo, includendo strumenti che aiutano a spiegare i modelli di ML e le loro previsioni. È possibile condividere i risultati tramite report di spiegabilità.			
Che tipo di distorsione rileva amazon sagemaker clarify?											Misurare le distorsioni in modelli di ML è un primo passo verso il loro contenimento. È possibile misurare le distorsioni prima dell’addestramento e dopo l’addestramento, oltre che per l’inferenza per un modello distribuito. Ogni misura di distorsioni corrisponde a un concetto diverso di equità. Anche considerare semplici concetti di equità conduce a molte misure diverse applicabili in svariati contesti. Devi scegliere le metriche e i concetti di distorsione validi per l'applicazione e la situazione oggetto dell'indagine. SageMaker attualmente supporta l'elaborazione di differenti metriche di distorsione per i dati di addestramento (come parte della preparazione dei dati SageMaker), per il modello addestrato (come parte di Esperimenti Amazon SageMaker) e per l'inferenza per un modello implementato (come parte di Amazon SageMaker Model Monitor). Ad esempio, prima dell'addestramento forniamo metriche per controllare se i dati di addestramento sono rappresentativi (cioè se un gruppo è sottorappresentato) e se ci sono differenze nella distribuzione delle etichette tra i gruppi. Dopo la formazione o durante l’implementazione, i parametri possono risultare utili per misurare se (e di quanto) le prestazioni del modello differiscono tra i gruppi. Ad esempio, puoi iniziare confrontando i tassi di errore (qual è la possibilità che una previsione del modello differisca dall'etichetta vera?) o aggiungendo precisione (qual è la possibilità che una previsione positiva sia corretta?) e riconoscimento (con quale possibilità il modello contrassegnerà correttamente un esempio positivo?).			
Come fa amazon sagemaker clarify a migliorare la comprensibilità del modello?											Amazon SageMaker Clarify è integrato con Esperimenti Amazon SageMaker per fornire un grafico di importanza delle funzionalità che elenca l'importanza di ciascun input per il processo decisionale globale relativo al modello dopo che è stato addestrato. Questi dettagli possono aiutare a stabilire se un particolare input abbia più influenza di quanto dovrebbe sul comportamento generale del modello. SageMaker Clarify rende anche disponibili spiegazioni per le singole previsioni tramite un'API.			
Cos'è amazon sagemaker studio?											Amazon SageMaker Studio fornisce un'interfaccia visuale unica basata sul Web in cui si possono eseguire tutte le fasi di sviluppo del ML. SageMaker Studio offre accesso, controllo e visibilità completi su ogni fase necessaria alla progettazione, all'addestramento e all'implementazione dei modelli. Puoi velocemente caricare i dati, creare nuovi notebook, addestrare e regolare i modelli, andare avanti e indietro tra le fasi per modificare gli esperimenti, confrontare i risultati e implementare i modelli in produzione in un unico luogo, rendendo il tuo processo più produttivo. Tutte le attività di sviluppo con il machine learning che includono notebook, gestione degli esperimenti, creazione automatica dei modelli, profilatura, debug e rilevamento delle deviazioni del modello possono essere eseguite all'interno dell'interfaccia visiva unificata di SageMaker Studio.			
Cos'è rstudio su amazon sagemaker?											RStudio su Amazon SageMaker è il primo workbench RStudio completamente gestito nel cloud. Puoi avviare rapidamente l'ambiente di sviluppo integrato (IDE) RStudio dall'aspetto familiare e aumentare o diminuire le risorse di calcolo sottostanti senza interrompere il tuo lavoro, facilitando la costruzione di soluzioni di machine learning (ML) e analisi in R su vasta scala. È possibile passare facilmente tra i notebook con IDE RStudio e Amazon SageMaker Studio per lo sviluppo in R e Python. Ogni aspetto del tuo lavoro, compresi codice, set di dati, repository e altri artefatti, viene sincronizzato in automatico tra i due ambienti per ridurre lo switching di contesto e incrementare la produttività.			
Come sono calcolati i prezzi di amazon sagemaker studio?											Non sono previsti costi aggiuntivi per l'utilizzo di Amazon SageMaker Studio. Sono addebitati unicamente i costi base di elaborazione e di archiviazione per i servizi effettivamente utilizzati con Amazon SageMaker Studio.			
In quali regioni è disponibile amazon sagemaker studio?											L'elenco delle regioni in cui è disponibile Amazon SageMaker Studio è consultabile nella documentazione a questo link.			
Quali strumenti di governance del ml fornisce amazon sagemaker?											Amazon SageMaker fornisce strumenti di governance del ML creati ad hoc per l'intero ciclo di vita del ML. Con Amazon SageMaker Role Manager è possibile definire le autorizzazioni minime in pochi minuti. SageMaker Model Cards facilita l'acquisizione, il recupero e la condivisione di informazioni essenziali relative al modello, dalla concezione all'implementazione, mentre SageMaker Model Dashboard riunisce in un unico posto tutte le informazioni sul comportamento del modello in produzione. Ottieni ulteriori informazioni.			
Quale funzione ha amazon sagemaker role manager?											Con Amazon SageMaker Role Manager è possibile definire le autorizzazioni minime in pochi minuti. SageMaker Role Manager fornisce una serie di autorizzazioni di base per le attività di ML e una varietà di profili con un catalogo di policy IAM predefinite. È possibile mantenere le autorizzazioni di base oppure personalizzarle sulla base delle proprie specifiche esigenze. Con una serie di istruzioni autoguidate, è possibile immettere rapidamente costrutti di governance comuni, come limiti di accesso alla rete e chiavi di crittografia. Dopodiché, SageMaker Role Manager genererà automaticamente la policy IAM. È possibile consultare il ruolo generato e le policy associate dalla console AWS IAM. Per personalizzare ulteriormente le autorizzazioni in base al caso d'uso, è possibile collegare le policy IAM gestite al ruolo IAM creato con SageMaker Role Manager. Per facilitare l'identificazione del ruolo e consentire un maggiore coordinamento tra i servizi AWS, è possibile aggiungere tag.			
Quale è la funzione di amazon sagemaker model cards?											Amazon SageMaker Model Cards facilita la centralizzazione e la standardizzazione della documentazione del modello per l'intero ciclo di vita del ML consentendo di creare una singola fonte di attendibilità per le informazioni relative al modello. SageMaker Model Cards compila automaticamente i dettagli dell'addestramento per accelerare il processo di documentazione. Inoltre, è possibile aggiungere dettagli come lo scopo del modello e gli obiettivi di prestazione. È possibile collegare alla Model Card i risultati della rispettiva valutazione e fornire visualizzazioni per ottenere informazioni dettagliate chiave sulle sue prestazioni. Le SageMaker Model Card possono essere facilmente condivise con altre persone tramite l'esportazione in formato PDF.			
Quali sono le caratteristiche di amazon sagemaker model dashboard?											Amazon SageMaker Model Dashboard fornisce una panoramica completa dei modelli implementati e degli endpoint, consentendo di monitorare le risorse e le violazioni di comportamento dei modelli in un unico pannello. Grazie all'integrazione con Amazon SageMaker Model Monitor e Amazon SageMaker Clarify, consente di monitorare il comportamento dei modelli rispetto a quattro dimensioni, incluse la qualità dei dati e del modello nonché la deviazione di distorsione e di attribuzione delle funzionalità. Inoltre, SageMaker Model Dashboard fornisce un'esperienza integrata per impostare e ricevere avvisi in merito ai processi di monitoraggio dei modelli assenti o non attivi e sulle deviazioni del comportamento dei modelli rispetto a qualità del modello, qualità dei dati, deviazione di distorsione e deviazione di attribuzione delle funzionalità. È possibile analizzare nel dettaglio i singoli modelli e i fattori che hanno un impatto sulle prestazioni nel corso del tempo. Dopodiché, è possibile consultarsi con i professionisti del ML per intraprendere le opportune misure correttive.			
Come posso iniziare a utilizzare subito amazon sagemaker?											Amazon SageMaker JumpStart ti aiuta a iniziare a utilizzare il machine learning in modo facile e veloce. SageMaker JumpStart fornisce una serie di soluzioni per i casi d’uso più comuni che è possibile distribuire subito con pochi clic. Le soluzioni sono totalmente personalizzabili e mostrano l'utilizzo dei modelli e delle architetture di riferimento di AWS CloudFormation, in questo modo puoi accelerare nel percorso verso il ML. Inoltre, SageMaker JumpStart fornisce i modelli di base, supporta l'implementazione con un clic e il perfezionamento di oltre 150 modelli open source popolari come il trasformatore, il rilevamento di oggetti e la classificazione delle immagini.			
In che modo amazon sagemaker jumpstart contribuisce a proteggere e rendere sicuri i miei dati?											La sicurezza è la massima priorità di AWS e Amazon SageMaker JumpStart è progettato per essere sicuro. È per questo che SageMaker ti offre sempre il controllo e la proprietà sui tuoi contenuti; grazie a strumenti semplici ma efficaci che consentono di determinare dove i dati vengono archiviati, proteggere le informazioni dei contenuti sia in transito che a riposo e gestire l'accesso ai servizi e alle risorse di AWS per i tuoi utenti.			
Quali modelli di base sono disponibili in amazon sagemaker jumpstart?											Amazon SageMaker JumpStart fornisce due tipi di modelli di base: modelli disponibili al pubblico e modelli proprietari. I modelli disponibili al pubblico includono FLAN T5, Bloom, GTP-2 e Stable Diffusion che possono essere scoperti tramite SageMaker JumpStart nell'interfaccia utente di SageMaker Studio, JumpStart nella console AWS e tramite le API SageMaker JumpStart. Questi modelli possono essere ottimizzati e/o implementati sugli endpoint del tuo account AWS. Puoi possedere completamente i pesi dei modelli e i codici degli script. I processi di addestramento e gli endpoint vengono addebitati a tariffe orarie in base ai prezzi di SageMaker. I modelli proprietari come i modelli Jurassic di AI21, il modello Cohere di Cohere e il modello Lyra-Fr di LightOn possono essere scoperti anche tramite SageMaker JumpStart nella Console AWS e sono attualmente in anteprima. Puoi valutare i modelli proprietari con la funzione di prova e implementarli su un endpoint SageMaker utilizzando un notebook Jupyter di esempio. La valutazione dei modelli tramite la funzione di prova non comporta alcun costo, ma gli endpoint implementati tramite il notebook Jupyter per questi modelli vengono addebitati in base ai prezzi di SageMaker. I modelli proprietari sono disponibili in anteprima e i prezzi sono soggetti a modifiche.			
Come posso iniziare a utilizzare i modelli di base tramite amazon sagemaker jumpstart?											Per iniziare a utilizzare i modelli di base disponibili al pubblico, puoi accedere a SageMaker JumpStart in SageMaker Studio. Per un elenco di tutti i modelli di base disponibili al pubblico, consulta la pagina introduttiva. Per iniziare a utilizzare i modelli di base proprietari in anteprima, puoi accedere a SageMaker JumpStart nella Console AWS. L'esperienza di anteprima include la funzione di prova per ogni modello e un processo di abbonamento per i modelli proprietari.			
I miei dati (derivanti dall'inferenza o dall'addestramento) vengono utilizzati o condivisi per aggiornare il modello base offerto ai clienti che utilizzano amazon sagemaker jumpstart?											No. I dati di inferenza e addestramento non vengono utilizzati né condivisi per aggiornare o addestrare il modello base che SageMaker JumpStart offre ai clienti.			
Posso vedere i pesi e gli script dei modelli proprietari in anteprima con amazon sagemaker jumpstart?											No. I modelli proprietari non consentono ai clienti di visualizzare i relativi pesi e script.			
Quali modelli open source sono supportati da amazon sagemaker jumpstart?											Amazon SageMaker JumpStart include oltre 150 modelli open source precedentemente addestrati da PyTorch Hub e TensorFlow Hub. Per attività visive come classificazioni di immagini e rilevamento di oggetti, è possibile usare modelli come ResNet, MobileNet e Single-Shot Detector (SSD). Per attività testuali come classificazioni di frasi, classificazione di testi e risposte a domande è possibile utilizzare modelli come BERT, RoBERTa e DistilBERT. Quali sono le soluzioni precostruite con Amazon SageMaker JumpStart? SageMaker JumpStart offre soluzioni preconfigurate con tutti i servizi AWS necessari per avviare una soluzione in produzione. Le soluzioni sono totalmente personalizzabili, in modo da poterle modificare in base al proprio specifico caso d’uso e set di dati. È possibile utilizzare soluzioni per oltre 15 casi d’uso tra cui previsione della domanda. rilevamento di frodi e manutenzione predittiva, nonché implementare rapidamente soluzioni con pochi clic. Per ulteriori informazioni su tutte le soluzioni disponibili, visita la pagina delle nozioni di base di SageMaker.			
Come si condividono gli artefatti di ml con altre persone all'interno di un'organizzazione?											Con Amazon SageMaker JumpStart, data scientist e sviluppatori di ML possono condividere con facilità gli artefatti di ML, tra cui notebook e modelli, all'interno dell'organizzazione. Gli amministratori possono configurare un repository accessibile da un insieme di utenti prestabilito. Tutti gli utenti muniti di autorizzazioni di accesso al repository possono sfogliare, cercare e utilizzare modelli e notebook, nonché i contenuti pubblici all'interno di SageMaker JumpStart. Gli utenti possono selezionare artefatti per addestrare modelli, implementare endpoint ed eseguire notebook in SageMaker JumpStart.			
Perché dovrei utilizzare amazon sagemaker jumpstart per condividere gli artefatti di ml con altre persone all'interno della mia organizzazione?											Utilizzando Amazon SageMaker JumpStart, puoi accelerare il time-to-market quando sviluppi applicazioni di ML. Modelli e notebook costruiti da un team possono facilmente essere condivisi con altri team all'interno della tua organizzazione con pochi clic. La condivisione delle informazioni interne e il riutilizzo delle risorse può aumentare sensibilmente la produttività dell'organizzazione.			
Come sono calcolati i prezzi di amazon sagemaker jumpstart?											Verranno addebitati i servizi AWS avviati da Amazon SageMaker JumpStart, come i processi di addestramento e gli endpoint, in base ai prezzi di SageMaker. Non sono previsti costi aggiuntivi per l'utilizzo di Amazon SageMaker JumpStart.			
Cos'è il pilota automatico amazon sagemaker?											Amazon SageMaker Autopilot è la prima funzionalità automatica di machine learning del settore che offre controllo e visibilità totali sui modelli di ML. SageMaker Autopilot esamina automaticamente i dati non elaborati, applica i processori di caratteristiche, sceglie il miglior set di algoritmi, addestra e ottimizza diversi modelli, controlla le loro prestazioni e in base a queste stila una classifica dei modelli, il tutto in pochi clic. Il risultato è un modello con le migliori prestazioni possibili, che si può distribuire in una frazione del tempo normalmente richiesto per la formazione del modello. Hai piena visibilità su come il modello è stato creato, cosa c'è al suo interno e SageMaker Autopilot si integra con Amazon SageMaker Studio. Puoi ricercare fino a 50 modelli diversi generati da SageMaker Autopilot all'interno di SageMaker Studio, così è facile scegliere il miglior modello per il tuo caso d'uso. SageMaker Autopilot può essere utilizzato per produrre facilmente un modello anche da chi non possiede esperienza di machine learning; può però essere utilizzato da sviluppatori esperti per sviluppare un modello di base per le successive iterazioni del team.			
Quali algoritmi integrati sono supportati in amazon sagemaker autopilot?											Amazon SageMaker Autopilot supporta 2 algoritmi integrati: XGBoost e Linear Learner.			
Posso interrompere manualmente un processo amazon sagemaker autopilot?											Sì. Puoi interrompere un processo in qualsiasi momento. Quando un processo del pilota automatico Amazon SageMaker viene interrotto, tutte le prove in corso vengono arrestate e non viene avviata alcuna nuova prova.			
Cos'è amazon sagemaker canvas?											Amazon SageMaker Canvas è un servizio visuale, drag and drop che permette agli analisti aziendali di costruire modelli ML e generare previsioni precise senza scrivere codice e senza richiedere competenze di ML. SageMaker Canvas semplifica l'accesso e la combinazione di dati da varie origini, pulisce automaticamente i dati e applica loro varie regolazioni, costruendo modelli di ML per generare previsioni precise con un solo clic. È possibile anche pubblicare facilmente i risultati, spiegare e interpretare i modelli, e condividerli con altri all'interno della propria organizzazione a scopi di revisione.			
Come sono calcolati i prezzi di amazon sagemaker canvas?											Le tariffe di Amazon SageMaker Canvas sono addebitate in base all'uso. SageMaker Canvas consente di importare, esplorare e preparare i dati in modo interattivo dai molteplici origini, di addestrare modelli di ML altamente accurati sui dati forniti dall'utente e di generare previsioni. La fattura è determinata da due componenti: le spese di sessione, basate sul numero di ore di utilizzo o accesso a SageMaker Canvas, e i costi di addestramento del modello, sulla base della dimensione del set di dati utilizzato allo scopo. Per maggiori informazioni, visita la pagina relativa ai prezzi di SageMaker Canvas.			
Come posso costruire una pipeline di integrazione e distribuzione continua (ci/cd) con amazon sagemaker?											Pipeline Amazon SageMaker aiuta a creare flussi di lavoro di ML completamente automatizzati, dalla preparazione dei dati fino all'implementazione dei modelli, in modo da poter gestire migliaia di modelli di ML in produzione. Pipeline SageMaker è dotato di un SDK di Python che si collega ad Amazon SageMaker Studio in modo da poter sfruttare un'interfaccia visiva per costruire ogni passaggio del flusso di lavoro. Quindi, utilizzando una singola API, è possibile collegare ogni passaggio per creare un flusso di lavoro completo. SageMaker Pipelines si occupa di gestire i dati tra una fase e l'altra, confezionare le ricette di codice e orchestrare la loro esecuzione, riducendo i mesi di codifica a poche ore. Ogni volta che un flusso di lavoro viene eseguito, viene tenuta una registrazione completa dei dati elaborati e delle azioni intraprese in modo che i data scientist e gli sviluppatori di ML possano eseguire rapidamente il debug dei problemi.  D: Come faccio a visualizzare tutti i miei modelli addestrati per scegliere il modello migliore per passare alla produzione?  Amazon SageMaker Pipelines fornisce un repository centrale di modelli addestrati chiamato registro dei modelli. Puoi scoprire i modelli e accedere al registro dei modelli visivamente attraverso SageMaker Studio o in modo programmatico attraverso l'SDK di Python, semplificando la scelta del modello desiderato da implementare nella produzione.  D: Quali componenti di Amazon SageMaker è possibile aggiungere ad Amazon SageMaker Pipelines?  A Pipeline SageMaker è possibile aggiungere i componenti disponibili tramite Amazon SageMaker Studio, quali Amazon SageMaker Clarify, Amazon SageMaker Data Wrangler, Amazon SageMaker Feature Store, Esperimenti Amazon SageMaker, Debugger Amazon SageMaker e Amazon SageMaker Model Monitor.  D: Come faccio a monitorare i componenti del mio modello attraverso l'intero flusso di lavoro di ML?  Amazon SageMaker Pipelines tiene automaticamente traccia di tutti i componenti del modello e mantiene un audit trail di tutte le modifiche, eliminando così il monitoraggio manuale. Può inoltre aiutare a raggiungere gli obiettivi di conformità. Con SageMaker Pipelines è possibile monitorare dati, codice, modelli addestrati e altro ancora.  D: Come sono calcolati i prezzi di Amazon SageMaker Pipelines?   Non sono previsti costi aggiuntivi per Amazon SageMaker Pipelines. Sono addebitati unicamente i costi base di elaborazione o qualunque servizio extra di AWS utilizzato con Amazon SageMaker Pipelines.			
Posso usare kubeflow con amazon sagemaker?											Sì. I componenti Amazon SageMaker per pipeline Kubeflow sono plug-in open source che consentono di utilizzare le pipeline Kubeflow per definire i flussi di lavoro ML e utilizzare SageMaker per le fasi di etichettatura, formazione e inferenza dei dati. Kubeflow Pipelines è un componente aggiuntivo di Kubeflow che consente di creare e distribuire pipeline di ML complete, portatili e scalabili. Tuttavia, durante l'uso di Kubeflow Pipelines, i team di operazioni di ML devono gestire un cluster Kubernetes con istanze CPU e GPU e mantenerne l'utilizzo elevato in ogni momento per ridurre i costi operativi. Massimizzare l'utilizzo di un cluster tra i team di data science è impegnativo e aggiunge un ulteriore sovraccarico operativo per i team delle attività di ML. In alternativa a un cluster Kubernetes ottimizzato per il ML, con i componenti SageMaker per Kubeflow Pipelines è possibile sfruttare le potenti caratteristiche di SageMaker come etichettatura dei dati, regolazione degli iperparametri completamente gestita su vasta scala e processi distribuiti di addestramento, implementazione di modelli sicura e scalabile con un clic e addestramento a costi contenuti con istanze spot di Amazon EC2, il tutto senza la necessità di configurare e gestire i cluster Kubernetes specificamente per eseguire i processi di ML.  D: Come sono calcolati i prezzi di Amazon SageMaker Components per Kubeflow Pipelines?   Non sono previsti costi aggiuntivi per l'utilizzo di Amazon SageMaker Components per Kubeflow Pipelines.			
Come fa amazon sagemaker a preparare i dati per il ml?											Amazon SageMaker Data Wrangler riduce il tempo richiesto per l'aggregazione e la preparazione dei dati per il ML. Da una singola interfaccia in Amazon SageMaker Studio, è possibile cercare e importare dati da Amazon S3, Amazon Athena, Amazon Redshift, AWS Lake Formation, Amazon SageMaker Feature Store e Snowflake in pochi clic. Inoltre, è possibile interrogare e importare dati trasferiti da oltre 40 origini dei dati e registrati nel Catalogo dati AWS Glue da Amazon AppFlow. SageMaker Data Wrangler carica, aggrega e visualizza automaticamente i dati grezzi. Dopo avere importato i dati in SageMaker Data Wrangler, è possibile visualizzare istogrammi e riepiloghi colonnari generati automaticamente. Per analizzare i dati in maggiore dettaglio e identificare errori potenziali, è possibile utilizzare il report sulla qualità dei dati e relativi approfondimenti di SageMaker Data Wrangler, che fornisce statistiche di riepilogo e segnalazioni relative alla qualità dei dati. Inoltre, è possibile eseguire l'analisi delle distorsioni supportata da Amazon SageMaker Clarify direttamente da SageMaker Data Wrangler per rilevare potenziali distorsioni durante la preparazione dei dati. Da qui, è possibile utilizzare le trasformazioni predefinite di SageMaker Data Wrangler per preparare i dati. Una volta che i dati sono pronti, è possibile costruire flussi di lavoro di ML completamente automatizzati con Pipeline Amazon SageMaker o importare i dati in Amazon SageMaker Feature Store.  D: Come faccio a creare le funzionalità del modello con Amazon SageMaker Data Wrangler?  Senza scrivere una singola riga di codice, Amazon SageMaker Data Wrangler è in grado di trasformare automaticamente i tuoi dati in nuove funzionalità. SageMaker Data Wrangler offre una selezione di trasformazioni di dati preconfigurate, imputazione dei dati mancanti, codifica one-hot, riduzione della dimensionalità utilizzando l'analisi dei componenti principali (PCA) nonché trasformatori specifici per le serie temporali. Ad esempio, è possibile convertire una colonna di campo testo in una colonna numerica con un solo clic, oppure creare uno snippet di codice attingendo alla libreria di snippet di SageMaker Data Wrangler.  D: Come faccio a visualizzare i miei dati in Amazon SageMaker Data Wrangler?  Amazon SageMaker Data Wrangler ti aiuta a comprendere i dati e a identificare potenziali errori e valori estremi con una serie di solidi modelli di visualizzazione preconfigurati. Gli istogrammi, i grafici di dispersione e le visualizzazioni specifiche per il ML, come il rilevamento di perdita dell'obiettivo, sono tutti disponibili senza scrivere una singola linea di codice. È inoltre possibile creare e modificare le proprie visualizzazioni.  D: Come sono calcolati i prezzi di Amazon SageMaker Data Wrangler?  Verranno addebitati i costi di tutte le risorse di calcolo, archiviazione ed elaborazione dati di ML utilizzate per Amazon SageMaker Data Wrangler. È possibile rivedere tutti i dettagli dei prezzi di SageMaker Data Wrangler qui. Grazie al Piano gratuito AWS, puoi iniziare a utilizzare SageMaker Data Wrangler gratuitamente.			
Come posso addestrare modelli di machine learning con i dati preparati in amazon sagemaker data wrangler?											Amazon SageMaker Data Wrangler offre un'esperienza unificata che ti consente di preparare i dati e addestrare senza problemi un modello di machine learning in Pilota automatico Amazon SageMaker. Pilota automatico SageMaker crea, addestra e regola automaticamente i migliori modelli di ML in base ai tuoi dati. Con Pilota automatico SageMaker, mantieni comunque il pieno controllo e la visibilità dei tuoi dati e del tuo modello. Inoltre, è possibile utilizzare le funzionalità preparate in SageMaker Data Wrangler nei modelli già esistenti. È possibile configurare l'esecuzione dei processi di elaborazione Amazon SageMaker Data Wrangler come parte della pipeline di addestramento di SageMaker in due modi: configurando il processo nell'interfaccia utente (UI) oppure esportando un notebook con il codice di orchestrazione.			
Quando le funzionalità sono state preparate in base ai dati storici, in quale modo amazon sagemaker data wrangler gestisce i nuovi dati?											È possibile configurare e avviare i processi di elaborazione Amazon SageMaker direttamente dalla UI di SageMaker Data Wrangler, pianificando il processo di elaborazione dei dati e applicando parametri alle origini dei dati per trasformare facilmente i nuovi batch di dati su vasta scala.			
Come funziona amazon sagemaker data wrangler con i processi di ci/cd?											Dopo avere preparato i dati, Amazon SageMaker Data Wrangler fornisce opzioni diverse per promuovere il flusso SageMaker Data Wrangler in produzione e si integra alla perfezione con le capacità MLOps e CI/CD. È possibile configurare e avviare i processi di elaborazione SageMaker direttamente dalla UI di SageMaker Data Wrangler, pianificando il processo di elaborazione dei dati e applicando parametri alle origini dei dati per trasformare facilmente i nuovi batch di dati su vasta scala. In alternativa, SageMaker Data Wrangler si integra in modo ottimale con l'elaborazione di SageMaker e il container SageMaker Spark, consentendo di utilizzare con facilità gli SDK di SageMaker per incorporare SageMaker Data Wrangler nel flusso di lavoro di produzione.			
Quale modello utilizza quick model di amazon sagemaker data wrangler?											In pochi clic, Amazon SageMaker Data Wrangler suddivide un modello XGBoost e lo addestra con gli iperparametri predefiniti. In base al tipo di problema, SageMaker Data Wrangler fornisce un riepilogo del modello, un riepilogo delle funzionalità e una matrice di confusione per fornire rapidamente informazioni dettagliate al fine di applicarle ai flussi di preparazione dei dati.			
Quali dimensioni di dati supporta amazon sagemaker data wrangler?											Amazon SageMaker Data Wrangler supporta varie tecniche di campionamento, come top-K, il campionamento casuale e quello stratificato per l'importazione dei dati; in questo modo, è possibile trasformare rapidamente i dati utilizzando la UI di SageMaker Data Wrangler. Se si utilizzano set di dati ampi o variegati, è possibile incrementare le dimensioni dell'istanza SageMaker Data Wrangler per migliorare le prestazioni. Dopo avere creato il flusso, è possibile elaborare l'intero set di dati utilizzando i processi di elaborazione di SageMaker Data Wrangler.			
Amazon sagemaker data wrangler funziona con amazon sagemaker feature store?											È possibile configurare Amazon SageMaker Feature Store come destinazione per le funzionalità preparate in Amazon SageMaker Data Wrangler. È possibile farlo direttamente nella UI oppure esportando un notebook generato specificatamente per l'elaborazione dei dati utilizzando SageMaker Feature Store come destinazione.			
Come faccio ad archiviare le funzionalità dei miei modelli di ml?											Amazon SageMaker Feature Store fornisce un repository centrale per le caratteristiche di dati con lettura e scrittura a bassa latenza (millisecondi). Le caratteristiche possono essere archiviate, recuperate, scoperte e condivise tramite SageMaker Feature Store per un facile riutilizzo tra modelli e team con accesso e controllo sicuri. SageMaker Feature Store supporta caratteristiche sia online che offline generate tramite pipeline in batch o in streaming. Supporta il backfilling delle caratteristiche e fornisce negozi online e offline per mantenere la parità tra le caratteristiche utilizzate nell’addestramento e nell’inferenza del modello.  D: Come faccio a mantenere la coerenza tra le funzionalità online e offline?  Amazon SageMaker Feature Store mantiene automaticamente la coerenza tra le funzionalità online e offline senza gestione o codice aggiuntivi. SageMaker Feature Store è completamente gestito e mantiene la coerenza tra gli ambienti di addestramento e di inferenza statistica.  D: Come faccio a riprodurre una funzione da un dato momento nel tempo?  Amazon SageMaker Feature Store mantiene i time stamp per tutte le funzionalità in ogni istanza di tempo. Ciò ti aiuta a recuperare le funzionalità in qualsiasi periodo di tempo per requisiti di business o di conformità. Puoi facilmente spiegare le funzionalità del modello e i loro valori da quando sono stati creati per la prima volta a oggi, riproducendo il modello a partire da un dato momento nel tempo.  D: Quali sono le funzionalità offline?  Le funzionalità offline sono utilizzate per l’addestramento perché è necessario accedere a volumi molto grandi per un lungo periodo di tempo. Queste caratteristiche sono servite da un repository a velocità effettiva e a larghezza di banda elevati.  D: Quali sono le caratteristiche online? Le caratteristiche online sono utilizzate nelle applicazioni necessarie per fare previsioni in tempo reale. Le caratteristiche online sono servite da un repository ad elevata velocità effettiva con latenza pari a singole unità di millisecondi per previsioni veloci.			
Come sono calcolati i prezzi di amazon sagemaker feature store?											Grazie al piano gratuito di AWS, puoi iniziare a utilizzare Amazon SageMaker Feature Store gratuitamente. Con SageMaker Feature Store, si paga per la scrittura nel feature store, e per la lettura e l’archiviazione dal feature store online. Per i dettagli sui prezzi, consulta la pagina dei prezzi SageMaker.  D: Cosa offre Amazon SageMaker per l'etichettatura dei dati? Amazon SageMaker fornisce due offerte di etichettatura dei dati, Amazon SageMaker Ground Truth Plus e Amazon SageMaker Ground Truth. Entrambe le opzioni consentono di identificare i dati non elaborati, come immagini, file di testo e video, e aggiungere etichette informative per creare set di dati di addestramento di alta qualità per i propri modelli di ML. Per ulteriori informazioni, visita la pagina Web Etichettatura dei dati con SageMaker.			
Cosa sono i dati geospaziali?											I dati geospaziali rappresentano oggetti o caratteristiche sulla superficie terrestre. Il primo tipo di dati geospaziali è costituito dai dati vettoriali che impiegano elementi geometrici bidimensionali come punti, linee o poligoni per rappresentare oggetti come strade e confini terrestri. Il secondo tipo di dati geospaziali sono i dati raster, come le immagini acquisite da satelliti o piattaforme aeree o i dati di rilevamento da remoto. Questo tipo di dati impiega una matrice di pixel per definire la posizione delle caratteristiche. I formati raster possono essere utilizzati per archiviare i dati variabili. Un terzo tipo di dati geospaziali sono i dati di posizione geo-taggati. Comprende punti di interesse, come ad esempio la Torre Eiffel, post dei social media con tag della posizione, coordinate di latitudine e longitudine o indirizzi stradali con stili e formati differenti.			
Cosa sono le capacità geospaziali di amazon sagemaker?											Le capacità geospaziali di Amazon SageMaker facilitano la costruzione, l'addestramento e l'implementazione dei modelli di machine learning (ML) per effettuare previsioni utilizzando i dati geospaziali da parte di data scientist e ingegneri del ML. È possibile utilizzare i propri dati, ad esempio i dati satellitari di Planet Labs satellite da Amazon S3, oppure importare i dati da Open Data su AWS, Servizio di posizione Amazon e altre origini dei dati geospaziali di Amazon SageMaker.			
Qual è il vantaggio del ml geospaziale su amazon sagemaker?											È possibile utilizzare le capacità geospaziali di Amazon SageMaker per effettuare previsioni sui dati geospaziali più rapidamente che con le soluzioni fai da te. Le capacità geospaziali di Amazon SageMaker consentono di accedere facilmente ai dati geospaziali dai data lake dei clienti esistenti, da set di dati open source e da altre origini dei dati geospaziali di Amazon SageMaker. Le capacità geospaziali di Amazon SageMaker riducono al minimo la necessità di costruire un'infrastruttura personalizzata e di eseguire funzioni di pre-elaborazione grazie ad algoritmi realizzati ad hoc per una preparazione dei dati, l'addestramento del modello e l'inferenza efficienti. Inoltre, da Amazon SageMaker Studio è possibile creare e condividere visualizzazioni personalizzati e dati all'interno dell'organizzazione. Le capacità geospaziali di Amazon SageMaker includono modelli pre-addestrati per impieghi comuni nei settori agricolo, immobiliare, assicurativo e dei servizi finanziari.			
Cosa sono i notebook amazon sagemaker studio?											I notebook Amazon SageMaker Studio sono notebook Jupyter gestiti, facili da utilizzare e ideali per la collaborazione. I notebook Amazon SageMaker Studio si integrano con gli strumenti progettati ad hoc per il ML in SageMaker e in altri servizi AWS per fornire lo sviluppo del ML end-to-end in Amazon SageMaker Studio, l'ambiente di sviluppo integrato (IDE) completo per il ML.			
In che modo i notebook amazon sagemaker studio sono diversi dall'offerta di notebook basati sulle istanze?											I notebook SageMaker Studio offrono alcune importanti caratteristiche che li differenziano dai notebook basati sull'istanza. Con i notebook Studio, è possibile avviare rapidamente notebook senza dover effettuare manualmente il provisioning di un'istanza e aspettare che sia operativa. Il tempo dello startup dell'avvio dell'interfaccia utente per leggere ed eseguire un notebook è più rapido rispetto ai notebook basati sulle istanze. Hai anche la flessibilità di scegliere tra una vasta raccolta di tipi di istanze all'interno dell'interfaccia utente in qualsiasi momento. Non è necessario andare alla console AWS Management per avviare nuove istanze e trasferirle sui tuoi notebook. Ciascun utente avrà una home directory isolata e indipendente da una determinata istanza. Questa directory viene automaticamente montata su tutti i server e kernel dei notebook all'avvio, in modo da poter accedere ai notebook e ad altri file anche quando si cambia istanza per visualizzarli ed eseguirli. Grazie all'integrazione con il Centro identità AWS IAM (che ha sostituito AWS SSO), l'uso delle credenziali della propria organizzazione per accedere ai notebook SageMaker Studio risulta notevolmente semplificato. La condivisione dei notebook è una caratteristica integrata nei notebook SageMaker Studio. È possibile condividere i notebook con i colleghi con un semplice clic oppure addirittura modificare contemporaneamente a quattro mani uno stesso notebook.			
Come funzionano i notebook amazon sagemaker studio?											I notebook Amazon SageMaker Studio sono notebook Jupyter che possono essere ruotati rapidamente con un semplice clic. Le risorse di calcolo sottostanti sono completamente elastiche, in modo da calibrare le risorse disponibili, e le modifiche vengono attuate in modo automatico in background senza interrompere il lavoro. SageMaker permette anche la condivisione di notebook con un clic. Puoi condividere facilmente i notebook con altri utenti, i quali avranno a disposizione lo stesso identico notebook salvato nella medesima posizione. Con i notebook SageMaker Studio è possibile accedere con le proprie credenziali aziendali utilizzando AWS IAM Identity Center (sostituisce AWS SSO). La condivisione dei notebook all'interno e all'esterno dei team è semplice, poiché le dipendenze necessarie per far funzionare un notebook vengono automaticamente monitorate in immagini di lavoro condensate all'interno del notebook durante la sua condivisione.			
Cosa sono gli spazi condivisi in amazon sagemaker?											I professionisti del machine learning possono creare uno spazio di lavoro condiviso all'interno dei quali i membri del team possono leggere e modificare in maniera collaborativa i notebook Amazon SageMaker Studio. Utilizzando gli spazi condivisi, i colleghi possono modificare a più mani lo stesso file del notebook, eseguire simultaneamente il codice del notebook e rivedere insieme i risultati, eliminando le sequenze di passaggi e ottimizzando la collaborazione. Negli spazi condivisi, i team del ML dispongono di un supporto incorporato per servizi come BitBucket e AWS CodeCommit, potendo così gestire con facilità versioni differenti dei propri notebook e confrontare le modifiche nel corso del tempo. Le risorse create all'interno dei notebook, come esperimenti e modelli di ML, vengono automaticamente salvati e associati allo specifico spazio di lavoro in cui sono stati creati affinché i team possano coordinarsi e organizzarsi con maggiore facilità e accelerare lo sviluppo dei modelli di ML.			
Come funzionano i notebook amazon sagemaker studio con altri servizi aws?											I notebook Amazon SageMaker Studio offrono accesso a tutte le caratteristiche di SageMaker, quali addestramento distribuito, trasformazione in batch, hosting e gestione degli esperimenti. Dai notebook SageMaker è possibile accedere ad altri servizi come set di dati in Amazon S3, Amazon Redshift, AWS Glue, Amazon EMR o AWS Lake Formation.			
Come sono calcolati i prezzi dei notebook amazon sagemaker studio?											Per l'utilizzo dei notebook SageMaker Studio vengono addebitati sia i costi per il calcolo sia i costi per l'archiviazione. Consulta i prezzi di Amazon SageMaker per conoscere i costi in base al tipo di istanza di calcolo. I notebook e gli artefattii associati di tua appartenenza come file di dati e script vengono conservati in Amazon EFS. Consulta i prezzi di Amazon EFS per conoscere i costi di archiviazione. Nell'ambito del Piano gratuito AWS, è possibile iniziare a utilizzare i notebook Amazon SageMaker Studio gratuitamente.			
Sono addebitati costi separati per ogni notebook creato ed eseguito in sagemaker studio?											No. È possibile creare ed eseguire più notebook sulla stessa istanza di calcolo. Paghi solamente in base al calcolo che utilizzi e non per i singoli elementi. Ulteriori informazioni a riguardo sono disponibili nella nostra guida alla tariffazione. Oltre ai notebook, è inoltre possibile avviare ed eseguire terminali e shell (interpreti di comandi) interattive in SageMaker Studio, tutti sulla stessa istanza di calcolo. Ogni applicazione viene eseguita all'interno di un container o di un'immagine. SageMaker Studio offre diverse immagini incorporate appositamente create e preconfigurate per data science e ML. Ulteriori informazioni sull'ambiente di sviluppo di SageMaker Studio sono disponibili nella guida per l'utilizzo dei notebook SageMaker Studio.			
Come è possibile monitorare e arrestare le risorse utilizzate dai notebook?											Puoi monitorare e arrestare le risorse utilizzate dai tuoi notebook SageMaker Studio tramite l'interfaccia visiva di SageMaker Studio e la console di gestione AWS. Consulta la documentazione per ulteriori dettagli.			
Se eseguo un notebook amazon sagemaker studio, mi verranno comunque addebitati costi se chiudo il browser, la scheda dei notebook o semplicemente lascio il browser aperto?											Sì, continueranno a essere addebitati i costi di calcolo. È una situazione simile all'avvio delle istanze Amazon EC2 nella console di gestione AWS e quindi alla chiusura del browser. Le istanze Amazon EC2 sono ancora in esecuzione e vengono comunque addebitati costi a meno che non si arresti esplicitamente l'istanza.			
Vengono addebitati costi per la creazione e la configurazione di un dominio amazon sagemaker studio?											No, non viene addebitato alcun costo per la creazione o la configurazione di un dominio Amazon SageMaker Studio, inclusi l'aggiunta, l'aggiornamento e l'eliminazione dei profili utente.			
Come è possibile visualizzare gli addebiti dettagliati per i notebook amazon sagemaker studio o altri servizi amazon sagemaker?											"L'amministratore può visualizzare l'elenco degli addebiti dettagliati per Amazon SageMaker, incluso SageMaker Studio, nella Console AWS per la fatturazione. Dalla Console di gestione AWS per SageMaker, scegli Services (Servizi) nel menu in alto, digita ""billing"" (fatturazione) nella casella di ricerca e seleziona Billing (Fatturazione) dal menu a discesa, quindi seleziona Bills (Fatture) nel pannello di sinistra. Nella sezione Dettagli, seleziona SageMaker per espandere l'elenco delle regioni e fai clic ripetutamente fino a visualizzare gli addebiti in dettaglio."			
Cos'è amazon sagemaker studio lab?											Amazon SageMaker Studio Lab è un ambiente di sviluppo gratuito per il ML, che fornisce calcolo, archiviazione (fino a 15 GB) e sicurezza, il tutto a costo zero, per chiunque voglia imparare e sperimentare con il ML. Tutto ciò di cui hai bisogno per iniziare è un ID email valido: non c'è bisogno di configurare l'infrastruttura o di gestire l'identità e l'accesso e nemmeno di registrarti per un account AWS. SageMaker Studio Lab accelera la costruzione di modelli attraverso l'integrazione con GitHub, e viene preconfigurato con i più popolari strumenti di ML, framework e librerie per iniziare immediatamente. SageMaker Studio Lab salva automaticamente il lavoro in modo da non dover riavviare tra una sessione e l'altra. Facile come chiudere il portatile e riaprirlo più tardi.			
Perché dovrei usare amazon sagemaker studio lab?											Amazon SageMaker Studio Lab è pensato per gli studenti, i ricercatori e i data scientist che hanno bisogno di un ambiente di sviluppo senza alcuna attrezzatura richiesta per i loro corsi ed esperimenti di ML. SageMaker Studio Lab è ideale per gli utenti che non necessitano di un ambiente di produzione, ma vogliono comunque un sottoinsieme delle funzionalità di SageMaker per migliorare le proprie capacità di ML. Le sessioni di SageMaker vengono salvate automaticamente, permettendo agli utenti di riprendere da dove si erano interrotti per ciascuna sessione utente.			
In che modo amazon sagemaker studio lab si relaziona/lavora con altri servizi aws?											Amazon SageMaker Studio Lab è un servizio costruito su AWS che usa molti degli stessi servizi fondamentali di Amazon SageMaker Studio come Amazon S3 e Amazon EC2. A differenza degli altri servizi, i clienti non avranno bisogno di un account AWS. Creeranno invece un account specifico per Amazon SageMaker Studio Lab con un indirizzo e-mail. Questo darà all'utente l'accesso a un ambiente limitato (15 GB di archiviazione, e 12 ore di sessione) per eseguire i notebook di ML.			
Quali origini dei dati supporta amazon sagemaker canvas?											Amazon SageMaker Canvas consente di scoprire senza problemi le origini dei dati AWS a cui l'account ha accesso, compresi Amazon S3 e Amazon Redshift. È possibile sfogliare e importare i dati usando l'interfaccia visiva e a trascinamento e rilascio di SageMaker Canvas. Inoltre, è possibile trascinare e rilasciare i file dal disco locale e utilizzare i connettori predefiniti per importare dati da origini di terze parti come Snowflake.			
Come si costruisce un modello di ml per generare previsioni precise in amazon sagemaker canvas?											Una volta collegate le origini, selezionato un set di dati e preparati i dati, è possibile selezionare la colonna di destinazione che si vuole prevedere per iniziare un processo di creazione del modello. Amazon SageMaker Canvas identificherà automaticamente il tipo di problema, genererà nuove funzionalità rilevanti, testerà un set completo di modelli di previsione utilizzando tecniche di ML quali regressione lineare, regressione logistica, deep learning, previsione di serie temporali e gradient boosting, e costruirà un modello che effettua previsioni precise sulla base del set di dati.			
Quanto tempo occorre per costruire un modello in amazon sagemaker canvas?											Come posso monitorare i progressi durante la creazione del modello? Il tempo necessario per costruire un modello dipende dalla dimensione del set di dati. Piccoli set di dati possono richiedere meno di 30 minuti, e grandi set di dati possono richiedere alcune ore. Man mano che il processo di creazione del modello procede, Amazon SageMaker Canvas fornisce aggiornamenti visivi dettagliati, compresa la percentuale di completamento del processo e la quantità di tempo rimanente per il completamento.			
Cos'è amazon sagemaker experiments?											"Amazon SageMaker Experiments ti aiuta a organizzare e controllare le iterazioni sui modelli di ML. Esperimenti SageMaker ti aiuta a gestire le iterazioni con l'acquisizione automatica di parametri di input, configurazioni e risultati salvandoli come ""esperimenti"". Puoi lavorare all'interno dell'interfaccia visiva di Amazon SageMaker Studio, in cui puoi sfogliare gli esperimenti attivi, cercare gli esperimenti precedenti in base alle loro caratteristiche, rivederne i risultati e confrontare i risultati degli esperimenti in modo visivo."			
Cos'è debugger amazon sagemaker?											Debugger Amazon SageMaker acquisisce automaticamente metriche in tempo reale durante l'addestramento, come matrici di confusione e gradienti di apprendimento, per contribuire a migliorare la precisione del modello. Le metriche di Debugger SageMaker possono essere visualizzate in Amazon SageMaker Studio per una facile comprensione. Debugger SageMaker può anche generare segnalazioni e avvisi di correzione quando vengono rilevati comuni problemi di addestramento. SageMaker Debugger inoltre monitora e profila automaticamente le risorse di sistema come CPU, GPU, rete e memoria in tempo reale, e fornisce consigli sulla loro riassegnazione. Ciò ti abilita ad utilizzare le tue risorse in modo efficiente durante l’addestramento e aiuta a ridurre i costi e le risorse.			
Amazon sagemaker supporta l’addestramento distribuito?											Sì. Amazon SageMaker è in grado di distribuire automaticamente modelli di deep learning e grandi set di addestramento fra istanze AWS GPU in una frazione del tempo necessario per costruire e ottimizzare queste strategie di distribuzione manualmente. Le due tecniche di addestramento distribuite che SageMaker applica sono il parallelismo dei dati e il parallelismo dei modelli. Il parallelismo dei dati viene applicato per migliorare la velocità di addestramento dividendo i dati equamente fra più istanze della GPU, permettendo a ciascuna istanza di addestrarsi contemporaneamente. Il parallelismo del modello è utile per i modelli troppo grandi per essere memorizzati su una singola GPU e richiedono che il modello sia partizionato in parti più piccole prima di essere distribuito su più GPU. Con solo poche righe di codice aggiuntivo nei tuoi script di addestramento PyTorch e TensorFlow, SageMaker applicherà automaticamente il parallelismo dei dati o il parallelismo dei modelli, consentendoti di sviluppare e distribuire i tuoi modelli più velocemente. SageMaker determinerà il miglior approccio per dividere il modello usando algoritmi di partizionamento dei grafici per bilanciare il calcolo di ciascuna GPU e minimizzando la comunicazione tra istanze GPU. Inoltre, SageMaker ottimizza i processi di addestramento distribuiti tramite algoritmi che sfruttano appieno le capacità di calcolo e la rete di AWS per raggiungere un'efficienza di scalabilità quasi lineare. In questo modo, è possibile completare l'addestramento più velocemente rispetto alle implementazioni open source manuali.			
Cos'è il compilatore di formazione amazon sagemaker?											Il Compilatore di formazione Amazon SageMaker è un compilatore di deep learning (DL) che accelera l'addestramento dei modelli di DL fino al 50% attraverso ottimizzazioni a livello di grafico e di kernel per utilizzare le GPU in modo più efficiente. Il Compilatore di formazione SageMaker è integrato con le versioni di TensorFlow e PyTorch in SageMaker, in modo da poter accelerare l'addestramento in questi framework popolari con modifiche minime al codice.			
Come funziona il compilatore di formazione amazon sagemaker?											Il Compilatore di formazione Amazon SageMaker accelera i processi di addestramento convertendo i modelli di DL dalla loro rappresentazione in linguaggio di alto livello a istruzioni ottimizzate per l'hardware che si addestrano più velocemente dei processi con i framework nativi. Più specificamente, il Compilatore di formazione SageMaker usa l'ottimizzazione a livello di grafico (fusione di operatori, pianificazione della memoria e semplificazione algebrica), le ottimizzazioni a livello di flusso di dati (trasformazione del layout, eliminazione delle sottoespressioni comuni) e le ottimizzazioni di back-end (nascondere la latenza della memoria, ottimizzazioni orientate ai circuiti) per produrre un processo di addestramento dei modelli ottimizzato che sfrutta in modo più efficiente le risorse hardware e, di conseguenza, esegue più velocemente l'addestramento.			
Come si utilizza il compilatore di formazione amazon sagemaker?											Il Compilatore di formazione Amazon SageMaker è integrato nell'SDK SageMaker per Python e nei container di deep learning SageMaker Hugging Face. Non è necessario modificare i flussi di lavoro per accedere ai vantaggi in termini di accelerazione. È possibile eseguire i processi di addestramento nel modo in cui già operi utilizzando una qualsiasi delle interfacce di SageMaker: istanze del notebook Amazon SageMaker, Amazon SageMaker Studio, AWS SDK per Python (Boto3) e interfaccia della linea di comando AWS (AWS CLI). È possibile attivare il Compilatore di formazione Amazon SageMaker aggiungendo una classe TrainingCompilerConfig come parametro quando si crea un oggetto stimatore di framework. In pratica, questo significa un paio di righe di codice aggiunte a uno script di addestramento esistente per una singola istanza GPU. La documentazione dettagliata più aggiornata, i notebook di prova e gli esempi sono disponibili nella documentazione.			
Quanto costa il compilatore di formazione amazon sagemaker?											Il Compilatore di formazione è una caratteristica di addestramento di SageMaker fornita senza costi aggiuntivi esclusivamente ai clienti di SageMaker. I clienti possono in effetti ridurre i costi con Training Compiler poiché i tempi di addestramento sono ridotti.			
Cos'è managed spot training?											Managed Spot Training con Amazon SageMaker ti consente di addestrare i modelli di ML utilizzando le istanze Spot di Amazon EC2, riducendo al contempo il costo della formazione fino al 90%.			
In che modo è possibile utilizzare managed spot training?											Puoi abilitare l'opzione Managed Spot Training durante l'invio dei tuoi processi di addestramento e specificare quanto a lungo desideri attendere per la capacità Spot. Amazon SageMaker gestisce la capacità Spot e utilizza le istanze Spot di Amazon EC2 per eseguire i tuoi processi. Avrai completa visibilità sullo stato del processo di formazione, sia quando è in esecuzione sia quando è in attesa di capacità disponibile.			
In quali casi è indicato utilizzare managed spot training?											Managed Spot Training è ideale quando hai la flessibilità di scegliere il momento in cui eseguire i processi di addestramento e per ridurre al minimo il loro costo. Con Managed Spot Training puoi ridurre il costo dell'addestramento dei modelli di ML fino al 90%.			
Come funziona managed spot training?											Managed Spot Training utilizza le istanze Spot di Amazon EC2 per l'addestramento. Queste istanze possono essere annullate nel caso in cui sia necessaria capacità per AWS. Come risultato, i processi di Managed Spot Training possono essere eseguiti in piccoli incrementi non appena la capacità diventa disponibile. I processi di addestramento non devono essere riavviati da zero in caso di interruzione, in quanto Amazon SageMaker può ripristinarli utilizzando l'ultimo checkpoint del modello. I framework e gli algoritmi di visione computerizzata integrati in SageMaker consentono di creare checkpoint periodici da poter abilitare con i modelli personalizzati.			
Con managed spot training è necessario creare checkpoint periodicamente?											Consigliamo di creare checkpoint periodici come procedura consigliata generale per i processi di addestramento con esecuzione prolungata. In questo modo è possibile evitare il riavvio dei processi di Managed Spot Training in caso di annullamento della capacità. Abilitando i checkpoint, Amazon SageMaker ripristina i processi di Managed Spot Training dall'ultimo checkpoint.			
In che modo è possibile calcolare il risparmio sui costi con i processi di managed spot training?											Quando completi un processo di Managed Spot Training, puoi visualizzare il risparmio nella Console di gestione AWS e calcolare il risparmio sui costi anche come differenza percentuale tra la durata di esecuzione del processo di formazione e la durata per la quale hai ricevuto la fattura. Indipendentemente dal numero di interruzioni dei processi di Managed Spot Training, i costi ti verranno addebitati solo una volta per la durata per cui i dati erano stati scaricati.			
Quali istanze si possono utilizzare con managed spot training?											La funzione Managed Spot Training può essere utilizzata con tutte le istanze supportate in Amazon SageMaker.			
Quali regioni di aws sono supportate con managed spot training?											Managed Spot Training è supportato in tutte le regioni di AWS nelle quali Amazon SageMaker è attualmente disponibile.			
Sono previste limitazioni per il set di dati utilizzabile per l'addestramento?											Non sono previsti limiti fissi alle dimensioni del set di dati utilizzabile per l'addestramento di modelli con Amazon SageMaker.			
Quali algoritmi usa amazon sagemaker per generare modelli?											Amazon SageMaker include di default algoritmi per regressione lineare, regressione logistica, clustering k-medie, analisi delle componenti principali, macchine di fattorizzazione, topic modeling neurale, allocazione latente di Dirichlet, alberi con gradient boosting, sequence2sequence, previsione di serie storiche, word2vec e classificazione di immagini. SageMaker fornisce inoltre container ottimizzati Apache MXNet, Tensorflow, Chainer, PyTorch, Gluon, Keras, Horovod, Scikit-learn e Deep Graph Library. Infine, Amazon SageMaker supporta gli algoritmi di addestramento personalizzati tramite immagini Docker conformi alle specifiche documentate.			
Cos'è l'ottimizzazione automatica dei modelli la maggior parte degli algoritmi di ml impiegano una serie di parametri che controllano il funzionamento dell'algoritmo sottostante. questi parametri vengono in genere chiamati iperparametri; i loro valori influenzano la qualità dei modelli addestrati. l'ottimizzazione automatica dei modelli è il processo di ricerca di un set di iperparametri di un algoritmo che offrano un modello ottimale. ?											D: Cos'è l'ottimizzazione automatica dei modelli La maggior parte degli algoritmi di ML impiegano una serie di parametri che controllano il funzionamento dell'algoritmo sottostante. Questi parametri vengono in genere chiamati iperparametri; i loro valori influenzano la qualità dei modelli addestrati. L'ottimizzazione automatica dei modelli è il processo di ricerca di un set di iperparametri di un algoritmo che offrano un modello ottimale.			
A quali modelli può essere applicata l'ottimizzazione automatica dei modelli?											È possibile eseguire l'ottimizzazione di modelli in Amazon SageMaker su qualsiasi algoritmo purché sia scientificamente fattibile, ad esempio algoritmi integrati in SageMaker, reti neurali profonde o algoritmi arbitrari caricati in SageMaker sotto forma di immagini Docker.			
È possibile utilizzare l'ottimizzazione automatica dei modelli al di fuori di amazon sagemaker?											No, al momento no. Amazon SageMaker fornisce il massimo livello di esperienza e prestazioni di regolazione dei modelli.			
In cosa consiste l'algoritmo di regolazione automatica dei modelli?											Al momento, l'algoritmo per la regolazione degli iperparametri è un'implementazione personalizzata dell'ottimizzazione bayesiana. Il suo scopo è ottimizzare una metrica obiettivo specificata dal cliente lungo l'intero processo di regolazione. In particolare, verifica le metriche dell'oggetto per i processi di addestramento completati e utilizza i dati ottenuti per dedurre la combinazione di iperparametri per il processo di addestramento successivo.			
La regolazione automatica dei modelli suggerisce iperparametri specifici per la regolazione?											No. Il modo in cui i singoli iperparametri alterano le prestazioni di un modello dipende da diversi fattori e non è semplice stabilire se un iperparametro sia più importante di altri e debba essere quindi regolato. Per gli algoritmi in Amazon SageMaker, è già stabilito quali iperparametri possono essere ottimizzati.			
Quanto tempo richiede un processo di ottimizzazione di iperparametri?											La durata di un processo di ottimizzazione degli iperparametri dipende da diversi fattori, tra cui le dimensioni dei dati, l'algoritmo sottostante e i valori degli iperparametri. Inoltre, i clienti potranno scegliere il numero di processi di addestramento simultanei e il numero totale. Tutte queste scelte influenzano la durata del processo di ottimizzazione.			
È possibile ottimizzare diversi obiettivi simultaneamente, ad esempio ottimizzando un modello sia rapido sia preciso?											No, al momento no. Al momento è necessario specificare un singolo obiettivo di ottimizzazione, oppure modificare il codice dell'algoritmo in modo che emetta un nuovo parametro, che sarà confrontato con altri parametri per applicarvi il processo di addestramento secondo il nuovo obiettivo.			
Quanto costa l'ottimizzazione automatica dei modelli?											Per il processo di ottimizzazione di per sé non è previsto alcun costo. Saranno tuttavia addebitati i costi dei processi di addestramento avviati dal processo di regolazione degli iperparametri in base ai prezzi di regolazione dei modelli.			
Cosa determina la scelta di usare amazon sagemaker o l’ottimizzazione automatica dei modelli?											Amazon SageMaker Autopilot automatizza tutto in un tipico flusso di lavoro di ML, tra cui la preelaborazione delle funzioni, la selezione dell'algoritmo e l'ottimizzazione dell'iperparametro, concentrandosi in particolare sui casi d'uso di classificazione e regressione. L'ottimizzazione automatica dei modelli, d'altra parte, è progettata per ottimizzare qualsiasi modello, indipendentemente dal fatto che si basi su algoritmi integrati, framework di deep learning o container personalizzati. Per ottenere flessibilità, è necessario selezionare manualmente l'algoritmo specifico, gli iperparametri da ottimizzare e gli intervalli di ricerca corrispondenti.			
Cos'è il consolidamento dell'apprendimento?											Il consolidamento dell'apprendimento è una tecnica di ML che consente a un agente di imparare in un ambiente interattivo tramite prove ed errori utilizzando feedback dalle proprie azioni ed esperienze.			
Posso formare i modelli di consolidamento dell'apprendimento in amazon sagemaker?											Sì, è possibile formare i modelli di consolidamento dell'apprendimento in Amazon SageMaker oltre ai tradizionali modelli di apprendimento supervisionato e non supervisionato.			
In cosa è diverso il consolidamento dell'apprendimento da quello supervisionato?											Sebbene sia l'apprendimento supervisionato che il consolidamento dell'apprendimento utilizzino la mappatura tra input e output, nell'apprendimento supervisionato il feedback fornito all'agente è un insieme di azioni corretto per eseguire un'attività, mentre il consolidamento dell'apprendimento utilizza un feedback ritardato dove i segnali di ricompensa sono ottimizzati per assicurare un obiettivo a lungo termine tramite una sequenza di azioni.			
Quando è indicato utilizzare il consolidamento dell'apprendimento?											Mentre l'obiettivo delle tecniche di apprendimento supervisionato è di trovare la risposta esatta in base ai modelli nei dati di training, l'obiettivo delle tecniche di apprendimento non supervisionato è di trovare similitudini e differenze tra i punti di dati. Al contrario, l'obiettivo delle tecniche di apprendimento per rinforzo (RL, reinforcement learning) è di imparare come ottenere un risultato desiderato anche quando non è chiaro come raggiungere tale risultato. Di conseguenza, RL è più adatto per abilitare le applicazioni intelligenti dove un agente può prendere decisioni autonome come nella robotica, veicoli con pilota automatico, HVAC, controllo industriale e altro.			
Che tipo di ambienti posso usare per addestrare i modelli rl?											Amazon SageMaker RL supporta un numero di ambienti diversi per la formazione di modelli di RL. È possibile utilizzare i servizi AWS come AWS RoboMaker, gli ambienti open source o personalizzati sviluppato utilizzando le interfacce Open AI Gym o gli ambienti di simulazione commerciale come MATLAB e SimuLink.			
Ho bisogno di scrivere i miei algoritmi di agenti rl per addestrare i modelli rl?											No, Amazon SageMaker RL include i kit di strumenti RL come Coach e Ray RLLib che offrono implementazioni o algoritmi di agente RL come DQN, PPO, A3C e molti altri.			
Posso portare le mie librerie rl e l'implementazione di algoritmi ed eseguirli in amazon sagemaker rl?											Sì, è possibile portare le librerie RL e le implementazione di algoritmi in container Docker ed eseguirle in Amazon SageMaker RL.			
Posso effettuare rollout distribuiti utilizzando amazon sagemaker rl?											Sì. È anche possibile selezionare un cluster eterogeneo in cui la formazione può essere eseguita su un'istanza GPU e le simulazioni possono essere eseguite su più istanze CPU.			
Quali opzioni di implementazione fornisce amazon sagemaker?											Una volta creati e formati dei modelli, Amazon SageMaker fornisce tre opzioni per implementarli, permettendoti di iniziare a fare previsioni. L'inferenza in tempo reale è adeguata per carichi di lavoro con requisiti di latenza di millisecondi, dimensioni di payload fino a 6MB e tempi di elaborazione fino a 60 secondi. La trasformazione in batch è ideale per previsioni offline su grandi batch di dati disponibili in anticipo. L'inferenza asincrona è progettata per carichi di lavoro che non richiedono latenza inferiore al secondo, dimensioni di payload fino a 1 GB e tempi di elaborazione fino a 15 minuti.			
Cos'è amazon sagemaker asynchronous inference?											Amazon SageMaker Asynchronous Inference mette in coda le richieste in entrata, elaborandole in maniera asincrona. Questa opzione è ideale per richieste con payload di grandi dimensioni e tempi di elaborazione lunghi che richiedono l'elaborazione al loro arrivo. Facoltativamente, quando non stai elaborando attivamente delle richieste, puoi configurare la scalabilità automatica per ridurre a zero il conto delle istanze e risparmiare sui costi.			
Come configuro le impostazioni di scalabilità automatica per ridurre a zero il conto delle istanze quando non sto elaborando le richieste attivamente?											"È possibile ridurre a zero il conto delle istanze di endpoint di Amazon SageMaker Asynchronous Inference per risparmiare sui costi quando non stai elaborando le richieste attivamente. È necessario definire una policy di dimensionamento che dimensioni sul parametro personalizzato ""ApproximateBacklogPerInstance"" e imposti il valore ""MinCapacity"" su zero. Per istruzioni dettagliate, visita la sezione Dimensionamento automatico di un endpoint asincrono nella guida per gli sviluppatori."			
Cos'è amazon sagemaker serverless inference?											Amazon SageMaker Serverless Inference è un'opzione di servizio di modelli serverless dedicata che semplifica l’implementazione e la scalabilità dei modelli di ML. Gli endpoint di SageMaker Serverless Inference avviano automaticamente le risorse di calcolo e le dimensionano dentro e fuori a seconda del traffico, eliminando la necessità di scegliere il tipo di istanza, eseguire capacità in provisioning o gestire il dimensionamento. Puoi opzionalmente specificare i requisiti di memoria per il tuo endpoint di inferenza serverless. Paghi solo per la durata dell'esecuzione del codice di inferenza e la quantità di dati elaborati, non per i periodi di inattività.			
Perché dovrei usare amazon sagemaker serverless inference?											Amazon SageMaker Serverless Inference semplifica l'esperienza dello sviluppatore eliminando la necessità di effettuare il provisioning di capacità in anticipo e gestire le policy di dimensionamento. SageMaker Serverless Inference può dimensionare istantaneamente da decine a migliaia di inferenze in pochi secondi in base ai modelli di utilizzo, rendendolo ideale per applicazioni ML con traffico intermittente o imprevedibile. Per esempio, un servizio di chatbot utilizzato da un'azienda di elaborazione di buste paga sperimenta un aumento delle richieste alla fine del mese, mentre per il resto del mese il traffico è intermittente. Effettuare il provisioning delle istanze per l'intero mese in questi scenari non è conveniente perché si finisce per pagare per i periodi di inattività. SageMaker Serverless Inference aiuta ad affrontare questi tipi di casi d'uso fornendo un dimensionamento automatico e veloce pronto all’uso senza la necessità di prevedere il traffico in anticipo o gestire le policy di dimensionamento. Inoltre, viene addebitato soltanto il tempo di calcolo richiesto per eseguire il codice dell'inferenza (fatturato in millisecondi) e per l'elaborazione dei dati, rendendolo un'opzione conveniente per i carichi di lavoro con traffico intermittente.			
Cos'è provisioned concurrency per l'inferenza serverless sagemaker?											Provisioned Concurrency consente di implementare modelli su endpoint serverless con prestazioni prevedibili e scalabilità elevata, mantenendo gli endpoint pronti per un numero specificato di richieste simultanee.			
Perché è indicato utilizzare provisioned concurrency?											Con gli endpoint serverless on demand, se l'endpoint non riceve traffico per un po' di tempo e poi riceve improvvisamente nuove richieste, l'endpoint può impiegare del tempo per attivare le risorse di calcolo per elaborare le richieste. Questo si chiama avvio a freddo. Un avvio a freddo può verificarsi anche se le richieste simultanee superano l'utilizzo corrente delle richieste simultanee. Il tempo di avvio a freddo dipende dalle dimensioni del modello, dal tempo necessario per scaricare il modello e dal tempo di avvio del container. Per ridurre la variabilità del profilo di latenza, puoi facoltativamente abilitare Provisioned concurrency per i tuoi endpoint serverless. Grazie a Provisioned concurrency, i tuoi endpoint serverless sono sempre pronti e possono gestire istantaneamente picchi di traffico, senza avvii a freddo.			
Quali costi vengono addebitati per provisioned concurrency?											Come per Inferenza serverless on demand, quando la funzionalità Provisioned concurrency è abilitata, si paga in base alla capacità di calcolo utilizzata per elaborare le richieste di inferenza, fatturata al millisecondo, e alla quantità di dati elaborati. Paghi anche per l'utilizzo di Provisioned concurrency, in base alla memoria configurata, alla durata fornita e alla quantità di concorrenza abilitata. Per ulteriori informazioni, visita Prezzi di SageMaker.			
Cos'è amazon sagemaker shadow testing?											SageMaker facilita l'esecuzione di shadow test per valutare un nuovo modello di ML prima del rilascio in produzione testandone le prestazioni rispetto al modello attualmente implementato. SageMaker implementa il nuovo modello in modalità shadow accanto al modello di produzione corrente, eseguendo il mirroring di una porzione specificata dall'utente del traffico di produzione al nuovo modello. Se lo si desidera, registra le inferenze del modello per un confronto offline. Inoltre, fornisce un dashboard in tempo reale con un confronto delle metriche di prestazione chiave, come latenza e tasso di errore, tra i modelli di produzione e shadow, per rendere più facile decidere se passare il nuovo modello in produzione.  D: Quali sono i vantaggi di SageMaker per lo shadow testing?  SageMaker semplifica il processo di configurazione e monitoraggio delle varianti shadow per valutare le prestazioni del nuovo modello di ML sul traffico di produzione dal vivo. SageMaker elimina la necessità di orchestrare l'infrastruttura per lo shadow testing. Consente di controllare i parametri di test, come ad esempio la percentuale di traffico in mirroring sulla variante shadow e la durata del test. Di conseguenza, è possibile partire su scala ridotta e incrementare le richieste di inferenza del nuovo modello dopo averne verificato le prestazioni. SageMaker crea un dashboard in tempo reale che visualizza le differenze di prestazione rispetto ad alcune metriche chiave, consentendo di confrontare con facilità le prestazioni dei modelli per valutare la differenza fra il nuovo modello e quello in produzione.			
Cos'è l'inferenza con funzione di suggerimento amazon sagemaker?											Amazon SageMaker Inference Recommender è una nuova funzionalità di Amazon SageMaker che riduce il tempo necessario per mettere in produzione i modelli ML automatizzando il benchmarking delle prestazioni e regolando le prestazioni del modello attraverso le istanze ML di SageMaker. Ora è possibile usare SageMaker Inference Recommender per implementare il proprio modello in un endpoint che offre le migliori prestazioni e riduce al minimo i costi. Puoi iniziare con SageMaker Inference Recommender in pochi minuti selezionando un tipo di istanza e ottenere raccomandazioni per configurazioni ottimali di endpoint in poche ore, eliminando settimane di test manuali e i tempi di messa a punto. Con l'Inferenza con funzione di suggerimento SageMaker, paghi solo per le istanze di ML di SageMaker utilizzate durante i test di carico senza costi aggiuntivi.  D: Perché dovrei usare l'Inferenza con funzione di suggerimento Amazon SageMaker? L'utilizzo dell'Inferenza con funzione di suggerimento SageMaker è consigliato se hai bisogno di suggerimenti sulla configurazione degli endpoint appropriata per migliorare le prestazioni e ridurre i costi. In precedenza, i data scientist che volevano implementare i loro modelli dovevano eseguire dei benchmark manuali per selezionare la giusta configurazione degli endpoint. Dovevano prima selezionare il giusto tipo di istanza ML tra gli oltre 70 tipi di istanze disponibili in base ai requisiti di risorse dei loro modelli e dei payload di prova, e quindi ottimizzare il modello per tenere conto dei diversi hardware. Poi, dovevano condurre minuziosi test di carico per accertarsi che i requisiti di latenza e di velocità effettiva venissero soddisfatti e che i costi fossero bassi. L'Inferenza con funzione di suggerimento SageMaker elimina questa complessità semplificando le seguenti operazioni: 1) iniziare in pochi minuti con un suggerimento sull'istanza; 2) condurre test di carico su vari tipi di istanza per ottenere suggerimenti sulla configurazione del proprio endpoint in poche ore; 3) regolare automaticamente i parametri dei server dei modelli e dei container, nonché eseguire ottimizzazioni dei modelli per un dato tipo di istanza.  D: Come funziona l'Inferenza con funzione di suggerimento Amazon SageMaker con altri servizi AWS? I data scientist possono accedere all'nferenza con funzione di suggerimento Amazon SageMaker da SageMaker Studio, AWS SDK per Python (Boto3) o da AWS CLI. Possono ottenere suggerimenti sull'implementazione all'interno di SageMaker Studio nel registro dei modelli di SageMaker per le versioni registrate del modello. I data scientist possono cercare e filtrare i suggerimenti attraverso SageMaker Studio, l'SDK AWS o AWS CLI.			
L'inferenza con funzione di suggerimento amazon sagemaker può supportare endpoint multi-modello o endpoint multi-container?											No, attualmente supportiamo un solo modello per endpoint.			
Che tipo di endpoint supporta sagemaker inference recommender?											Attualmente supportiamo solo endpoint in tempo reale.			
Posso utilizzare l'inferenza con funzione di suggerimento amazon sagemaker in una regione ed effettuare un benchmark in regioni diverse?											Al lancio, supporteremo tutte le regioni supportate da Amazon SageMaker, eccetto le regioni AWS Cina.			
L'inferenza con funzione di suggerimento amazon sagemaker supporta le istanze amazon ec2 inf1?											Sì, supportiamo tutti i tipi di container. Amazon EC2 Inf1, basata sul chip AWS Inferentia, richiede un artefatto di modello compilato utilizzando il compilatore Neuron o Amazon SageMaker Neo. Una volta che disponi di un modello compilato per un target Inferentia e l'URI dell'immagine del container associato, puoi utilizzare l'Inferenza con funzione di suggerimento Amazon SageMaker per valutare diversi tipi di istanze Inferentia.			
Cos'è amazon sagemaker model monitor?											Amazon SageMaker Model Monitor consente agli sviluppatori di rilevare e correggere il concept drift. SageMaker Model Monitor rileva automaticamente la deviazione di concept nei modelli implementati e fornisce avvisi dettagliati che aiutano a identificare la causa del problema. Tutti i modelli addestrati su SageMaker emettono automaticamente metriche chiave che possono essere raccolte e visualizzate in Amazon SageMaker Studio. Dall'interno di SageMaker Studio è possibile configurare i dati da raccogliere, le modalità di visualizzazione e quando ricevere gli avvisi.			
È possibile accedere all'infrastruttura su cui viene eseguito amazon sagemaker?											No. Amazon SageMaker gestisce automaticamente l'infrastruttura di elaborazione, consentendo l'esecuzione di controlli dello stato, l'applicazione di patch di sicurezza e altre attività di manutenzione di routine. È anche possibile distribuire artefatti di modelli provenienti dai processi di addestramento con codice di inferenza personalizzato nell'ambiente di hosting aziendale.			
In che modo è possibile ricalibrare le dimensioni e le prestazioni di un modello di amazon sagemaker una volta avviata la fase di produzione?											L'hosting di Amazon SageMaker viene ricalibrato automaticamente mediante Application Auto Scaling in base alle prestazioni necessarie all'applicazione. Inoltre, è possibile modificare manualmente il tipo e il numero di istanze senza interrompere l'operatività apportando modifiche alla configurazione dell'endpoint.			
In che modo è possibile monitorare l'ambiente di produzione di amazon sagemaker?											Amazon SageMaker può inoltrare i propri parametri prestazionali in Amazon CloudWatch per permetterne il monitoraggio, per impostare allarmi e configurare operazioni da eseguire in base alle variazioni del traffico. Inoltre, Amazon SageMaker trascrive i propri log in Amazon CloudWatch Logs per favorire monitoraggio e risoluzione dei problemi negli ambienti di produzione.			
Quali tipi di modelli possono essere conservati in hosting con amazon sagemaker?											Amazon SageMaker è compatibile con l'hosting di qualsiasi modello conforme alle specifiche documentate per le immagini Docker di inferenza. Sono pertanto inclusi i modelli creati a partire da codice di inferenza e artefatti di modello di Amazon SageMaker.			
Quante richieste simultanee in tempo reale dell'api supporta amazon sagemaker?											Amazon SageMaker è stato progettato per ricalibrare le risorse fino a supportare un numero elevato di transazioni al secondo. Il numero preciso varia in base al modello distribuito e a tipo e numero di istanze in cui il modello è stato implementato.			
Che cos'è la trasformazione in batch?											La trasformazione in batch abilita ad eseguire analisi predittive su batch di dati di piccole e grandi dimensioni. Non è necessario porzionare il set di dati o gestire gli endpoint in tempo reale. È possibile richiedere analisi predittive con una semplice API per un numero elevato di record di dati, eseguendone la trasformazione in modo rapido e semplice.			
Cos’è amazon sagemaker edge manager?											Il Gestore di bordo Amazon SageMaker semplifica l'ottimizzazione, la sicurezza, il monitoraggio e la manutenzione di modelli di ML su flotte di dispositivi edge come telecamere intelligenti, robot, personal computer e dispositivi mobili. Il Gestore di bordo SageMaker aiuta gli sviluppatori di ML a utilizzare i modelli di ML su una varietà di dispositivi edge su larga scala.  D: Come possono iniziare a utilizzare il Gestore di bordo Amazon SageMaker?  Per iniziare a utilizzare il Gestore di bordo Amazon SageMaker è necessario compilare e confezionare i modelli addestrati di ML nel cloud, registrare i dispositivi e prepararli con l'SDK Gestore di bordo SageMaker. Per preparare il modello per l'implementazione, il Gestore di bordo SageMaker utilizza SageMaker Neo per compilare il modello per l'hardware edge di destinazione. Una volta compilato un modello, SageMaker Edge Manager firma il modello con una chiave generata da AWS, quindi confeziona il modello con il proprio runtime e le credenziali necessarie per prepararlo all’implementazione. Dal lato del dispositivo, si registra il dispositivo con SageMaker Edge Manager, si scarica l'SDK di SageMaker Edge Manager e si seguono le istruzioni per installare l'agente SageMaker Edge Manager sui propri dispositivi. Il notebook del tutorial fornisce un esempio passo per passo di come è possibile preparare i modelli e collegarli con il Gestore di bordo SageMaker sui dispositivi edge.			
Quali sono i dispositivi supportati dal gestore di bordo amazon sagemaker?											Amazon SageMaker Edge Manager supporta i comuni dispositivi basati su CPU (ARM, x86) e GPU (ARM, Nvidia) con sistemi operativi Linux e Windows. Nel corso del tempo, SageMaker Edge Manager si espanderà per supportare più processori incorporati e piattaforme mobili che sono supportati anche da SageMaker Neo.			
Devo utilizzare amazon sagemaker per addestrare il mio modello e poter utilizzare amazon sagemaker edge manager?											No. È possibile addestrare i propri modelli altrove o utilizzare un modello preaddestrato open source o un modello del tuo fornitore.			
Devo utilizzare amazon sagemaker neo per compilare il mio modello e poter utilizzare amazon sagemaker edge manager?											Sì. Amazon SageMaker Neo converte e compila i propri modelli in un eseguibile che è poi possibile confezionare e implementare sui tuoi dispositivi edge. Una volta che il pacchetto del modello è implementato, l'agente di Amazon SageMaker Edge Manager decomprimerà il pacchetto ed eseguirà il modello sul dispositivo.			
Come faccio a distribuire i modelli ai dispositivi edge?											Amazon SageMaker Edge Manager archivia il pacchetto del modello nel proprio specifico bucket di Amazon S3. È possibile utilizzare la funzione di distribuzione over-the-air (OTA) fornita da AWS IoT Greengrass o qualsiasi altro meccanismo di distribuzione a scelta per distribuire il pacchetto del modello dal proprio bucket S3 ai dispositivi.			
In che modo l’sdk di amazon sagemaker edge manager è diverso dal runtime di sagemaker neo (dlr)?											Neo dlr è un runtime open source che esegue solo modelli compilati dal servizio Amazon SageMaker Neo. Rispetto all'open source dlr, l'SDK di SageMaker Edge Manager include un agente di livello aziendale integrato nel dispositivo con ulteriore sicurezza, gestione dei modelli e funzionalità di model serving. L’SDK di SageMaker Edge Manager è adatto per la distribuzione della produzione su larga scala.			
Come è collegato amazon sagemaker edge manager con aws iot greengrass?											Amazon SageMaker Edge Manager e AWS IoT Greengrass possono lavorare insieme alla tua soluzione di IoT. Una volta che il modello di ML è confezionato con SageMaker Edge Manager, è possibile utilizzare la funzione di aggiornamento OTA di AWS Iot Greengrass per implementare il pacchetto del modello sul proprio dispositivo. AWS IoT Greengrass permette di monitorare i dispositivi IoT da remoto, mentre SageMaker Edge Manager aiuta a monitorare e mantenere i modelli di ML sui dispositivi.			
Come è collegato amazon sagemaker edge manager con aws panorama?											Quando si deve usare Amazon SageMaker Edge Manager e quando AWS Panorama?  AWS offre la massima portata e completezza delle funzionalità per l'esecuzione di modelli su dispositivi edge. Disponiamo di servizi che supportano una vasta gamma di casi d'uso tra cui la visione computerizzata, il riconoscimento vocale e la manutenzione predittiva. Per le aziende che intendono eseguire la visione computerizzata su dispositivi edge come telecamere e elettrodomestici, è possibile utilizzare AWS Panorama. Panorama offre applicazioni di visione computerizzata pronte all’uso per i dispositivi edge. È facile iniziare con AWS Panorama accedendo alla console cloud, specificando il modello che si desidera utilizzare in Amazon S3 o in SageMaker, e poi scrivendo la logica aziendale come script python. AWS Panorama compila il modello per il dispositivo di destinazione e crea un pacchetto di applicazioni in modo che possa essere distribuito ai propri dispositivi con pochi clic. Inoltre, i produttori di software indipendenti che vogliono creare le proprie applicazioni personalizzate possono utilizzare AWS Panorama SDK, mentre i produttori di dispositivi possono utilizzare Device SDK per certificare i propri dispositivi per AWS Panorama. I clienti che vogliono creare i propri modelli e hanno un controllo più granulare delle caratteristiche del modello, possono utilizzare Amazon SageMaker Edge Manager. SageMaker Edge Manager è un servizio gestito per la preparazione, l’esecuzione, il monitoraggio e l’aggiornamento di modelli di machine learning (ML) in flotte di dispositivi edge come telecamere intelligenti, altoparlanti intelligenti e robot per qualsiasi caso d’uso, come l'elaborazione del linguaggio naturale, l’individuazione delle frodi e la manutenzione predittiva. SageMaker Edge Manager è concepito per gli sviluppatori edge di ML che vogliono avere il controllo del proprio modello tra cui la progettazione di diverse funzionalità e monitorare i modelli in caso di deviazione. Qualsiasi sviluppatore edge di ML può utilizzare SageMaker Edge Manager attraverso la console e le API di SageMaker. SageMaker Edge Manager trasferisce le funzionalità di SageMaker quali creazione, addestramento e distribuzione di modelli nel cloud ai dispositivi edge.			
In quali regioni aws è disponibile amazon sagemaker edge manager?											Il Gestore di bordo Amazon SageMaker è disponibile in sei regioni AWS: Stati Uniti orientali (Virginia settentrionale), Stati Uniti orientali (Ohio), Stati Uniti occidentali (Oregon), Europa (Irlanda), Europa (Francoforte) e Asia Pacifico (Tokyo). Consulta l'elenco dei servizi per regione AWS per maggiori dettagli.			
Cos'è amazon sagemaker neo?											Amazon SageMaker Neo consente di addestrare una sola volta i modelli di ML e di eseguirli ovunque nel cloud e nell'edge. SageMaker Neo ottimizza automaticamente i modelli costruiti con framework comuni di deep learning che possono essere utilizzati per la distribuzione su più piattaforme hardware. I modelli ottimizzati vengono eseguiti fino a 25 volte più velocemente e consumano meno di un decimo delle risorse dei modelli tradizionali di machine learning.			
Come si inizia a usare amazon sagemaker neo?											Per iniziare a usare Amazon SageMaker Neo, è necessario eseguire l'accesso nella Amazon SageMaker console, scegliere un modello formato, seguire l'esempio per compilare i modelli e distribuire il modello risultante nella piattaforma hardware di destinazione.			
Quali sono i componenti principali di amazon sagemaker neo?											Amazon SageMaker Neo contiene due componenti principali: un compilatore e un runtime. Prima, il compilatore Neo legge modelli esportati da diversi framework. Converte quindi le funzioni specifiche del framework e le operazioni in una rappresentazione intermedia indipendente dal framework. Inoltre, esegue una serie di ottimizzazioni. Quindi, il compilatore genera un codice binario per le operazioni ottimizzate e le scrive in una libreria di oggetti condivisa. Il compilatore salva inoltre la definizione del modello e i parametri in file separati. Durante l'esecuzione, il runtime Neo carica gli artefatti generati dal compilatore, definizione del modello, parametri e libreria di oggetti condivisa per eseguire il modello.			
Devo utilizzare amazon sagemaker per formare il mio modello e poter utilizzare amazon sagemaker neo per convertire il modello?											No. È possibile formare modelli altrove e utilizzare Neo per ottimizzarli per le istanze ML Amazon SageMaker o i dispositivi supportati AWS IoT Greengrass.			
Quali modelli supporta amazon sagemaker neo?											Al momento, Amazon SageMaker Neo supporta i modelli di deep learning più conosciuti che alimentano le applicazioni di visione artificiale e i modelli di albero delle decisioni utilizzati in Amazon SageMaker oggi. Neo ottimizza le prestazioni dei modelli AlexNet, ResNet, VGG, Inception, MobileNet, SqueezeNet e DenseNet addestrati in MXNet e TensorFlow, e i modelli classification e random cut forest addestrati in XGBoost.			
Quali piattaforme hardware supporta amazon sagemaker neo?											È possibile trovare l’elenco delle istanze cloud supportate, dei dispositivi edge e delle versioni del framework nella documentazione relativa ad Amazon SageMaker Neo.			
In quali regioni aws è disponibile amazon sagemaker neo?											Per visualizzare le regioni supportare, consulta l'elenco dei servizi per regione AWS.			
Cosa sono i savings plans di amazon sagemaker?											Savings Plans di Amazon SageMaker offre un modello flessibile di determinazione dei prezzi basato sull'uso per Amazon SageMaker, in cambio dell'impegno di un uso costante (misurato in dollari/ore) per un periodo annuale o triennale. Amazon SageMaker Savings Plans fornisce la massima flessibilità e contribuiscono a ridurre i costi fino al 64%. Questi piani si applicano automaticamente agli usi idonei delle istanze ML SageMaker, inclusi SageMaker Studio Notebooks, SageMaker On-Demand Notebooks, SageMaker Processing, SageMaker Data Wrangler, SageMaker Training, SageMaker Real-Time Inference e SageMaker Batch Transform, indipendentemente dalla famiglia di istanze, dalla dimensione o dalla regione. Per esempio, si può modificare in qualsiasi momento l'uso da un'istanza CPU ml.c5.xlarge in esecuzione negli Stati Uniti orientali (Ohio) a un'istanza ml.Inf1 in esecuzione negli Stati Uniti occidentali (Oregon) per carichi di lavoro di inferenza e continuare automaticamente a pagare il prezzo di Savings Plans.  Perché dovrei usare Savings Plans di Amazon SageMaker? In caso di uso costante (misurato in dollari/ore) delle istanze Amazon SageMaker e di molteplici componenti di SageMaker o se si prevede un cambiamento della configurazione tecnologica (ad esempio famiglia di istanze, regione) nel corso del tempo, SageMaker Savings Plans semplifica l'ottimizzazione dei risparmi offrendo allo stesso tempo la flessibilità di modificare la configurazione tecnologica sottostante in base alle necessità dell'applicazione o alle innovazioni. La tariffa Savings Plans si applica automaticamente a tutti gli usi idonei delle istanze ML senza che sia necessaria alcuna modifica manuale.			
Come si comincia a usare i savings plans di amazon sagemaker?											Puoi iniziare a utilizzare Savings Plans da AWS Cost Explorer nella console di gestione o utilizzando API/CLI. Puoi stabilire facilmente l'impegno per i Savings Plans usando i suggerimenti forniti in AWS Cost Explorer per ottenere il massimo risparmio. L'impegno orario delle raccomandazioni è basato sul tuo storico dell'utilizzo di on demand e sulla tua scelta del tipo di piano, della lunghezza e dell'opzione di pagamento. Una volta effettuata l'iscrizione a Savings Plan, l'uso sarà automaticamente fatturato alla tariffa scontata del prezzo di Savings Plans e ogni uso superiore all'impegno stabilito sarà fatturato alla tariffa on demand normale.  D: Qual è la differenza tra Savings Plans per Amazon SageMaker e Compute Savings Plans per Amazon EC2? La differenza tra Savings Plans per Amazon SageMaker e Savings Plans per EC2 sta nei servizi inclusi. I piani di risparmio SageMaker si applicano solo all'uso di SageMaker ML Instance.  D: Come funziona Savings Plans con AWS Organizations/Fatturazione consolidata? Savings Plans può essere acquistato in qualsiasi account all'interno di una famiglia AWS Organization/Fatturazione consolidata. Per impostazione predefinita, il vantaggio fornito da Savings Plans è applicabile all'uso in tutti gli account di una famiglia AWS Organization/Fatturazione consolidata. Si può anche scegliere tuttavia di restringere il vantaggio di Savings Plans al solo account in cui si è effettuato l'acquisto.			
Cos'è amazon sagemaker ground truth plus?												Amazon SageMaker Ground Truth Plus consente di creare facilmente set di dati di formazione di alta qualità senza dover creare applicazioni di etichettatura o gestire le forze lavoro di etichettatura personalmente. Una volta forniti i dati insieme ai requisiti di etichettatura, SageMaker Ground Truth Plus gestisce l'impostazione dei flussi di lavoro di etichettatura dei dati e li controlla per tuo conto, in conformità ai tuoi requisiti. Da lì, una forza lavoro esperta addestrata su varie attività di machine learning (ML) esegue l'etichettatura dei dati. Ground Truth Plus utilizza tecniche di ML, inclusi apprendimento attivo, pre-etichettatura e convalida automatica. Ciò migliora la qualità del set di dati di output e riduce i costi di etichettatura dei dati. Ground Truth Plus fornisce trasparenza nelle operazioni di etichettatura dei dati e nella gestione della qualità. Con Ground Truth Plus puoi monitorare l'andamento dei set di dati di formazione in più progetti, tenere traccia delle metriche dei progetti, ad esempio la velocità effettiva giornaliera, analizzare la qualità delle etichette e fornire un feedback sui dati etichettati. Ground Truth Plus può essere utilizzato per vari casi d'uso, tra cui visione artificiale, elaborazione del linguaggio naturale e riconoscimento vocale.		
Perché dovrei usare amazon sagemaker ground truth plus?												Per formare un modello di machine learning (ML), i data scientist hanno bisogno di set di dati etichettati di grandi dimensioni e qualità elevata. Man mano che cresce l'adozione di ML, le esigenze di etichettatura aumentano. Questo costringe i data scientist a trascorrere settimane a costruire flussi di lavoro di etichettatura dei dati e a gestire una forza lavoro per l'etichettatura dei dati. Purtroppo, questo rallenta l'innovazione e aumenta i costi. Per poter dedicare il loro tempo alla costruzione, alla formazione e all'implementazione di modelli di ML, i data scientist in genere incaricano altri team interni costituiti da responsabili delle operazioni sui dati e da responsabili di programmi di produrre set di dati di formazione di alta qualità. Tuttavia, questi team in genere non hanno accesso alle competenze necessarie per fornire set di dati di formazione di alta qualità, il che influisce sui risultati di ML. Amazon SageMaker Ground Truth Plus consente ai data scientist, nonché ai responsabili aziendali, come gestori di operazioni sui dati e gestori di programmi, di creare set di dati di formazione di alta qualità, eliminando il lavoro pesante indifferenziato associato alla creazione di applicazioni di etichettatura dei dati e alla gestione della forza lavoro di etichettatura. Tutto ciò che devi fare è condividere i dati insieme ai requisiti di etichettatura e Ground Truth Plus imposta e gestisce il tuo flusso di lavoro di etichettatura dei dati, in base a questi requisiti. Da lì, una forza lavoro esperta addestrata su varie attività di ML esegue l'etichettatura dei dati. Per utilizzare Ground Truth Plus, non hai nemmeno bisogno di una profonda esperienza di ML o di una conoscenza della progettazione del flusso di lavoro e della gestione della qualità.		
Come inizio a utilizzare amazon sagemaker ground truth plus?												Per iniziare subito a utilizzare Amazon SageMaker Ground Truth Plus, completa il modulo di requisiti del progetto. Il nostro team ti contatterà per discutere il tuo progetto di etichettatura dei dati.		
In che modo amazon sagemaker ground truth plus può aiutarmi a gestire i miei set di dati di formazione?												Amazon SageMaker Ground Truth Plus fornisce maggiore trasparenza nelle operazioni di etichettatura dei dati e nella gestione della qualità. Ad esempio, SageMaker Ground Truth Plus fornisce una vista del progetto, che puoi utilizzare per monitorare l'andamento del set di dati di formazione in diversi progetti. Inoltre, un pannello di controllo di metriche in tempo reale permette di tenere traccia delle metriche dettagliate del progetto, tra cui la velocità effettiva giornaliera. SageMaker Ground Truth Plus fornisce anche un'interfaccia utente che consente di analizzare la qualità delle etichette e fornire un feedback in tempo reale. Infine, con la modalità streaming, puoi ottenere un tempo di risposta dell'etichetta nello stesso giorno o nella stessa ora per determinati tipi di carichi di lavoro.		
In che modo amazon sagemaker ground truth plus contribuisce ad aumentare la precisione dei miei set di dati di formazione?												Ground Truth Plus utilizza molte tecniche per aumentare la precisione del set di dati di formazione: Qual è la differenza tra SageMaker Ground Truth e SageMaker Ground Truth Plus? • SageMaker Ground Truth Plus è un servizio chiavi in mano completamente gestito, in cui gli esperti AWS configurano e gestiscono i flussi di lavoro e una forza lavoro esterna di etichettatori di dati. Ha uno SLA garantito in termini di qualità, tempistiche per la consegna delle etichette e prezzi personalizzati. SageMaker Ground Truth è un'opzione self-service in cui i clienti possono configurare i propri flussi di lavoro, scegliere tra interfacce utente di etichettatura predefinite o svilupparne di proprie e gestire la propria forza lavoro interna. Possono anche procurarsi la forza lavoro da Mechanical Turk o da un fornitore nel Marketplace AWS. I prezzi di SageMaker Ground Truth si basano sul piano tariffario pubblico.		
In che modo amazon sagemaker ground truth plus contribuisce a proteggere e rendere sicuri i miei dati?												Per impostazione predefinita, Amazon SageMaker Ground Truth Plus codifica i dati archiviati in un bucket di Amazon S3 a riposo e in transito. L'accesso ai dati è controllato tramite AWS Identity and Access Management (IAM). I tuoi dati vengono memorizzati in un account AWS indipendente e un bucket Amazon S3 viene creato per il tuo progetto. Amazon SageMaker Ground Truth Plus non archivia né esegue copie dei dati al di fuori dell'ambiente AWS creato per te. AWS registra e controlla tutti gli accessi ai tuoi dati utilizzando la registrazione degli accessi ad Amazon S3 e AWS CloudTrail.		
Chi ha accesso ai miei contenuti elaborati e archiviati da amazon sagemaker ground truth plus?												I dipendenti autorizzati di AWS e la forza lavoro esperta che etichetta i tuoi dati avranno accesso ai tuoi contenuti elaborati da Amazon SageMaker Ground Truth Plus. La forza lavoro esperta che etichetta i tuoi dati li visualizza e li etichetta attraverso il portale sicuro dei lavoratori di SageMaker Ground Truth. L'accesso attraverso il portale dei lavoratori permette ai lavoratori solo di visualizzare ed etichettare i dati, non di modificarli o eliminarli. La tua fiducia, la tua privacy e la tua sicurezza sono la nostra massima priorità. Implementiamo controlli tecnici e fisici appropriati, compresa la crittografia a riposo e in transito, progettati per impedire l'accesso non autorizzato o la divulgazione dei tuoi contenuti.		
Gli input di dati (immagini, file di testo, video, ecc.) elaborati da amazon sagemaker ground truth plus vengono archiviati?												Come vengono utilizzati da AWS? Amazon SageMaker Ground Truth Plus archivia i contenuti elaborati e non elaborati solo per la durata dei tuoi progetti ed elimina i contenuti associati al tuo progetto di etichettatura dei dati su richiesta. Amazon SageMaker Ground Truth Plus utilizza i tuoi contenuti esclusivamente per fornire e mantenere il servizio. Amazon SageMaker Ground Truth Plus non utilizza mai i tuoi contenuti o qualsiasi modello formato su quei contenuti a beneficio di altri clienti.		
I contenuti elaborati da amazon sagemaker ground truth plus vengono spostati al di fuori della regione aws in cui utilizzo amazon sagemaker ground truth plus?												I contenuti elaborati da Amazon SageMaker Ground Truth Plus vengono codificati e archiviati a riposo nella Regione AWS in cui utilizzi Amazon SageMaker Ground Truth Plus. A meno che non specifichi diversamente nei requisiti di localizzazione dei dati concordati reciprocamente attraverso una dichiarazione di lavoro, sarà possibile accedere ai tuoi contenuti al di fuori della Regione AWS in cui sono archiviati per eseguire il servizio di etichettatura.		
Posso richiedere l'eliminazione dei dati (immagini, file di testo, video ecc.) archiviati da amazon sagemaker ground truth plus?												Sì. Puoi richiedere l'eliminazione di input di dati elaborati e non elaborati associati al tuo progetto di etichettatura dei dati contattando il Supporto AWS.		
I miei contenuti elaborati e archiviati da amazon sagemaker ground truth plus rimangono di mia proprietà?												Sì. Manterrai la proprietà sui contenuti. Li useremo solo previo consenso.		
Posso elaborare i dati relativi alle informazioni sanitarie personali (phi) attraverso amazon sagemaker ground truth plus?												No. Attualmente, Amazon SageMaker Ground Truth Plus non è un servizio idoneo alla normativa HIPAA.		
Cos'è una forza lavoro esperta in amazon sagemaker ground truth plus?												Con Ground Truth Plus, l'etichettatura viene eseguita da una forza lavoro altamente qualificata, diversificata ed elastica, addestrata su attività di machine learning che può contribuire a soddisfare un'ampia varietà di esigenze, tra cui sicurezza, privacy e conformità dei dati. La forza lavoro è formata da due livelli, 1/Forza lavoro di Amazon: è costituita da lavoratori impiegati e gestiti da Amazon, laddove Amazon controlla gli SLA di operazioni, qualità e tempo di risposta per tuo conto. 2/Forza lavoro del fornitore: è costituita da lavoratori presenti in una lista curata di fornitori di terze parti, specializzati nella fornitura di servizi di etichettatura dei dati, laddove Amazon controlla gli SLA di qualità e tempo di risposta per tuo conto.		
Chi decide quale livello di forza lavoro sarà usato per il mio progetto amazon sagemaker ground truth plus?												Puoi decidere il tipo di forza lavoro da utilizzare per il tuo progetto. A meno che non indichi di utilizzare una forza lavoro specifica, per aiutarti a soddisfare i requisiti di qualità, tempo di risposta e sicurezza del tuo progetto, può essere utilizzata la forza lavoro di Amazon, la forza lavoro del fornitore o una combinazione di entrambe.		
Di quali cambiamenti implementati dalla forza lavoro del fornitore alla luce del covid-19 dovrei essere al corrente?												Alla luce del COVID-19, alcuni fornitori di servizi hanno implementato una policy di lavoro a distanza per la salute e la sicurezza dei loro dipendenti.		
Quali standard di sicurezza deve rispettare la forza lavoro di un fornitore?												I fornitori di servizi devono ottenere la conformità SOC 2 o la certificazione ISO 27001 su base annuale da parte di un revisore terzo indipendente. Il report SOC 2 contiene una descrizione dell'ambiente di controllo del fornitore di servizi basata sui Trust Services Criteria dell'American Institute of Certified Public Accountants (AICPA): sicurezza, disponibilità, processo, integrità, confidenzialità e riservatezza. La certificazione ISO 27001 si basa sull'International Organization for Standardization (ISO) e sull'International Electrotechnical Commission (IEC), che illustra nei dettagli i requisiti per stabilire, implementare, mantenere e migliorare continuamente un sistema di gestione della sicurezza delle informazioni (ISMS). Oltre a ottenere indipendentemente SOC 2 o ISO 27001, i fornitori di servizi sono tenuti a mantenere ulteriori controlli di sicurezza, descritti di seguito, per contribuire a mantenere i tuoi dati sicuri. Controlli tecnologici: I fornitori di servizi devono utilizzare software appropriati per bloccare ogni tentativo di scaricare o copiare i file/dati dai propri sistemi e prevenire l'accesso non autorizzato a questi ultimi. I fornitori di servizi devono inoltre vietare ai loro dipendenti di archiviare o copiare i dati relativi alle attività dei clienti. Controlli di sicurezza di rete: Chiediamo che la rete dei nostri fornitori di servizi sia progettata in modo da prevenire l'accesso da remoto ai dati relativi alle attività del cliente. Inoltre, la condivisione di file peer-to-peer è bloccata nella rete del fornitore e il firewall dovrebbe poter consentire un'elevata disponibilità. Controllo dei dipendenti: I fornitori di servizi devono garantire di avere accordi di non divulgazione con i propri dipendenti. I fornitori di servizi devono adottare politiche rigide per prevenire qualsiasi divulgazione delle informazioni ed evitare la trasmissione delle informazioni da parte dei dipendenti attraverso qualsiasi mezzo: cartaceo, USB, telefono cellulare o altri supporti. Controlli sugli accessi fisici: I fornitori di servizi devono mantenere misure di controllo sugli accessi fisici per prevenire accessi non autorizzati ai loro siti di produzione. Ciò può includere tornelli con autenticazione biometrica, identificazione del dipendente attraverso un badge, ecc.		
In che modo aws aiuta la forza lavoro di un fornitore a rispettare questi standard di sicurezza?												AWS richiede che i fornitori di servizi forniscano rapporti sulle loro certificazioni SOC 2 o ISO 27001 prima di diventare parte della forza lavoro dei fornitori di Amazon SageMaker Ground Truth Plus. I report SOC e le certificazioni ISO di AWS non coprono la forza lavoro dei fornitori.		
Cos'è amazon sagemaker ground truth?												Amazon SageMaker Ground Truth consente di etichettare in modo efficiente e accurato i set di dati richiesti per la formazione dei sistemi di machine learning. SageMaker Ground Truth può etichettare automaticamente una parte del set di dati in base alle etichette fatte manualmente dagli etichettatori. Puoi scegliere di utilizzare una forza lavoro di Amazon Mechanical Turk in crowdsourcing composta da oltre 500.000 etichettatori, i tuoi dipendenti o uno dei fornitori di servizi di terze parti per l’etichettatura dati elencato in AWS Marketplace, precedentemente selezionato da Amazon. SageMaker Ground Truth utilizza algoritmi innovativi e tecniche di esperienza utente (UX) per migliorare la precisione dell'etichettatura umana. Nel tempo, il modello migliora progressivamente imparando continuamente dalle etichette create dagli esseri umani, per aumentare l'etichettatura automatica.		
Che cos'è l'etichettatura dei dati automatica?												L'etichettatura dei dati automatica è l'etichettatura dei dati mediante il machine learning. Amazon SageMaker Ground Truth selezionerà prima un campione casuale di dati e lo invierà agli umani per essere etichettato. I risultati vengono quindi utilizzati per addestrare un modello di etichettatura che tenta di etichettare automaticamente un nuovo campione di dati grezzi. Le etichette vengono confermate quando il modello può etichettare i dati con un punteggio di confidenza che soddisfa o supera una soglia elevata. Laddove il punteggio di confidenza scende al di sotto di questa soglia, i dati vengono inviati agli etichettatori. Alcuni dati etichettati da persone vengono utilizzati per generare un nuovo gruppo di dati per formare un modello di etichettatura e il modello viene riformato nuovamente in modo automatico per migliorarne l’accuratezza. Questo processo si ripete con ogni campione di dati grezzi da etichettare. Con ogni iterazione, il modello di etichettatura diventa più capace di etichettare automaticamente i dati grezzi e meno dati vengono instradati agli esseri umani.		
Perché dovrei utilizzare amazon sagemaker ground truth?												Prima di costruire, formare e implementare modelli di machine learning, hai bisogno di dati. I modelli di successo si basano su dati di formazione di alta qualità: la raccolta e l'etichettatura dei set di dati di formazione richiede molto tempo e impegno. Per costruire i set di dati in cui essere formati, gli etichettatori devono valutare un gran numero di immagini o altri tipi di dati, quindi identificare ed etichettare determinati oggetti in ogni tipo di dati. Queste attività di etichettatura sono distribuite tra molti etichettatori, aggiungendo spese generali e costi significativi. Se ci sono etichette errate, il sistema apprende dalle informazioni errate e fa previsioni imprecise. Amazon SageMaker Ground Truth risolve questo problema semplificando l'esecuzione efficiente dell'etichettatura dei dati utilizzando i dati archiviati in Amazon S3, utilizzando una combinazione di etichettatura automatica dei dati e etichettatura eseguita dall'uomo.		
Come inizio con amazon sagemaker ground truth?												Amazon SageMaker Ground Truth offre un'esperienza gestita in cui è possibile impostare un intero lavoro di etichettatura dei dati con pochi passaggi. Per iniziare a utilizzare Amazon SageMaker Ground Truth, accedi alla Console di gestione AWS e vai alla console SageMaker. Quindi seleziona Lavori di etichettatura in Ground Truth. Qui puoi creare un lavoro di etichettatura. Per prima cosa, come parte del flusso di creazione del lavoro di etichettatura, fornisci un puntatore al bucket S3 che contiene il set di dati da etichettare. Ground Truth offre modelli per attività di etichettatura comuni in cui è sufficiente fare clic su alcune scelte e fornire istruzioni minime su come ottenere l’etichettatura dei propri dati. In alternativa, puoi creare il tuo modello personalizzato. Come ultima fase della creazione di un lavoro di etichettatura, seleziona una delle tre opzioni umane di forza lavoro: (1) una forza lavoro pubblica crowdsourcing, (2) un insieme selezionato di fornitori di servizi di terze parti per l’etichettatura dati, oppure (3) usa lavoratori di tua scelta. Hai inoltre la possibilità di abilitare l'etichettatura automatica dei dati.		
In che modo i miei set di dati di addestramento sono gestiti utilizzando amazon sagemaker ground truth?												Amazon SageMaker Ground Truth gestisce i metadati, le etichette associate e una tassonomia delle etichette e dei set di dati. È possibile utilizzare facilmente AWS SDK tramite un notebook SageMaker, o la console di Ground Truth all'interno della console SageMaker, per richiedere e gestire i set di dati e le etichette. Consulta la documentazione di Amazon SageMaker Ground Truth per maggiori informazioni.		
In che modo amazon sagemaker ground truth consente di aumentare la precisione dei miei set di dati di formazione?												"Amazon SageMaker Ground Truth offre le seguenti funzionalità per permettere di aumentare la precisione dell'etichettatura dei dati eseguita dagli esseri umani: (a) Consolidamento delle annotazioni: contrasta l'errore/bias dei singoli lavoratori inviando ciascun oggetto dati a più lavoratori e quindi consolida le loro risposte (dette ""annotazioni"") in un'unica etichetta. Quindi prende le loro annotazioni e le confronta usando un algoritmo di consolidamento delle annotazioni. Questo algoritmo prima rileva le annotazioni anomale che vengono ignorate. Esegue quindi un consolidamento ponderato delle annotazioni, assegnando pesi più elevati a annotazioni più affidabili. L'output è una singola etichetta per ogni oggetto. (b) Best practice dell'interfaccia di annotazione:  queste sono le caratteristiche delle interfacce di annotazione che consentono ai lavoratori di svolgere le loro attività in modo più accurato. I lavoratori umani sono inclini a errori e pregiudizi e interfacce ben progettate migliorano la precisione del lavoratore. Una buona pratica è quella di visualizzare brevi istruzioni associate ad esempi di etichette buone e cattive in un pannello laterale fisso. Un'altra best practice è di scurire l'area al di fuori del confine del riquadro quando i lavoratori stanno disegnando il riquadro di delimitazione su un'immagine."		
In che modo amazon sagemaker ground truth garantisce che i miei dati sono protetti e sicuri?												Per impostazione predefinita, Amazon SageMaker Ground Truth crittografa i dati a riposo e in transito. L'accesso ai dati può anche essere controllato tramite AWS Identity and Access Management (IAM). Ground Truth non memorizza o crea copie dei tuoi dati al di fuori del tuo ambiente AWS e i tuoi dati rimangono sotto il tuo controllo. Inoltre, Ground Truth supporta standard di conformità come il GDPR (General Data Protection Regulation) e offre funzionalità complete di registrazione e auditing utilizzando Amazon CloudWatch e Amazon CloudTrail. Consulta la documentazione di Amazon SageMaker Ground Truth per maggiori informazioni.		
Come posso accedere a una forza lavoro umana utilizzando amazon sagemaker ground truth?												Da SageMaker Ground Truth, puoi scegliere una delle tre opzioni della forza lavoro, ovvero (1) la forza lavoro pubblica crowdsourcing attraverso Amazon Mechanical Turk, (2) fornitori di servizi terzi per l'etichettatura dei dati disponibili attraverso Marketplace AWS e (3) i tuoi dipendenti. Consulta la documentazione di Amazon SageMaker Ground Truth per maggiori informazioni.		
I fornitori di servizi di etichettatura dei dati di amazon sagemaker ground truth possono processare dati riservati?												Sì, il fornitore di servizi di etichettatura dei dati di Amazon SageMaker Ground Truth può processare dati riservati. Il contratto sul servizio standard tra i clienti AWS e i fornitori terzi di servizi di etichettatura dei dati contiene alcune protezioni di base per le tue informazioni riservate. Verifica tali termini prima di condividere qualsiasi informazione riservata con il fornitore di servizi. Le condizioni sono disponibili nella pagina contenente gli elenchi del fornitore di servizi su AWS Marketplace.		
Lavoro con un fornitore di servizi di terze parti attraverso aws marketplace. di quali cambiamenti implementati dai fornitori di servizi alla luce del covid-19 dovrei essere al corrente?												Considerando il rapido impatto del COVID-19, alcuni fornitori di servizi hanno implementato temporaneamente una policy di lavoro a distanza per la sicurezza dei loro dipendenti. Durante questo periodo, gli standard di sicurezza tra cui la conformità SOC 2 e ulteriori controlli di sicurezza delineati nella sezione Domande Frequenti sottostante potrebbero non essere applicabili ai fornitori di servizi interessati. Per adattarsi a questa situazione, i fornitori di servizi interessati hanno aggiornato i loro elenchi di Marketplace AWS e non tratteranno i dati dei clienti a distanza senza il consenso specifico del cliente.	R: Considerando il rapido impatto del COVID-19, alcuni fornitori di servizi hanno implementato temporaneamente disposizioni sul lavoro a distanza per la sicurezza dei loro dipendenti. Durante questo periodo, gli standard di sicurezza tra cui la conformità SOC 2 e ulteriori controlli di sicurezza delineati nella sezione Domande frequenti sottostante potrebbero non essere validi per i fornitori di servizi interessati. Per adattarsi a questa situazione, i fornitori di servizi interessati hanno aggiornato i loro elenchi AWS Marketplace e non tratteranno i dati dei clienti a distanza senza il consenso specifico del cliente.	
A quali standard di sicurezza i fornitori di servizi di etichettatura dei dati di amazon sagemaker ground truth devono rispondere?												Un fornitore di servizi di etichettatura dei dati deve possedere conformità e certificazione SOC 2 su base annuale. Il report SOC 2 contiene una descrizione dell'ambiente di controllo del fornitore di servizi basata sui Trust Services Criteria dell'American Institute of Certified Public Accountants (AICPA): sicurezza, disponibilità, processo, integrità, confidenzialità e riservatezza. Oltre al SOC 2, ai fornitori di servizi viene richiesto di mantenere questi ulteriori controlli di sicurezza, per conservare al sicuro i dati dei clienti. Controlli tecnologici: I fornitori di servizi devono utilizzare software appropriati per bloccare ogni tentativo di scaricare o copiare i file/dati dai propri sistemi e prevenire l'accesso non autorizzato a questi ultimi. I fornitori di servizi devono inoltre vietare ai loro dipendenti di archiviare o copiare i dati relativi alle attività dei clienti. Controlli di sicurezza di rete: Chiediamo che la rete dei nostri fornitori di servizi sia progettata in modo da prevenire l'accesso da remoto ai dati relativi alle attività del cliente. Inoltre, la condivisione di file peer-to-peer è bloccata nella rete del fornitore e il firewall dovrebbe poter consentire un'elevata disponibilità. Controllo dei dipendenti: I fornitori di servizi devono garantire di avere accordi di non divulgazione con i propri dipendenti. I fornitori di servizi devono adottare politiche rigide per prevenire qualsiasi divulgazione delle informazioni ed evitare la trasmissione delle informazioni da parte dei dipendenti attraverso qualsiasi mezzo: cartaceo, USB, telefono cellulare o altri media. Controlli sugli accessi fisici: I fornitori di servizi devono mantenere misure di controllo sugli accessi fisici per prevenire accessi non autorizzati ai loro siti di produzione. Ciò può includere tornelli con autenticazione biometrica, identificazione del dipendente attraverso un badge, ecc.		
In che modo aws garantisce che i fornitori di servizi si attengano a questi standard di sicurezza?												AWS chiede ai fornitori di servizi di fornire i report di certificazione SOC 2 prima di essere inseriti negli elenchi di marketplace e ne conferma: L'autenticità (se il fornitore di servizi è certificato presso l'AICPA); Il periodo del report (data di validità della certificazione SOC 2); e Il sito di produzione (il sito fisico dove la forza lavoro del fornitore di servizi lavora sulle attività di etichettatura di Amazon SageMaker Ground Truth).	R: AWS chiede ai fornitori di servizi di fornire i report di certificazione SOC 2 prima di essere inseriti negli elenchi di marketplace e ne conferma: L'autenticità (se il fornitore di servizi è certificato presso l'AICPA). Il periodo del report (data di validità della certificazione SOC 2). La verifica del sito di produzione (il sito fisico dove la forza lavoro del fornitore di servizi lavora sulle attività di Amazon Augmented AI).	
Qual è la frequenza di verifica degli standard di sicurezza del fornitore di servizi?												Gli standard di sicurezza di ogni fornitore di servizi vengono verificati annualmente per assicurare il rispetto dei requisiti obbligatori.	R: Gli standard di sicurezza di ogni fornitore di servizi vengono verificati annualmente per assicurare il rispetto dei requisiti obbligatori.	
Esistono eccezioni alla verifica di aws?												No. Se un fornitore di servizi non risponde agli standard di sicurezza, il loro elenco viene rimosso dal Marketplace AWS. La rimozione dall'elenco viene completata entro 24 ore e tutti i clienti attivi ricevono una notifica via e-mail.	R: No. Se un fornitore di servizi non risponde agli standard di sicurezza, la sua inserzione viene rimossa da AWS Marketplace. La rimozione dall'elenco viene completata entro 24 ore e tutti i clienti interessati ricevono una notifica via e-mail.	
Qualora un fornitore di servizi offra servizi di etichettatura dei dati in diversi siti di produzione, questi ultimi devono tutti essere sottoposti al processo di verifica?												Sì. Tutti i siti devono rispettare gli standard di sicurezza richiesti.		
Cosa accade in caso di violazione dei dati sul sito di produzione del fornitore di servizi?												Il fornitore di servizi informa AWS e i clienti interessati entro 24 ore dal rilevamento di qualsiasi accesso, raccolta, acquisizione, utilizzo, trasmissione, divulgazione, corruzione o perdita non autorizzata, reale o sospettata, delle informazioni dei clienti. Il fornitore di servizi rimedierà nell'immediato ad ogni incidente di sicurezza e fornirà per iscritto dettagli sulle investigazioni interne ad AWS e ai clienti interessati.		
Quanto costa amazon sagemaker ground truth?												Consulta la pagina dei prezzi di SageMaker Ground Truth per informazioni sui prezzi attuali.		
In quali regioni aws è disponibile amazon sagemaker ground truth?												La tabella delle Regioni AWS elenca tutte le regioni AWS in cui Amazon SageMaker Ground Truth è attualmente disponibile.		
Come posso generare dati sintetici etichettati?												Amazon SageMaker Ground Truth permette di generare dati sintetici etichettati al posto tuo. Tu specifichi i tuoi requisiti di immagine sintetica o fornisci asset 3D e immagini di base, come immagini di progettazione assistita dall'elaboratore (CAD), e gli artisti digitali di AWS creano immagini da zero o utilizzano asset forniti dal cliente. Le immagini generate imitano pose e posizionamenti di oggetti, includono variazioni di oggetti o scene e opzionalmente aggiungono delle integrazioni, come scratch, tagli e altre alterazioni, eliminando il dispendioso processo di raccolta di dati o il bisogno di danneggiare parti per acquisire immagini. SageMaker Ground Truth può generare centinaia di migliaia di immagini sintetiche etichettate automaticamente con elevata precisione.		
Perché dovrei usare dati sintetici etichettati?												Ottenere dati per i modelli di formazione di machine learning (ML) impiega molto tempo e molti sforzi. Per alcuni tipi di dati, come scenari rari o altamente variabili, la raccolta di dati può essere costosa o persino impossibile. Per esempio, identificare difetti di manifattura richiede una grande quantità di immagini. Inoltre, i modelli di ML devono essere formati a riconoscere scenari che non si verificano frequentemente, come difetti rari. Per identificare i difetti rari, i modelli di ML necessitano di immagini di difetti. Tuttavia, dal momento che questi eventi accadono in maniera non frequente, questi dati sono spesso creati manualmente, il che può richiedere danni a parti costose. Infine le immagini devono essere etichettate manualmente. Utilizzando SageMaker Ground Truth, è possibile generare dati sintetici che sono automaticamente etichettati, riducendo il tempo e le spese necessarie alla raccolta e all'etichettatura dei dati di formazione. Puoi quindi usare i dati sintetici per formare modelli di ML attraverso un'ampia gamma di casi d'uso di visioni informatiche, come oggetti, anomalie e individuazione dei difetti.		
Come fa amazon sagemaker ground truth a generare dati sintetici etichettati?												Vi è un processo in tre fasi per generare dati sintetici etichettati. In primo luogo, si forniscono asset 3D, immagini base, e/o requisiti di immagine. In secondo luogo, gli artisti digitali convertono questi input in asset 3D, aggiungendo integrazioni come scratch, tagli e texture. In terzo luogo, SageMaker Ground Truth genera immagini sintetiche e le etichette automaticamente.		
Posso usare sagemaker ground truth per generare dati sintetici etichettati se non possiedo immagini o asset 3d?												Sì, vi è una libreria di asset 3D di più di 1 milione di oggetti che può essere usata per supportare la creazione di dati sintetici al posto tuo. In alternativa, è possibile utilizzare un piccolo set di immagini pre-etichettate per creare nuovi set di dati sintetici. Se si hanno immagini di background o esempi dei dati necessari, questi possono accelerare la creazione di dati sintetici altamente accurati.		
Come posso usare amazon sagemaker ground truth plus per creare le mie applicazioni di ia generativa?												SageMaker Ground Truth Plus ti aiuta a generare set di dati di alta qualità per personalizzare e allineare i modelli di base alle preferenze umane. Esistono due tipi di set di dati etichettati generati da Amazon SageMaker Ground Truth: dati dimostrativi e dati sulle preferenze. Nei dati dimostrativi, un annotatore di dati completa un'attività (come scrivere domande e risposte o riassumere un testo) che simula e dimostra come un modello interagirebbe con un essere umano. Il set di dati etichettato viene quindi utilizzato per ottimizzare il modello in un processo noto come ottimizzazione di precisione supervisionata (SFT). Nei dati sulle preferenze, un annotatore umano fornisce feedback diretti e indicazioni sul contenuto generato da un modello o sui dati del modello simulato. Ad esempio, classificare le risposte testuali di un modello linguistico di grandi dimensioni in base a dimensioni specifiche come precisione, pertinenza o chiarezza di scrittura. Un metodo di ottimizzazione che utilizza i dati sulle preferenze è chiamato apprendimento per rinforzo dal feedback umano (RLHF).		
Quali casi d'uso dell'ia generativa può supportare amazon sagemaker ground truth plus?												Amazon SageMaker Ground Truth Plus ti consente di generare set di dati per modelli linguistici di grandi dimensioni (LLM), modelli testo-immagine e modelli testo-video. Per i modelli linguistici di grandi dimensioni, gli annotatori di dati possono creare set di dati dimostrativi per la messa a punto supervisionata, tra cui coppie di domande e risposte, riepiloghi di testo, rielaborazione del testo per aggiungere elementi di redazione o modificare stile e voce. Gli annotatori possono anche creare set di dati sulle preferenze per RLHF classificando le risposte LLM per garantire che i chatbot siano allineati alle preferenze umane. Per i modelli testo-immagine e testo-video, gli annotatori di dati possono creare set di dati ricchi di didascalie. Questi set di dati vengono quindi utilizzati per addestrare i modelli su come generare immagini e video più strettamente allineati con l'input di testo originale dell'utente. Gli annotatori di dati possono anche generare set di dati sulle preferenze, contenenti immagini e video classificati in base a dimensioni specificate dal cliente, ad esempio attributi estetici specifici. Puoi anche richiedere un nuovo tipo di attività non ancora coperto e il nostro team lavorerà con te per creare un flusso di lavoro che soddisfi le tue esigenze.		
Perché il feedback umano è importante per i modelli di base?												Nelle applicazioni di intelligenza artificiale generativa, gli esseri umani sono in genere sia il richiedente che il consumatore di contenuti. È quindi fondamentale che gli esseri umani insegnino ai modelli di base come rispondere correttamente in base alle richieste degli utenti. Ottimizzando e personalizzando i modelli con dati etichettati, gli annotatori di dati possono simulare lo stile, la lunghezza e la precisione del modo in cui un modello dovrebbe interagire con gli utenti. Ad esempio, per creare un chatbot, gli annotatori di dati insegnano al modello come rispondere alle domande e fornire risposte addestrandolo su domande e risposte scritte da persone. Gli annotatori di dati classificano anche le diverse risposte dei chatbot in base al loro allineamento con le preferenze umane per insegnare al modello come scrivere in base all'intento e ai valori umani, cosa che può essere fatta attraverso l'apprendimento per rinforzo dal feedback umano (RLHF).		
Cos'è amazon augmented ai (amazon a2i)?													Amazon Augmented AI (Amazon A2I) è un servizio che facilita la creazione dei flussi di lavoro richiesti per la revisione umana per le previsioni di machine learning. Amazon A2I rende possibile la revisione umana a tutti gli sviluppatori, rimuovendo il lavoro oneroso associato con la costruzione di sistemi di revisione umana o la gestione di grandi numeri di revisori umani.	
Qual è il vantaggio di utilizzare amazon a2i?													"R: Molte applicazioni di machine learning richiedono che la revisione delle predizioni con bassa affidabilità sia effettuata da umani per garantire che risultati corretti. Per esempio, l'estrazione di informazioni dalle scansioni di moduli di richiesta dei mutui in alcuni casi può richiedere la revisione umana a causa della bassa qualità delle scansioni o della brutta grafia. Tuttavia, la creazione di sistemi di revisione umana può richiedere molto tempo e denaro perché rende necessaria l'implementazione di processi complessi o ""flussi di lavoro"", la scrittura di software su misura per la gestione dei compiti e dei risultati di revisione e, in molti casi, la gestione di gruppi composti da numerosi revisori. Amazon A2I facilita la creazione e la gestione di revisioni umane per le applicazioni di machine learning. Amazon A2I fornisce flussi di lavoro integrati di revisione umana per i casi d'uso comuni di machine learning, per esempio la moderazione di contenuti o l'estrazione di testo da documenti, facilitando la revisione delle previsioni di Amazon Rekognition e Amazon Textract. È possibile anche creare dei propri flussi di lavoro per modelli di ML con Amazon SageMaker o qualsiasi altro strumento. L'utilizzo di Amazon A2I permette ai revisori umani di intervenire quando un modello non può fare una previsione con grande affidabilità o effettuare un audit sulle proprie previsioni su base regolare."	
Come si inizia a usare amazon a2i?													R: Amazon A2I fornisce un'esperienza gestita per impostare un flusso di lavoro di revisione completamente umano in pochi passaggi. Per iniziare con Amazon A2I, accedi alla console AWS e raggiungi la console di Amazon SageMaker. Da qui, seleziona i flussi di lavoro di revisione umana sotto ad Augmented AI. Innanzitutto, all'interno del flusso di lavoro di revisione umano, fornisci un pointer al bucket S3 dove archiviare i risultati della revisione. Successivamente, seleziona il tipo di attività corretto e definisci le condizioni che attivano la revisione umana. Amazon A2I offre flussi di lavoro predefiniti che necessitano solo l'inserimento di alcune opzioni e forniscono istruzioni su come gli oggetti devono essere revisionati dagli essere umani. Oppure, puoi creare un flusso di lavoro personalizzato e utilizzare modelli di revisione di tua proprietà. Dopo la creazione, il flusso di lavoro può essere utilizzato direttamente nelle applicazioni utilizzando un identificatori univoco generato per questo flusso di lavoro.	
Come faccio a decidere quali oggetti devono essere inviati alla revisione umana?													R: Con A2I puoi definire puoi definire quale sia la confidenza predittiva accettabile per il tuo problema aziendale. Puoi definire regole aziendali per le predizioni di machine learning sulla base delle quali verrà attivata una revisione. Per le attività di moderazione dell'immagine di Amazon Rekognition puoi utilizzare un punteggio di confidenza che Amazon Rekognition fornisce per ogni livello in uscita per attivare la revisione umana. Per le attività di Amazon Textract puoi attivare una revisione umana quando chiavi di modulo specifiche risultano mancanti o quando il tasso di confidenza di rilevamento della chiave del modulo è basso. È anche possibile attivare una revisione umana se, dopo la valutazione di tutte le chaivi di modulo nel testo, il tasso di confidenza è al di sotto della soglia richiesta per qualsiasi chiave di modulo. Per il flusso di lavoro personalizzato puoi scrivere il codice per le condizioni aziendali in AWS Lambda o direttamente nell'applicazione client.	
Come posso accedere a una forza lavoro umana utilizzando amazon a2i?													R: Con Amazon A2I, puoi scegliere fra le seguenti opzioni della forza lavoro, ovvero (1) Amazon Mechanical Turk, (2) fornitori di servizi terzi per l’etichettatura dati disponibili attraverso AWS Marketplace e (3) i tuoi dipendenti. Per ulteriori informazioni, consulta la Guida per sviluppatori di Amazon A2I.	
Quanto costa a2i?													Consulta la pagina dei prezzi di Amazon A2I per informazioni aggiornate.	
In quali regioni aws è disponibile amazon a2i?													R: La tabella delle regioni AWS elenca tutte le regioni AWS in cui Amazon A2I è attualmente disponibile.	
I fornitori di servizi terzi di amazon augmented ai possono elaborare i dati riservati dei clienti?													R: Sì, i fornitori di servizi di Amazon Augmented AI possono elaborare i dati riservati dei clienti. Il contratto sul servizio standard tra i clienti AWS e i fornitori di servizi terzi contiene alcune disposizioni destinate a tutelare le tue informazioni riservate. Verifica tali termini prima di condividere qualsiasi informazione riservata con il fornitore di servizi. Le condizioni sono disponibili nella pagina contenente gli elenchi del fornitore di servizi su AWS Marketplace.	
Quali sono gli standard di sicurezza che i fornitori di servizi terzi amazon augmented ai devono rispettare?													R: Un fornitore di servizi di revisione umana deve possedere conformità e certificazione SOC 2 su base annuale. Il report SOC 2 contiene una descrizione dell'ambiente di controllo del fornitore di servizi basata sull'American Institute of Certified Public Accountants (AICPA) Trust Services Criteria - sicurezza, disponibilità, processo, integrità, confidenzialità e riservatezza. Oltre al SOC 2, ai fornitori di servizi viene richiesto di mantenere questi ulteriori controlli di sicurezza, per tutelare i dati dei clienti nel proprio ambiente. Controlli tecnologici: I fornitori di servizi devono utilizzare software idonei per bloccare ogni tentativo di scaricamento o copia di file/dati dai propri sistemi e prevenire l'accesso non autorizzato a questi ultimi. I fornitori di servizi devono inoltre vietare ai loro dipendenti di archiviare o copiare i dati relativi alle attività dei clienti al di fuori degli ambienti protetti dei fornitori stessi. Controlli di sicurezza di rete: I fornitori di servizi devono vietare l’accesso remoto ai dati relativi alle attività dei clienti. Inoltre, il software di condivisione di file peer-to-peer viene bloccato sulla rete del fornitore. Controllo dei dipendenti: I fornitori di servizi devono garantire di avere accordi di non divulgazione con i propri dipendenti. I fornitori di servizi sono tenuti ad adottare rigide disposizioni per impedire ai dipendenti di copiare o spostare i dati relativi alle attività dei clienti dagli ambienti protetti dei fornitori, inclusi controlli per supporti cartacei, USB, smartphone o altri dispositivi. Controlli sugli accessi fisici: I fornitori di servizi devono mantenere misure di controllo sugli accessi fisici per prevenire accessi non autorizzati ai loro siti di produzione. Tali misure possono includere autenticazione biometrica, identificazione dei dipendenti tramite badge, verifica visiva dei dipendenti da parte del personale di sicurezza ecc.	
Qualora un fornitore di servizi offra servizi di revisione umana in diversi siti di produzione, questi ultimi devono tutti essere sottoposti al processo di verifica?													R: Sì. Tutti i siti devono rispettare gli standard di sicurezza richiesti.	
Cosa accade in caso di accesso dati non autorizzato al sito di produzione del fornitore di servizi?													R: Il fornitore di servizi informa AWS e i clienti interessati entro 24 ore dal rilevamento di qualsiasi accesso, raccolta, acquisizione, utilizzo, trasmissione, divulgazione, corruzione o perdita non autorizzata(o), reale o sospettata(o), delle informazioni dei clienti. Il fornitore di servizi rimedierà nell'immediato ad ogni incidente di sicurezza e fornirà per iscritto, ad AWS e ai clienti interessati, dettagli descrittivi delle investigazioni interne.	
Cosa sono gli aws deep learning containers?														Gli AWS Deep Learning Containers (detti anche “AWS DL container”) offrono ai professionisti del machine learning e del deep learning ambienti Docker ottimizzati per formare e distribuire modelli nelle rispettive pipeline e nei flussi di lavoro su Amazon Sagemaker, Amazon EC2, Amazon ECS e Amazon EKS. Gli AWS DL container sono disponibili come immagini Docker per la formazione e l’inferenza con TensorFlow, PyTorch e MXNet su Amazon ECR.
Qual è il vantaggio di utilizzare gli aws dl container?														Sviluppare, testare, mantenere e ottimizzare immagini Docker per l’apprendimento profondo richiede investimenti notevoli in termini di tempo, risorse e manodopera di data scientist, sviluppatori di machine learning e professionisti. I tecnici sono costretti a impiegare risorse preziose in attività non differenziate piuttosto che utilizzarle per approfondire e sviluppare nuovi modelli. Tali attività includono l’installazione di pacchetti, il debug di problemi di compatibilità, l’ottimizzazione delle prestazioni e l’integrazione e il collaudo con Amazon SageMaker, Amazon EC2, Amazon ECS e Amazon EKS. Gli AWS DL container offrono ambienti Docker di apprendimento profondo completamente testati e ottimizzati che non richiedono alcuna installazione, configurazione o manutenzione. I professionisti del deep learning che desiderano formare e servire modelli in TensorFlow o Apache MXNet possono ottenere la pacchettizzazione e l’ottimizzazione desiderata grazie a queste immagini Docker.
In che modo questo servizio si collega/funziona con gli altri servizi aws?														Gli AWS DL container sono sviluppati, testati e ottimizzati per essere utilizzati in Amazon SageMaker, Amazon EC2, Amazon ECS e Amazon EKS. Le immagini Docker per gli AWS DL container sono disponibili su Amazon ECR. Per la formazione e l’inferenza di modelli di deep learning tramite GPU, gli AWS DL container necessitano che l’Amazon Machine Image (AMI) sottostante abbia installati gli adeguati driver GPU. I DL container sono progettati per funzionare con le AMI GPU predefinite disponibili in Amazon SageMaker, Amazon ECS e Amazon EKS.
Come funzionano gli aws dl container con le ami di apprendimento profondo aws?														Le AMI di apprendimento profondo AWS sono Amazon Machine Images (AMI) di EC2 sviluppate e ottimizzate per la creazione, formazione e inferenza di modelli di machine learning e apprendimento profondo. Per ulteriori informazioni visita la pagina AMI di apprendimento profondo AWS. Per ulteriori informazioni sull’utilizzo degli AWS DL container in EC2 consulta la nostra documentazione.
Qual è il costo degli aws dl container?														Gli AWS DL container sono disponibili senza alcun costo aggiuntivo. Gli unici costi da sostenere per Amazon Sagemaker sono relativi ad Amazon EC2, Amazon ECS, Amazon EKS e alle altre risorse AWS che utilizzi.
Come faccio ad accedere alle immagini docker per gli aws dl container?														Puoi accedere alle immagini Docker per gli AWS DL container dai repository in Amazon ECR. Per ulteriori informazioni e accedere all’elenco delle immagini Docker disponibili, consulta la documentazione.
